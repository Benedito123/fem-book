
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Interpolation</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>

        <script src="http://sagecell.sagemath.org/static/jquery.min.js"></script>
        <script src="http://sagecell.sagemath.org/static/embedded_sagecell.js"></script>

        <script>sagecell.makeSagecell({inputLocation: ".sage"});</script>

        <style type="text/css">
                .sagecell .CodeMirror-scroll {
                        overflow-y: hidden;
                        overflow-x: auto;
                }
                .sagecell .CodeMirror {
                        height: auto;
                }
        </style>

    
    <link rel="top" title="Introduction to Numerical Methods for Variational Problems" href="index.html" />
    <link rel="next" title="Approximation of functions in higher dimensions" href="._book007.html" />
    <link rel="prev" title="Orthogonal basis functions" href="._book005.html" />
 
  
       <style type="text/css">
         div.admonition {
           background-color: whiteSmoke;
           border: 1px solid #bababa;
         }
       </style>
      </head>
    
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="._book007.html" title="Approximation of functions in higher dimensions"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="._book005.html" title="Orthogonal basis functions"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Introduction to Numerical Methods for Variational Problems</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="interpolation">
<h1>Interpolation<a class="headerlink" href="#interpolation" title="Permalink to this headline">¶</a></h1>
<div class="section" id="the-interpolation-or-collocation-principle">
<span id="fem-approx-global-interp"></span><h2>The interpolation (or collocation) principle<a class="headerlink" href="#the-interpolation-or-collocation-principle" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-0"></span><span class="target" id="index-1"></span><span class="target" id="index-2"></span><p id="index-3">The principle of minimizing the distance between <span class="math">\(u\)</span> and <span class="math">\(f\)</span> is
an intuitive way of computing a best approximation <span class="math">\(u\in V\)</span> to <span class="math">\(f\)</span>.
However, there are other approaches as well.
One is to demand that <span class="math">\(u(x_{i}) = f(x_{i})\)</span> at some selected points
<span class="math">\(x_{i}\)</span>, <span class="math">\(i\in{\mathcal{I}_s}\)</span>:</p>
<div class="math" id="eq-auto24">
\[\tag{58}
u(x_{i}) = \sum_{j\in{\mathcal{I}_s}} c_j {\psi}_j(x_{i}) = f(x_{i}),
    \quad i\in{\mathcal{I}_s}{\thinspace .}\]</div>
<p>We recognize that the equation <span class="math">\(\sum_j c_j {\psi}_j(x_{i}) = f(x_{i})\)</span>
is actually a linear system with <span class="math">\(N+1\)</span> unknown coefficients <span class="math">\(\left\{ {c}_j \right\}_{j\in{\mathcal{I}_s}}\)</span>:</p>
<div class="math" id="eq-auto25">
\[\tag{59}
\sum_{j\in{\mathcal{I}_s}} A_{i,j}c_j = b_i,\quad i\in{\mathcal{I}_s},\]</div>
<p>with coefficient matrix and right-hand side vector given by</p>
<div class="math" id="eq-auto26">
\[\tag{60}
A_{i,j} = {\psi}_j(x_{i}),\]</div>
<div class="math" id="eq-auto27">
\[\tag{61}
b_i = f(x_{i}){\thinspace .}\]</div>
<p>This time the coefficient matrix is not symmetric because
<span class="math">\({\psi}_j(x_{i})\neq {\psi}_i(x_{j})\)</span> in general.
The method is often referred to as an <em>interpolation method</em>
since some point values of <span class="math">\(f\)</span> are given (<span class="math">\(f(x_{i})\)</span>) and we
fit a continuous function <span class="math">\(u\)</span> that goes through the <span class="math">\(f(x_{i})\)</span> points.
In this case the <span class="math">\(x_{i}\)</span> points are called <em>interpolation points</em>.
When the same approach is used to approximate differential equations,
one usually applies the name <em>collocation method</em> and
<span class="math">\(x_{i}\)</span> are known as <em>collocation points</em>.</p>
<p>Given <span class="math">\(f\)</span>  as a <code class="docutils literal"><span class="pre">sympy</span></code> symbolic expression <code class="docutils literal"><span class="pre">f</span></code>, <span class="math">\(\left\{ {{\psi}}_i \right\}_{i\in{\mathcal{I}_s}}\)</span>
as a list <code class="docutils literal"><span class="pre">psi</span></code>, and a set of points <span class="math">\(\left\{ {x}_i \right\}_{i\in{\mathcal{I}_s}}\)</span>  as a list or array
<code class="docutils literal"><span class="pre">points</span></code>, the following Python function sets up and solves the matrix system
for the coefficients <span class="math">\(\left\{ {c}_i \right\}_{i\in{\mathcal{I}_s}}\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">psi_sym</span> <span class="o">=</span> <span class="n">psi</span>  <span class="c1"># save symbolic expression</span>
    <span class="c1"># Turn psi and f into Python functions</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="n">sym</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">f</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">j</span><span class="p">](</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="c1"># c is a sympy Matrix object, turn to list</span>
    <span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">sym</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">psi_sym</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">,</span> <span class="n">c</span>
</pre></div>
</div>
<p>The <code class="docutils literal"><span class="pre">interpolation</span></code> function is a part of the <code class="docutils literal"><span class="pre">approx1D</span></code>
module.</p>
<p>We found it convenient in the above function to turn the expressions <code class="docutils literal"><span class="pre">f</span></code> and
<code class="docutils literal"><span class="pre">psi</span></code> into ordinary Python functions of <code class="docutils literal"><span class="pre">x</span></code>, which can be called with
<code class="docutils literal"><span class="pre">float</span></code> values in the list <code class="docutils literal"><span class="pre">points</span></code> when building the matrix and
the right-hand side. The alternative is to use the <code class="docutils literal"><span class="pre">subs</span></code> method
to substitute the <code class="docutils literal"><span class="pre">x</span></code> variable in an expression by an element from
the <code class="docutils literal"><span class="pre">points</span></code> list. The following session illustrates both approaches
in a simple setting:</p>
<div class="highlight-ipy"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sym</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">e</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>              <span class="c1"># symbolic expression involving x</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">p</span> <span class="o">=</span> <span class="mf">0.5</span>               <span class="c1"># a value of x</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">v</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>      <span class="c1"># evaluate e for x=p</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">v</span>
<span class="mf">0.250000000000000</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="n">sympy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">numbers</span><span class="o">.</span><span class="n">Float</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">e</span> <span class="o">=</span> <span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">e</span><span class="p">)</span>  <span class="c1"># make Python function of e</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">function</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">v</span> <span class="o">=</span> <span class="n">e</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>              <span class="c1"># evaluate e(x) for x=p</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">v</span>
<span class="mf">0.25</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="nb">float</span>
</pre></div>
</div>
<p>A nice feature of the interpolation or collocation method is that it
avoids computing integrals. However, one has to decide on the location
of the <span class="math">\(x_{i}\)</span> points.  A simple, yet common choice, is to
distribute them uniformly throughout the unit interval.</p>
<div class="section" id="example-2">
<h3>Example<a class="headerlink" href="#example-2" title="Permalink to this headline">¶</a></h3>
<p>Let us illustrate the interpolation method by approximating
our parabola <span class="math">\(f(x)=10(x-1)^2-1\)</span> by a linear function on <span class="math">\(\Omega=[1,2]\)</span>,
using two collocation points <span class="math">\(x_0=1+1/3\)</span> and <span class="math">\(x_1=1+2/3\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sym</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>
<span class="n">Omega</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="o">+</span> <span class="n">sym</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">sym</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)]</span>
<span class="n">u</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
</pre></div>
</div>
<p>The resulting linear system becomes</p>
<div class="math">
\[\begin{split}\left(\begin{array}{ll}
1 &amp; 4/3\\
1 &amp; 5/3\\
\end{array}\right)
\left(\begin{array}{l}
c_0\\
c_1\\
\end{array}\right)
=
\left(\begin{array}{l}
1/9\\
31/9\\
\end{array}\right)\end{split}\]</div>
<p>with solution <span class="math">\(c_0=-119/9\)</span> and <span class="math">\(c_1=10\)</span>.
Figure <a class="reference internal" href="#fem-approx-global-linear-interp-fig1"><span class="std std-ref">Approximation of a parabola by linear functions computed by two interpolation points: 4/3 and 5/3 (left) versus 1 and 2 (right)</span></a> (left) shows the resulting
approximation <span class="math">\(u=-119/9 + 10x\)</span>.
We can easily test other interpolation points, say <span class="math">\(x_0=1\)</span> and <span class="math">\(x_1=2\)</span>.
This changes the line quite significantly, see
Figure <a class="reference internal" href="#fem-approx-global-linear-interp-fig1"><span class="std std-ref">Approximation of a parabola by linear functions computed by two interpolation points: 4/3 and 5/3 (left) versus 1 and 2 (right)</span></a> (right).</p>
<div class="figure" id="id1">
<span id="fem-approx-global-linear-interp-fig1"></span><a class="reference internal image-reference" href="_images/parabola_inter.png"><img alt="_images/parabola_inter.png" src="_images/parabola_inter.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text"><em>Approximation of a parabola by linear functions computed by two interpolation points: 4/3 and 5/3 (left) versus 1 and 2 (right)</em></span></p>
</div>
</div>
</div>
<div class="section" id="lagrange-polynomials">
<span id="fem-approx-global-lagrange"></span><h2>Lagrange polynomials<a class="headerlink" href="#lagrange-polynomials" title="Permalink to this headline">¶</a></h2>
<p id="index-4">In the section <a class="reference internal" href="._book005.html#fem-approx-global-fourier"><span class="std std-ref">Fourier series</span></a> we explained the advantage
of having a diagonal matrix: formulas for the coefficients
<span class="math">\(\left\{ {c}_i \right\}_{i\in{\mathcal{I}_s}}\)</span> can then be derived by hand. For an interpolation (or
collocation) method a diagonal matrix implies that <span class="math">\({\psi}_j(x_{i})
= 0\)</span> if <span class="math">\(i\neq j\)</span>. One set of basis functions <span class="math">\({\psi}_i(x)\)</span> with this
property is the <em>Lagrange interpolating polynomials</em>, or just
<em>Lagrange polynomials</em>. (Although the functions are named after
Lagrange, they were first discovered by Waring in 1779, rediscovered
by Euler in 1783, and published by Lagrange in 1795.)  Lagrange
polynomials are key building blocks in the finite element method, so
familiarity with these polynomials will be required anyway.</p>
<p>A Lagrange polynomial can be written as</p>
<div class="math" id="eq-fem-approx-global-lagrange-poly">
\[\tag{62}
{\psi}_i(x) =
    \prod_{j=0,j\neq i}^N
    \frac{x-x_{j}}{x_{i}-x_{j}}
    = \frac{x-x_0}{x_{i}-x_0}\cdots\frac{x-x_{i-1}}{x_{i}-x_{i-1}}\frac{x-x_{i+1}}{x_{i}-x_{i+1}}
    \cdots\frac{x-x_N}{x_{i}-x_N},\]</div>
<p>for <span class="math">\(i\in{\mathcal{I}_s}\)</span>.
We see from <a class="reference internal" href="#eq-fem-approx-global-lagrange-poly"><span class="std std-ref">(62)</span></a> that all the <span class="math">\({\psi}_i\)</span>
functions are polynomials of degree <span class="math">\(N\)</span> which have the property</p>
<div class="math" id="eq-fem-inter-prop">
<span id="index-5"></span>\[\begin{split}\tag{63}
{\psi}_i(x_s) = \delta_{is},\quad \delta_{is} =
    \left\lbrace\begin{array}{ll}
    1, &amp; i=s,\\
    0, &amp; i\neq s,
    \end{array}\right.\end{split}\]</div>
<p>when <span class="math">\(x_s\)</span> is an interpolation (collocation) point.
Here we have used the <em>Kronecker delta</em> symbol <span class="math">\(\delta_{is}\)</span>.
This property implies that <span class="math">\(A\)</span> is a diagonal matrix, that is
that  <span class="math">\(A_{i,j}=0\)</span> for <span class="math">\(i\neq j\)</span> and
<span class="math">\(A_{i,j}=1\)</span> when <span class="math">\(i=j\)</span>. The solution of the linear system is
then simply</p>
<div class="math" id="eq-auto28">
\[\tag{64}
c_i = f(x_{i}),\quad i\in{\mathcal{I}_s},\]</div>
<p>and</p>
<div class="math" id="eq-auto29">
\[\tag{65}
u(x) = \sum_{j\in{\mathcal{I}_s}} c_i {\psi}_i(x) = \sum_{j\in{\mathcal{I}_s}} f(x_{i}){\psi}_i(x){\thinspace .}\]</div>
<p>We remark however that <a class="reference internal" href="#eq-fem-inter-prop"><span class="std std-ref">(63)</span></a> does not necessary imply that the matrix
obtained by the least squares or project methods are diagonal.</p>
<p>The following function computes the Lagrange interpolating polynomial
<span class="math">\({\psi}_i(x)\)</span> on the unit interval (0,1), given the interpolation points <span class="math">\(x_{0},\ldots,x_{N}\)</span> in
the list or array <code class="docutils literal"><span class="pre">points</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="n">i</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">*=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">p</span>
</pre></div>
</div>
<p>The next function computes a complete basis, <span class="math">\({\psi}_0,\ldots,{\psi}_N\)</span>, using equidistant points throughout
<span class="math">\(\Omega\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">h</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
    <span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="n">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span>
</pre></div>
</div>
<p>When <code class="docutils literal"><span class="pre">x</span></code> is an <code class="docutils literal"><span class="pre">sym.Symbol</span></code> object, we let the spacing between the
interpolation points, <code class="docutils literal"><span class="pre">h</span></code>, be a <code class="docutils literal"><span class="pre">sympy</span></code> rational number, so that we
get nice end results in the formulas for <span class="math">\({\psi}_i\)</span>.  The other case,
when <code class="docutils literal"><span class="pre">x</span></code> is a plain Python <code class="docutils literal"><span class="pre">float</span></code>, signifies numerical computing, and
then we let <code class="docutils literal"><span class="pre">h</span></code> be a floating-point number.  Observe that the
<code class="docutils literal"><span class="pre">Lagrange_polynomial</span></code> function works equally well in the symbolic and
numerical case - just think of <code class="docutils literal"><span class="pre">x</span></code> being an <code class="docutils literal"><span class="pre">sym.Symbol</span></code> object or a
Python <code class="docutils literal"><span class="pre">float</span></code>.  A little interactive session illustrates the
difference between symbolic and numerical computing of the basis
functions and points:</p>
<div class="highlight-ipy"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sym</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">points</span>
<span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">psi</span>
<span class="p">[(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">),</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">),</span> <span class="o">-</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">)]</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># numerical computing</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">points</span>
<span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">psi</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
</pre></div>
</div>
<p>That is, when used symbolically, the <code class="docutils literal"><span class="pre">Lagrange_polynomials_01</span></code>
function returns the symbolic expression for the Lagrange functions
while when <code class="docutils literal"><span class="pre">x</span></code> is a numerical valued the function returns the value of
the basis function evaluate in <code class="docutils literal"><span class="pre">x</span></code>.  In the present example only the
second basis function should be 1 in the mid-point while the others
are zero according to <a class="reference internal" href="#eq-fem-inter-prop"><span class="std std-ref">(63)</span></a>.</p>
<div class="section" id="approximation-of-a-polynomial">
<h3>Approximation of a polynomial<a class="headerlink" href="#approximation-of-a-polynomial" title="Permalink to this headline">¶</a></h3>
<p>The Galerkin or least squares methods lead to an exact approximation
if <span class="math">\(f\)</span> lies in the space spanned by the basis functions. It could be
of interest to see how the interpolation method with Lagrange
polynomials as basis is able to approximate a polynomial, e.g., a
parabola. Running</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">psi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
</pre></div>
</div>
<p>shows the result that up to <code class="docutils literal"><span class="pre">N=4</span></code> we achieve an exact approximation,
and then round-off errors start to grow, such that
<code class="docutils literal"><span class="pre">N=15</span></code> leads to a 15-degree polynomial for <span class="math">\(u\)</span> where
the coefficients in front of <span class="math">\(x^r\)</span> for <span class="math">\(r&gt;2\)</span> are
of size <span class="math">\(10^{-5}\)</span> and smaller. As the matrix is ill-conditioned
and we use floating-point arithmetic, we do not obtain the exact
solution. Still, we get  a solution that is visually identical to the
exact solution. The reason is that the ill-conditioning causes
the system to have many solutions very close to the true solution.
While we are lucky for <code class="docutils literal"><span class="pre">N=15</span></code> and obtain a solution that is
visually identical to the true solution, ill-conditioning may also
result in completely wrong results. As we continue with higher values,  <code class="docutils literal"><span class="pre">N=20</span></code> reveals that the
procedure is starting to fall apart as the approximate solution is around 0.9 at <span class="math">\(x=1.0\)</span>,
where it should have
been <span class="math">\(1.0\)</span>. At <code class="docutils literal"><span class="pre">N=30</span></code> the approximate solution is around <span class="math">\(5\cdot10^8\)</span> at <span class="math">\(x=1\)</span>.</p>
<p>[<strong>kam 2</strong>: Not sure of this. Need to test. Seems like an unstable variant of Lagrange which is somewhat strange when combined with interpolation which should produce the identity matrix]</p>
</div>
<div class="section" id="successful-example">
<h3>Successful example<a class="headerlink" href="#successful-example" title="Permalink to this headline">¶</a></h3>
<p>Trying out the Lagrange polynomial basis for approximating
<span class="math">\(f(x)=\sin 2\pi x\)</span> on <span class="math">\(\Omega =[0,1]\)</span> with the least squares
and the interpolation techniques can be done by</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sym</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
<span class="n">psi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">u</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="n">u</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
</pre></div>
</div>
<p>Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-sine-ls-colloc"><span class="std std-ref">Approximation via least squares (left) and interpolation (right) of a sine function by Lagrange interpolating polynomials of degree 3</span></a> shows the results.
There is a difference between the least squares and the interpolation
technique but the difference decreases rapidly with  Increasing <span class="math">\(N\)</span>.</p>
<div class="figure" id="id2">
<span id="fem-approx-global-lagrange-fig-sine-ls-colloc"></span><a class="reference internal image-reference" href="_images/Lagrange_ls_interp_sin_4.png"><img alt="_images/Lagrange_ls_interp_sin_4.png" src="_images/Lagrange_ls_interp_sin_4.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text"><em>Approximation via least squares (left) and interpolation (right) of a sine function by Lagrange interpolating polynomials of degree 3</em></span></p>
</div>
</div>
<div class="section" id="less-successful-example">
<span id="index-6"></span><h3>Less successful example<a class="headerlink" href="#less-successful-example" title="Permalink to this headline">¶</a></h3>
<p>The next example concerns interpolating <span class="math">\(f(x)=|1-2x|\)</span> on <span class="math">\(\Omega
=[0,1]\)</span> using Lagrange polynomials. Figure
<a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-7-14"><span class="std std-ref">Interpolation of an absolute value function by Lagrange polynomials and uniformly distributed interpolation points: degree 7 (left) and 14 (right)</span></a> shows a peculiar
effect: the approximation starts to oscillate more and more as <span class="math">\(N\)</span>
grows. This numerical artifact is not surprising when looking at the
individual Lagrange polynomials. Figure
<a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-osc"><span class="std std-ref">Illustration of the oscillatory behavior of two Lagrange polynomials based on 12 uniformly spaced points (marked by circles)</span></a> shows two such
polynomials, <span class="math">\(\psi_2(x)\)</span> and <span class="math">\(\psi_7(x)\)</span>, both of degree 11 and
computed from uniformly spaced points <span class="math">\(x_{i}=i/11\)</span>,
<span class="math">\(i=0,\ldots,11\)</span>, marked with circles.  We clearly see the property of
Lagrange polynomials: <span class="math">\(\psi_2(x_{i})=0\)</span> and <span class="math">\(\psi_7(x_{i})=0\)</span> for
all <span class="math">\(i\)</span>, except <span class="math">\(\psi_2(x_{2})=1\)</span> and <span class="math">\(\psi_7(x_{7})=1\)</span>.  The most
striking feature, however, is the dominating oscillation near the
boundary where <span class="math">\(\psi_2&gt;5\)</span> and <span class="math">\(\psi_7=-10\)</span> in some points. The reason is easy to understand: since we force the
functions to be zero at so many points, a polynomial of high degree is
forced to oscillate between the points.  The phenomenon is named
<em>Runge&#8217;s phenomenon</em> and you can read a more detailed explanation on
<a class="reference external" href="http://en.wikipedia.org/wiki/Runge%27s_phenomenon">Wikipedia</a>.</p>
</div>
<div class="section" id="remedy-for-strong-oscillations">
<span id="index-7"></span><h3>Remedy for strong oscillations<a class="headerlink" href="#remedy-for-strong-oscillations" title="Permalink to this headline">¶</a></h3>
<p>The oscillations can be reduced by a more clever choice of
interpolation points, called the <em>Chebyshev nodes</em>:</p>
<div class="math" id="eq-auto30">
\[\tag{66}
x_{i} = \frac{1}{2} (a+b) + \frac{1}{2}(b-a)\cos\left( \frac{2i+1}{2(N+1)}pi\right),\quad i=0\ldots,N,\]</div>
<p>on the interval <span class="math">\(\Omega = [a,b]\)</span>.
Here is a flexible version of the <code class="docutils literal"><span class="pre">Lagrange_polynomials_01</span></code> function above,
valid for any interval <span class="math">\(\Omega =[a,b]\)</span> and with the possibility to generate
both uniformly distributed points and Chebyshev nodes:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">Lagrange_polynomials</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span> <span class="n">point_distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">point_distribution</span> <span class="o">==</span> <span class="s1">&#39;uniform&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">):</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">N</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
        <span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">i</span><span class="o">*</span><span class="n">h</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">elif</span> <span class="n">point_distribution</span> <span class="o">==</span> <span class="s1">&#39;Chebyshev&#39;</span><span class="p">:</span>
        <span class="n">points</span> <span class="o">=</span> <span class="n">Chebyshev_nodes</span><span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="n">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span>

<span class="k">def</span> <span class="nf">Chebyshev_nodes</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">cos</span><span class="p">,</span> <span class="n">pi</span>
    <span class="k">return</span> <span class="p">[</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">*</span><span class="n">cos</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="n">pi</span><span class="p">)</span> \
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
</pre></div>
</div>
<p>All the functions computing Lagrange polynomials listed
above are found in the module file <code class="docutils literal"><span class="pre">Lagrange.py</span></code>.</p>
<p>Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-cheb-7-14"><span class="std std-ref">Interpolation of an absolute value function by Lagrange polynomials and Chebyshev nodes as interpolation points: degree 7 (left) and 14 (right)</span></a> shows the
improvement of using Chebyshev nodes, compared with the equidistant
points in Figure
<a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-7-14"><span class="std std-ref">Interpolation of an absolute value function by Lagrange polynomials and uniformly distributed interpolation points: degree 7 (left) and 14 (right)</span></a>.  The reason for
this improvement is that the corresponding Lagrange polynomials have
much smaller oscillations, which can be seen by comparing Figure
<a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-cheb-osc"><span class="std std-ref">Illustration of the less oscillatory behavior of two Lagrange polynomials based on 12 Chebyshev points (marked by circles)</span></a> (Chebyshev
points) with Figure
<a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-osc"><span class="std std-ref">Illustration of the oscillatory behavior of two Lagrange polynomials based on 12 uniformly spaced points (marked by circles)</span></a> (equidistant
points). Note the different scale on the vertical axes in the two
figures and also that the Chebyshev points tend to cluster
more around the element boundaries.</p>
<p>Another cure for undesired oscillations of higher-degree interpolating
polynomials is to use lower-degree Lagrange polynomials on many small
patches of the domain. This is actually the idea pursued in the finite
element method. For instance, linear Lagrange polynomials on <span class="math">\([0,1/2]\)</span>
and <span class="math">\([1/2,1]\)</span> would yield a perfect approximation to <span class="math">\(f(x)=|1-2x|\)</span> on
<span class="math">\(\Omega = [0,1]\)</span> since <span class="math">\(f\)</span> is piecewise linear.</p>
<div class="figure" id="id3">
<span id="fem-approx-global-lagrange-fig-abs-lag-unif-7-14"></span><a class="reference internal image-reference" href="_images/Lagrange_interp_abs_8_15.png"><img alt="_images/Lagrange_interp_abs_8_15.png" src="_images/Lagrange_interp_abs_8_15.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text"><em>Interpolation of an absolute value function by Lagrange polynomials and uniformly distributed interpolation points: degree 7 (left) and 14 (right)</em></span></p>
</div>
<div class="figure" id="id4">
<span id="fem-approx-global-lagrange-fig-abs-lag-unif-osc"></span><a class="reference internal image-reference" href="_images/Lagrange_basis_12.png"><img alt="_images/Lagrange_basis_12.png" src="_images/Lagrange_basis_12.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-text"><em>Illustration of the oscillatory behavior of two Lagrange polynomials based on 12 uniformly spaced points (marked by circles)</em></span></p>
</div>
<div class="figure" id="id5">
<span id="fem-approx-global-lagrange-fig-abs-lag-cheb-7-14"></span><a class="reference internal image-reference" href="_images/Lagrange_interp_abs_Cheb_8_15.png"><img alt="_images/Lagrange_interp_abs_Cheb_8_15.png" src="_images/Lagrange_interp_abs_Cheb_8_15.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text"><em>Interpolation of an absolute value function by Lagrange polynomials and Chebyshev nodes as interpolation points: degree 7 (left) and 14 (right)</em></span></p>
</div>
<div class="figure" id="id6">
<span id="fem-approx-global-lagrange-fig-abs-lag-cheb-osc"></span><a class="reference internal image-reference" href="_images/Lagrange_basis_Cheb_12.png"><img alt="_images/Lagrange_basis_Cheb_12.png" src="_images/Lagrange_basis_Cheb_12.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-text"><em>Illustration of the less oscillatory behavior of two Lagrange polynomials based on 12 Chebyshev points (marked by circles)</em></span></p>
</div>
<p>How does the least squares or projection methods work with Lagrange
polynomials?
We can just call the <code class="docutils literal"><span class="pre">least_squares</span></code> function, but
<code class="docutils literal"><span class="pre">sympy</span></code> has problems integrating the <span class="math">\(f(x)=|1-2x|\)</span>
function times a polynomial, so we need to fall back on numerical
integration.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sym</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
                <span class="c1"># Could not integrate symbolically, fall back</span>
                <span class="c1"># on numerical integration with mpmath.quad</span>
                <span class="n">integrand</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
                <span class="n">I</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
        <span class="n">integrand</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">f</span>
        <span class="n">I</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sym</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">sym</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
    <span class="n">u</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">,</span> <span class="n">c</span>
</pre></div>
</div>
<div class="figure" id="id7">
<span id="fem-approx-global-lagrange-fig-abs-lag-unif-ls"></span><a class="reference internal image-reference" href="_images/Lagrange_ls_abs_12.png"><img alt="_images/Lagrange_ls_abs_12.png" src="_images/Lagrange_ls_abs_12.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-text"><em>Illustration of an approximation of the absolute value function using the least square method</em></span></p>
</div>
</div>
</div>
<div class="section" id="bernstein-polynomials">
<span id="fem-approx-global-bernstein"></span><h2>Bernstein polynomials<a class="headerlink" href="#bernstein-polynomials" title="Permalink to this headline">¶</a></h2>
<p id="index-8">An alternative to the Taylor and Lagrange families of polynomials
are the Bernstein polynomials.
These polynomials are popular in visualization and we include a
presentation of them for completeness. Furthermore, as we
will demonstrate, the choice of basis functions may matter
in terms of accuracy and efficiency.
In fact, in finite element methods,
a main challenge, from a numerical analysis point of view,
is to determine appropriate basis functions for
a particular purpose or equation.</p>
<p>On the unit interval, the Bernstein
polynomials are defined in terms of powers of <span class="math">\(x\)</span> and <span class="math">\(1-x\)</span>
(the barycentric coordinates of the unit interval) as</p>
<div class="math" id="eq-bernstein-basis">
\[\tag{67}
B_{i,n} = \binom{n}{i} x^i (1-x)^{n-i}, \quad i=0, \ldots, n .\]</div>
<div class="figure" id="id8">
<span id="bernstein-basis-8"></span><img alt="_images/Bernstein_basis8.png" src="_images/Bernstein_basis8.png" />
<p class="caption"><span class="caption-text"><em>The nine functions of a Bernstein basis of order 8</em></span></p>
</div>
<div class="figure" id="id9">
<span id="lagrange-basis-8"></span><img alt="_images/Lagrange_basis8.png" src="_images/Lagrange_basis8.png" />
<p class="caption"><span class="caption-text"><em>The nine functions of a Lagrange basis of order 8</em></span></p>
</div>
<p>The Figure <a class="reference internal" href="#bernstein-basis-8"><span class="std std-ref">The nine functions of a Bernstein basis of order 8</span></a> shows the  basis functions of a Bernstein basis of order 8.
This figure should be compared against Figure <a class="reference internal" href="#lagrange-basis-8"><span class="std std-ref">The nine functions of a Lagrange basis of order 8</span></a>, which
shows the corresponding Lagrange basis of order 8.
The Lagrange basis is convenient because it is a nodal basis, that is; the basis functions are 1 in their nodal points and zero at all other nodal points as described by <a class="reference internal" href="#eq-fem-inter-prop"><span class="std std-ref">(63)</span></a>.
However, looking at Figure <a class="reference internal" href="#lagrange-basis-8"><span class="std std-ref">The nine functions of a Lagrange basis of order 8</span></a>
we also notice that the basis function are oscillatory and have absolute
values that are significantly larger than 1 between the nodal points.
Consider for instance the basis function represented by the purple color.
It is 1 in <span class="math">\(x=0.5\)</span> and 0 at all other nodal points
and hence this basis function represents the value at the mid-point.
However, this function also has strong
negative contributions close to the element boundaries where
it takes negative values less than <span class="math">\(-2\)</span>.
For the Bernstein basis, all  functions are positive and
all functions output values in <span class="math">\([0,1]\)</span>. Therefore there is no oscillatory behavior.
The main disadvantage of the Bernstein basis is that the basis is not
a nodal basis. In fact, all functions contribute everywhere except <span class="math">\(x=0\)</span> and <span class="math">\(x=1\)</span>.</p>
<p>Both Lagrange and Bernstein polynomials take larger values towards the element boundaries than in
the middle of the element, but the Bernstein polynomials always remain less or equal to 1.</p>
<p>We  remark that the Bernstein basis is easily extended to polygons in 2D and
3D in terms of the barycentric coordinates. For example, consider the reference triangle in
2D consisting of the faces <span class="math">\(x=0\)</span>, <span class="math">\(y=0\)</span>, and <span class="math">\(x+y=1\)</span>. The barycentric coordinates
are <span class="math">\(b_1(x,y)=x\)</span>, <span class="math">\(b_2(x,y)\)</span>, and <span class="math">\(b_3(x,y)=1-x-y\)</span> and the Bernstein basis functions
of order <span class="math">\(n\)</span> is of the form</p>
<div class="math">
\[B_{i,j,k} = \frac{n!}{i! j! k!} x^i y^j (1-x-y)^k, \quad \mbox{ for }  i+j+k = n {\thinspace .}\]</div>
</div>
</div>
<div class="section" id="approximation-properties-and-convergence-rates">
<h1>Approximation properties and convergence rates<a class="headerlink" href="#approximation-properties-and-convergence-rates" title="Permalink to this headline">¶</a></h1>
<p>We will now compare the different approximation methods in terms of
accuracy and efficiency.  We consider four different series for
generating approximations: Taylor, Lagrange, sinusoidal, and
Bernstein. For all families we expect that the approximations improve
as we increase the number of basis functions in our
representations. We also expect that the computational complexity
increases. Let us therefore try to quantify the accuracy and
efficiency of the different methods in terms of the number of basis
functions <span class="math">\(N\)</span>. In the present example we consider the least square
method.</p>
<p>Let us consider the approximation of a Gaussian bell function, i.e.,
that the exact solution is</p>
<div class="math">
\[u_e = \exp(-(x-0.5)^2) - \exp(-0.5^2)\]</div>
<p>We remark that <span class="math">\(u_e\)</span> is zero in <span class="math">\(x=0\)</span> and <span class="math">\(x=1\)</span> and that
we have chosen the bell function because it cannot be expressed
as a finite sum of either polynomials or sines.
We may therefore study the behavior as <span class="math">\(N\rightarrow\infty\)</span>.</p>
<p>To quantify the behavior of the error as well as the
complexity of the computations we  compute the approximation
with increasing number of basis functions and time
the computations by using <code class="docutils literal"><span class="pre">time.clock</span></code> (returning the CPU time so far
in the program). A code example goes as
follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">convergence_rate_analysis</span><span class="p">(</span><span class="n">series_type</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
    <span class="n">N_values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">]</span>
    <span class="n">norms</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">cpu_times</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="n">N_values</span><span class="p">:</span>

        <span class="n">psi</span> <span class="o">=</span> <span class="n">series</span><span class="p">(</span><span class="n">series_type</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">least_squares_non_verbose</span><span class="p">(</span>
           <span class="n">gauss_bell</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
        <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span>

        <span class="n">error2</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="p">(</span><span class="n">func</span> <span class="o">-</span> <span class="n">u</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">L2_norm</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">error2</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">L2_norm</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">L2_norm</span><span class="p">)</span>
        <span class="n">norms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">L2_norm</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">cpu_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t1</span><span class="o">-</span><span class="n">t0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">N_values</span><span class="p">,</span> <span class="n">norms</span><span class="p">,</span> <span class="n">cpu_times</span>
</pre></div>
</div>
<p>We run the analysis as follows</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">Omega</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">gaussian_bell</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">sym</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">step</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Piecewise</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.25</span> <span class="o">&lt;</span> <span class="n">x</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">True</span><span class="p">))</span> <span class="o">-</span> \
       <span class="n">sym</span><span class="o">.</span><span class="n">Piecewise</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.75</span> <span class="o">&lt;</span> <span class="n">x</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">True</span><span class="p">))</span>
<span class="n">func</span> <span class="o">=</span> <span class="n">gaussian_bell</span>

<span class="kn">import</span> <span class="nn">pylab</span>
<span class="n">series_types</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Taylor&quot;</span><span class="p">,</span> <span class="s2">&quot;Sinusoidal&quot;</span><span class="p">,</span> <span class="s2">&quot;Bernstein&quot;</span><span class="p">,</span> <span class="s2">&quot;Lagrange&quot;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">series_type</span> <span class="ow">in</span> <span class="n">series_types</span><span class="p">:</span>
    <span class="n">N_values</span><span class="p">,</span> <span class="n">norms</span><span class="p">,</span> <span class="n">cpu_times</span> <span class="o">=</span> \
        <span class="n">convergence_rate_analysis</span><span class="p">(</span><span class="n">series_type</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">loglog</span><span class="p">(</span><span class="n">N_values</span><span class="p">,</span> <span class="n">norms</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Below we list the numerical error for different <span class="math">\(N\)</span>  when approximating the Gaussian bell function.</p>
<table border="1" class="docutils">
<colgroup>
<col width="22%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">N</th>
<th class="head">2</th>
<th class="head">4</th>
<th class="head">8</th>
<th class="head">16</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Taylor</td>
<td>9.83e-02</td>
<td>2.63e-03</td>
<td>7.83e-07</td>
<td>3.57e-10</td>
</tr>
<tr class="row-odd"><td>sine</td>
<td>2.70e-03</td>
<td>6.10e-04</td>
<td>1.20e-04</td>
<td>2.17e-05</td>
</tr>
<tr class="row-even"><td>Bernstein</td>
<td>2.10e-03</td>
<td>4.45e-05</td>
<td>8.73e-09</td>
<td>4.49e-15</td>
</tr>
<tr class="row-odd"><td>Lagrange</td>
<td>2.10e-03</td>
<td>4.45e-05</td>
<td>8.73e-09</td>
<td>2.45e-12</td>
</tr>
</tbody>
</table>
<p>It is quite clear that the different methods have different
properties.  For example, the Lagrange basis for <span class="math">\(N=16\)</span> is 145 times
more accurate than the Taylor basis. However, Bernstein is actually
more than 500 times more accurate than the Lagrange basis! The
approximations obtained by sines are far behind the polynomial
approximations for <span class="math">\(N&gt;4\)</span>.</p>
<p>The corresponding CPU time of the required computations also vary quite a bit:</p>
<table border="1" class="docutils">
<colgroup>
<col width="28%" />
<col width="19%" />
<col width="19%" />
<col width="19%" />
<col width="16%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">N</th>
<th class="head">2</th>
<th class="head">4</th>
<th class="head">8</th>
<th class="head">16</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Taylor</td>
<td>0.0123</td>
<td>0.0325</td>
<td>0.108</td>
<td>0.441</td>
</tr>
<tr class="row-odd"><td>sine</td>
<td>0.0113</td>
<td>0.0383</td>
<td>0.229</td>
<td>1.107</td>
</tr>
<tr class="row-even"><td>Bernstein</td>
<td>0.0384</td>
<td>0.1100</td>
<td>0.3368</td>
<td>1.187</td>
</tr>
<tr class="row-odd"><td>Lagrange</td>
<td>0.0807</td>
<td>0.3820</td>
<td>2.5233</td>
<td>26.52</td>
</tr>
</tbody>
</table>
<p>Here, the timings are in seconds.  The Taylor basis is the most
efficient and is in fact more than 60 times faster than the Lagrange
basis for <span class="math">\(N=16\)</span> (with our naive implementation of basic formulas).</p>
<p>In order to get a more precise idea of how the approximation methods
behave as <span class="math">\(N\)</span> increases, we investigate two simple data models which
may be used in a regression analysis.  These two are the polynomial
and exponential model defined by</p>
<div class="math" id="eq-sec-approx-pol-model">
\[\tag{68}
E_{1}(N) = \alpha_{1} N^{\beta_{1}},\]</div>
<div class="math" id="eq-sec-approx-exp-model">
\[\tag{69}
E_{2}(N) = \alpha_{2} \exp(\beta_2 N)\]</div>
<p>Taking the logarithm of <a class="reference internal" href="#eq-sec-approx-pol-model"><span class="std std-ref">(68)</span></a> we
obtain</p>
<div class="math">
\[\log (E_1(N)) = \beta_1 \log(N) + log(\alpha_1)\]</div>
<p>Hence, letting <span class="math">\(x=\log(N)\)</span> be the independent variable and <span class="math">\(y=\log
(E_1(N))\)</span> the dependent one, we simply have the straight line <span class="math">\(y = a x
+ b\)</span> with <span class="math">\(a=\beta_1\)</span> and <span class="math">\(b= log(\alpha_1)\)</span>.  Then, we may perform a
regression analysis as earlier with respect to the basis functions
<span class="math">\((1,x)\)</span> and obtain an estimate of the order of convergence in terms of
<span class="math">\(\beta_1\)</span> . For the second model <a class="reference internal" href="#eq-sec-approx-exp-model"><span class="std std-ref">(69)</span></a>, we take
the natural logarithm and obtain</p>
<div class="math">
\[\ln (E_2(N)) = \beta_2 N + \ln(\alpha_2)\]</div>
<p>Again, regression analysis provides the means to estimate the convergence,
but here we let <span class="math">\(x=N\)</span> be the independent variable,
<span class="math">\(y=\ln (E_2(N))\)</span>, <span class="math">\(a=\beta_2\)</span> and <span class="math">\(b= \ln(\alpha_2)\)</span>.
To summarize, the polynomial model should have the data around a straight
line in a log-log plot, while the exponential model has its date around
a straight line in a log plot with the logarithmic scale on the <span class="math">\(y\)</span> axis.</p>
<p>Before we perform the regression analysis, a good rule is to inspect
the behavior visually in log and log-log plots. Figure
<a class="reference internal" href="#fem-approx-bell-loglogfig"><span class="std std-ref">Convergence of least square approximation using basis function in terms of the Taylor, sinusoidal, Bernstein and Lagrange basis in a log-log plot</span></a> shows a log-log plot of the error with
respect to <span class="math">\(N\)</span> for the various methods. Clearly, the sinusoidal basis
seems to have a polynomial convergence rate as the log-log plot is a
linear line. The Bernstein, Lagrange, and Taylor methods appear to
have convergence that is faster than polynomial. It is then
interesting to consider a log plot and see if the behavior is
exponential. Figure <a class="reference internal" href="#fem-approx-bell-semilogfig"><span class="std std-ref">Convergence of least square approximation using basis function in terms of the Taylor, sinusoidal, Bernstein and Lagrange basis in a log plot</span></a> is a log
plot. Here, the Bernstein approximation appears to be a linear line
which suggests that the convergence is exponential.</p>
<div class="figure" id="id10">
<span id="fem-approx-bell-loglogfig"></span><img alt="_images/Bell_convergence_loglog.png" src="_images/Bell_convergence_loglog.png" />
<p class="caption"><span class="caption-text"><em>Convergence of least square approximation using basis function in terms of the Taylor, sinusoidal, Bernstein and Lagrange basis in a log-log plot</em></span></p>
</div>
<div class="figure" id="id11">
<span id="fem-approx-bell-semilogfig"></span><img alt="_images/Bell_convergence_semilogy.png" src="_images/Bell_convergence_semilogy.png" />
<p class="caption"><span class="caption-text"><em>Convergence of least square approximation using basis function in terms of the Taylor, sinusoidal, Bernstein and Lagrange basis in a log plot</em></span></p>
</div>
<p>The following program computes the order of convergence for
the sines using the polynomial model <a class="reference internal" href="#eq-sec-approx-pol-model"><span class="std std-ref">(68)</span></a>
while the Bernstein approximation is estimates
in terms of model <a class="reference internal" href="#eq-sec-approx-exp-model"><span class="std std-ref">(69)</span></a>. We avoid to
compute estimates for the Taylor and Lagrange approximations as neither
the log-log plot nor the log plot demonstrated linear behavior.</p>
<p>[<strong>hpl 3</strong>: Any comment about the <code class="docutils literal"><span class="pre">regression_with_noise</span></code> function?]</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">N_values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
<span class="n">Taylor</span>     <span class="o">=</span> <span class="p">[</span><span class="mf">0.0983</span><span class="p">,</span> <span class="mf">0.00263</span><span class="p">,</span>  <span class="mf">7.83e-07</span><span class="p">,</span> <span class="mf">3.57e-10</span><span class="p">]</span>
<span class="n">Sinusoidal</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0027</span><span class="p">,</span> <span class="mf">0.00061</span><span class="p">,</span>  <span class="mf">0.00012</span><span class="p">,</span>  <span class="mf">2.17e-05</span><span class="p">]</span>
<span class="n">Bernstein</span>  <span class="o">=</span> <span class="p">[</span><span class="mf">0.0021</span><span class="p">,</span> <span class="mf">4.45e-05</span><span class="p">,</span> <span class="mf">8.73e-09</span><span class="p">,</span> <span class="mf">4.49e-15</span><span class="p">]</span>
<span class="n">Lagrange</span>   <span class="o">=</span> <span class="p">[</span><span class="mf">0.0021</span><span class="p">,</span> <span class="mf">4.45e-05</span><span class="p">,</span> <span class="mf">8.73e-09</span><span class="p">,</span> <span class="mf">2.45e-12</span><span class="p">]</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>

<span class="n">u</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">regression_with_noise</span><span class="p">(</span><span class="n">log2</span><span class="p">(</span><span class="n">Sinusoidal</span><span class="p">),</span> <span class="n">psi</span><span class="p">,</span> <span class="n">log2</span><span class="p">(</span><span class="n">N_values</span><span class="p">))</span>
<span class="k">print</span> <span class="s2">&quot;estimated model for sine: </span><span class="si">%3.2e</span><span class="s2">*N**(</span><span class="si">%3.2e</span><span class="s2">)&quot;</span> <span class="o">%</span> \
      <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Check the numbers estimated by the model by manual inspection</span>
<span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="n">N_values</span><span class="p">:</span>
    <span class="k">print</span> <span class="mi">2</span><span class="o">**</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">N</span><span class="o">**</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">u</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">regression_with_noise</span><span class="p">(</span><span class="n">log</span><span class="p">(</span><span class="n">Bernstein</span><span class="p">),</span> <span class="n">psi</span><span class="p">,</span> <span class="n">N_values</span><span class="p">)</span>
<span class="k">print</span> <span class="s2">&quot;estimated model for Bernstein: </span><span class="si">%3.2e</span><span class="s2">*exp(</span><span class="si">%3.2e</span><span class="s2">*N)&quot;</span> <span class="o">%</span> \
      <span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Check the numbers estimated by the model by manual inspection</span>
<span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="n">N_values</span><span class="p">:</span>
    <span class="k">print</span> <span class="n">exp</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">exp</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>The program estimates the sine approximation convergences as
<span class="math">\(1.43e-02\cdot N^{-2.3}\)</span>, which means that the convergence is slightly
above second order.  The Bernstein approximation on the other hand is
<span class="math">\(8.01e-02 \cdot \exp(-1.92e+00 N)\)</span>.</p>
<p>The CPU time in this example here would be significantly faster if the
algorithms were implemented in a compiled language like C/C++ or
Fortran and we should not be careful in drawing conclusion about the
efficiency of the different methods based on this example
alone. However, for completeness we include a log-log plot in Figure
<a class="reference internal" href="#fem-comp-bell-loglogfig"><span class="std std-ref">CPU timings of the approximation with the difference basis in a log-log plot</span></a> to illustrate the polynomial increase in
CPU time with respect to N.</p>
<div class="figure" id="id12">
<span id="fem-comp-bell-loglogfig"></span><img alt="_images/Bell_computations_loglog.png" src="_images/Bell_computations_loglog.png" />
<p class="caption"><span class="caption-text"><em>CPU timings of the approximation with the difference basis in a log-log plot</em></span></p>
</div>
<p>The complete code can be found in
<a class="reference external" href="http://tinyurl.com/znpudbt/convergence_rate_local.py">convergence_rate_local.py</a>.</p>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <center>
            <p class="logo"><a href="http://cbc.simula.no/" title="Go to Center for Biomedical Computing">
              <img class="logo" src="_static/cbc_logo.png" alt="Logo"/>
            </a></p>
            </center>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Interpolation</a><ul>
<li><a class="reference internal" href="#the-interpolation-or-collocation-principle">The interpolation (or collocation) principle</a><ul>
<li><a class="reference internal" href="#example-2">Example</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lagrange-polynomials">Lagrange polynomials</a><ul>
<li><a class="reference internal" href="#approximation-of-a-polynomial">Approximation of a polynomial</a></li>
<li><a class="reference internal" href="#successful-example">Successful example</a></li>
<li><a class="reference internal" href="#less-successful-example">Less successful example</a></li>
<li><a class="reference internal" href="#remedy-for-strong-oscillations">Remedy for strong oscillations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#bernstein-polynomials">Bernstein polynomials</a></li>
</ul>
</li>
<li><a class="reference internal" href="#approximation-properties-and-convergence-rates">Approximation properties and convergence rates</a></li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="._book005.html"
                        title="previous chapter">Orthogonal basis functions</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="._book007.html"
                        title="next chapter">Approximation of functions in higher dimensions</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/._book006.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="._book007.html" title="Approximation of functions in higher dimensions"
             >next</a> |</li>
        <li class="right" >
          <a href="._book005.html" title="Orthogonal basis functions"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Introduction to Numerical Methods for Variational Problems</a> &raquo;</li> 
      </ul>
    </div>
<div class="wrapper">
  <div class="footer">
    <a href="http://cbc.simula.no"><img src="_static/cbc_banner.png" width="100%"><a>
    <br />
    <br />
      &copy;2016, Hans Petter Langtangen, Kent-Andre Mardal. Released under CC Attribution 4.0 license.
  </div>
</div>

  </body>
</html>