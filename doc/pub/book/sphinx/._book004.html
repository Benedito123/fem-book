
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Approximation principles</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>

        <script src="http://sagecell.sagemath.org/static/jquery.min.js"></script>
        <script src="http://sagecell.sagemath.org/static/embedded_sagecell.js"></script>

        <script>sagecell.makeSagecell({inputLocation: ".sage"});</script>

        <style type="text/css">
                .sagecell .CodeMirror-scroll {
                        overflow-y: hidden;
                        overflow-x: auto;
                }
                .sagecell .CodeMirror {
                        height: auto;
                }
        </style>

    
    <link rel="top" title="Introduction to Numerical Methods for Variational Problems" href="index.html" />
    <link rel="next" title="Orthogonal basis functions" href="._book005.html" />
    <link rel="prev" title="Approximation of vectors" href="._book003.html" />
 
  
       <style type="text/css">
         div.admonition {
           background-color: whiteSmoke;
           border: 1px solid #bababa;
         }
       </style>
      </head>
    
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="._book005.html" title="Orthogonal basis functions"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="._book003.html" title="Approximation of vectors"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Introduction to Numerical Methods for Variational Problems</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="approximation-principles">
<span id="fem-approx-global"></span><h1>Approximation principles<a class="headerlink" href="#approximation-principles" title="Permalink to this headline">¶</a></h1>
<p id="index-0">Let <span class="math">\(V\)</span> be a function space spanned by a set of <em>basis functions</em>
<span class="math">\({\psi}_0,\ldots,{\psi}_N\)</span>,</p>
<div class="math">
\[V = \hbox{span}\,\{{\psi}_0,\ldots,{\psi}_N\},\]</div>
<p>such that any function <span class="math">\(u\in V\)</span> can be written as a linear
combination of the basis functions:</p>
<div class="math" id="eq-fem-approx-ufem">
\[\tag{30}
u = \sum_{j\in{\mathcal{I}_s}} c_j{\psi}_j{\thinspace .}\]</div>
<p>That is, we consider functions as vectors in a vector space - a
so-called function space - and we have a finite set of basis
functions that span the space just as basis vectors or unit vectors
span a vector space.</p>
<p>The index set <span class="math">\({\mathcal{I}_s}\)</span> is defined as <span class="math">\({\mathcal{I}_s} =\{0,\ldots,N\}\)</span> and is
from now on used
both for compact notation and for flexibility in the numbering of
elements in sequences.</p>
<p>For now, in this introduction, we shall look at functions of a
single variable <span class="math">\(x\)</span>:
<span class="math">\(u=u(x)\)</span>, <span class="math">\({\psi}_j={\psi}_j(x)\)</span>, <span class="math">\(j\in{\mathcal{I}_s}\)</span>. Later, we will almost
trivially extend the mathematical details
to functions of two- or three-dimensional physical spaces.
The approximation <a class="reference internal" href="#eq-fem-approx-ufem"><span class="std std-ref">(30)</span></a> is typically used
to discretize a problem in space. Other methods, most notably
finite differences, are common for time discretization, although the
form <a class="reference internal" href="#eq-fem-approx-ufem"><span class="std std-ref">(30)</span></a> can be used in time as well.</p>
<div class="section" id="the-least-squares-method-3">
<span id="fem-approx-ls"></span><h2>The least squares method<a class="headerlink" href="#the-least-squares-method-3" title="Permalink to this headline">¶</a></h2>
<p>Given a function <span class="math">\(f(x)\)</span>, how can we determine its best approximation
<span class="math">\(u(x)\in V\)</span>? A natural starting point is to apply the same reasoning
as we did for vectors in the section <a class="reference internal" href="._book003.html#fem-approx-vec-np1dim"><span class="std std-ref">Approximation of general vectors</span></a>. That is,
we minimize the distance between <span class="math">\(u\)</span> and <span class="math">\(f\)</span>. However, this requires
a norm for measuring distances, and a norm is most conveniently
defined through an
inner product. Viewing a function as a vector of infinitely
many point values, one for each value of <span class="math">\(x\)</span>, the inner product of
two arbitrary functions <span class="math">\(f(x)\)</span> and <span class="math">\(g(x)\)</span> could
intuitively be defined as the usual summation of
pairwise &#8220;components&#8221; (values), with summation replaced by integration:</p>
<div class="math">
\[(f,g) = \int f(x)g(x)\, {\, \mathrm{d}x}
{\thinspace .}\]</div>
<p>To fix the integration domain, we let <span class="math">\(f(x)\)</span> and <span class="math">\({\psi}_i(x)\)</span>
be defined for a domain <span class="math">\(\Omega\subset\mathbb{R}\)</span>.
The inner product of two functions <span class="math">\(f(x)\)</span> and <span class="math">\(g(x)\)</span> is then</p>
<div class="math" id="eq-fem-approx-ls-innerprod">
\[ \begin{align}\begin{aligned}\tag{31}
(f,g) = \int_\Omega f(x)g(x)\, {\, \mathrm{d}x}\\    {\thinspace .}\end{aligned}\end{align} \]</div>
<p>The distance between <span class="math">\(f\)</span> and any function <span class="math">\(u\in V\)</span> is simply
<span class="math">\(f-u\)</span>, and the squared norm of this distance is</p>
<div class="math" id="eq-fem-approx-ls-e">
\[\tag{32}
E = (f(x)-\sum_{j\in{\mathcal{I}_s}} c_j{\psi}_j(x), f(x)-\sum_{j\in{\mathcal{I}_s}} c_j{\psi}_j(x)){\thinspace .}\]</div>
<p>Note the analogy with <a class="reference internal" href="._book003.html#eq-fem-vec-gene"><span class="std std-ref">(21)</span></a>: the given function
<span class="math">\(f\)</span> plays the role of the given vector <span class="math">\(\boldsymbol{f}\)</span>, and the basis function
<span class="math">\({\psi}_i\)</span> plays the role of the basis vector <span class="math">\(\boldsymbol{\psi}_i\)</span>.
We can rewrite <a class="reference internal" href="#eq-fem-approx-ls-e"><span class="std std-ref">(32)</span></a>,
through similar steps as used for the result
<a class="reference internal" href="._book003.html#eq-fem-vec-gene"><span class="std std-ref">(21)</span></a>, leading to</p>
<div class="math" id="eq-auto10">
\[\tag{33}
E(c_i, \ldots, c_N) = (f,f) -2\sum_{j\in{\mathcal{I}_s}} c_j(f,{\psi}_i)
    + \sum_{p\in{\mathcal{I}_s}}\sum_{q\in{\mathcal{I}_s}} c_pc_q({\psi}_p,{\psi}_q){\thinspace .}\]</div>
<p>Minimizing this function of <span class="math">\(N+1\)</span> scalar variables
<span class="math">\(\left\{ {c}_i \right\}_{i\in{\mathcal{I}_s}}\)</span>, requires differentiation
with respect to <span class="math">\(c_i\)</span>, for all <span class="math">\(i\in{\mathcal{I}_s}\)</span>. The resulting
equations are very similar to those we had in the vector case,
and we hence end up with a
linear system of the form <a class="reference internal" href="._book003.html#eq-fem-approx-vec-np1dim-eqsys"><span class="std std-ref">(25)</span></a>, with
basically the same expressions:</p>
<div class="math" id="eq-fem-approx-aij">
\[\tag{34}
A_{i,j} = ({\psi}_i,{\psi}_j),\]</div>
<div class="math" id="eq-fem-approx-bi">
\[\tag{35}
b_i = (f,{\psi}_i){\thinspace .}\]</div>
<p>The only difference from
<a class="reference internal" href="._book003.html#eq-fem-approx-vec-np1dim-eqsys"><span class="std std-ref">(25)</span></a>
is that the inner product is defined in terms
of integration rather than summation.</p>
</div>
<div class="section" id="the-projection-or-galerkin-method">
<h2>The projection (or Galerkin) method<a class="headerlink" href="#the-projection-or-galerkin-method" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-1"></span><p id="index-2">As in the section <a class="reference internal" href="._book003.html#fem-approx-vec-np1dim"><span class="std std-ref">Approximation of general vectors</span></a>, the minimization of <span class="math">\((e,e)\)</span>
is equivalent to</p>
<div class="math" id="eq-fem-approx-galerkin">
\[\tag{36}
(e,v)=0,\quad\forall v\in V{\thinspace .}\]</div>
<p>This is known as a projection of a function <span class="math">\(f\)</span> onto the subspace <span class="math">\(V\)</span>.
We may also call it a Galerkin method for approximating functions.
Using the same reasoning as
in
<a class="reference internal" href="._book003.html#eq-fem-approx-vec-np1dim-galerkin"><span class="std std-ref">(28)</span></a>-<a class="reference internal" href="._book003.html#eq-fem-approx-vec-np1dim-galerkin0"><span class="std std-ref">(29)</span></a>,
it follows that <a class="reference internal" href="#eq-fem-approx-galerkin"><span class="std std-ref">(36)</span></a> is equivalent to</p>
<div class="math" id="eq-fem-approx-galerkin0">
\[\tag{37}
(e,{\psi}_i)=0,\quad i\in{\mathcal{I}_s}{\thinspace .}\]</div>
<p>Inserting <span class="math">\(e=f-u\)</span> in this equation and ordering terms, as in the
multi-dimensional vector case, we end up with a linear
system with a coefficient matrix <a class="reference internal" href="#eq-fem-approx-aij"><span class="std std-ref">(34)</span></a> and
right-hand side vector <a class="reference internal" href="#eq-fem-approx-bi"><span class="std std-ref">(35)</span></a>.</p>
<p>Whether we work with vectors in the plane, general vectors, or
functions in function spaces, the least squares principle and
the projection or Galerkin method are equivalent.</p>
</div>
<div class="section" id="example-on-linear-approximation">
<span id="fem-approx-global-linear"></span><h2>Example on linear approximation<a class="headerlink" href="#example-on-linear-approximation" title="Permalink to this headline">¶</a></h2>
<p>Let us apply the theory in the previous section to a simple problem:
given a parabola <span class="math">\(f(x)=10(x-1)^2-1\)</span> for <span class="math">\(x\in\Omega=[1,2]\)</span>, find
the best approximation <span class="math">\(u(x)\)</span> in the space of all linear functions:</p>
<div class="math">
\[V = \hbox{span}\,\{1, x\}{\thinspace .}\]</div>
<p>With our notation, <span class="math">\({\psi}_0(x)=1\)</span>, <span class="math">\({\psi}_1(x)=x\)</span>, and <span class="math">\(N=1\)</span>.
We seek</p>
<div class="math">
\[u=c_0{\psi}_0(x) + c_1{\psi}_1(x) = c_0 + c_1x,\]</div>
<p>where
<span class="math">\(c_0\)</span> and <span class="math">\(c_1\)</span> are found by solving a <span class="math">\(2\times 2\)</span> the linear system.
The coefficient matrix has elements</p>
<div class="math" id="eq-auto11">
\[\tag{38}
A_{0,0} = ({\psi}_0,{\psi}_0) = \int_1^21\cdot 1\, {\, \mathrm{d}x} = 1,\]</div>
<div class="math" id="eq-auto12">
\[\tag{39}
A_{0,1} = ({\psi}_0,{\psi}_1) = \int_1^2 1\cdot x\, {\, \mathrm{d}x} = 3/2,\]</div>
<div class="math" id="eq-auto13">
\[\tag{40}
A_{1,0} = A_{0,1} = 3/2,\]</div>
<div class="math" id="eq-auto14">
\[\tag{41}
A_{1,1} = ({\psi}_1,{\psi}_1) = \int_1^2 x\cdot x\,{\, \mathrm{d}x} = 7/3{\thinspace .}\]</div>
<p>The corresponding right-hand side is</p>
<div class="math" id="eq-auto15">
\[\tag{42}
b_1 = (f,{\psi}_0) = \int_1^2 (10(x-1)^2 - 1)\cdot 1 \, {\, \mathrm{d}x} = 7/3,\]</div>
<div class="math" id="eq-auto16">
\[\tag{43}
b_2 = (f,{\psi}_1) = \int_1^2 (10(x-1)^2 - 1)\cdot x\, {\, \mathrm{d}x} = 13/3{\thinspace .}\]</div>
<p>Solving the linear system results in</p>
<div class="math" id="eq-auto17">
\[\tag{44}
c_0 = -38/3,\quad c_1 = 10,\]</div>
<p>and consequently</p>
<div class="math" id="eq-auto18">
\[\tag{45}
u(x) = 10x - \frac{38}{3}{\thinspace .}\]</div>
<p>Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-linear"><span class="std std-ref">Best approximation of a parabola by a straight line</span></a> displays the
parabola and its best approximation in the space of all linear functions.</p>
<div class="figure" id="id1">
<span id="fem-approx-global-fig-parabola-linear"></span><a class="reference internal image-reference" href="_images/parabola_ls_linear.png"><img alt="_images/parabola_ls_linear.png" src="_images/parabola_ls_linear.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-text"><em>Best approximation of a parabola by a straight line</em></span></p>
</div>
</div>
<div class="section" id="implementation-of-the-least-squares-method">
<span id="fem-approx-global-ls-code"></span><h2>Implementation of the least squares method<a class="headerlink" href="#implementation-of-the-least-squares-method" title="Permalink to this headline">¶</a></h2>
<div class="section" id="symbolic-integration">
<h3>Symbolic integration<a class="headerlink" href="#symbolic-integration" title="Permalink to this headline">¶</a></h3>
<p>The linear system can be computed either symbolically or
numerically (a numerical integration rule is needed in the latter case).
Let us first compute the system and its solution symbolically, i.e.,
using classical &#8220;pen and paper&#8221; mathematics with symbols.
The Python package <code class="docutils literal"><span class="pre">sympy</span></code> can greatly help with this type of
mathematics, and will therefore be frequently used in this text.
Some basic familiarity with <code class="docutils literal"><span class="pre">sympy</span></code> is assumed, typically
<code class="docutils literal"><span class="pre">symbols</span></code>, <code class="docutils literal"><span class="pre">integrate</span></code>, <code class="docutils literal"><span class="pre">diff</span></code>, <code class="docutils literal"><span class="pre">expand</span></code>, and <code class="docutils literal"><span class="pre">simplify</span></code>. Much can be learned
by studying the many applications of <code class="docutils literal"><span class="pre">sympy</span></code> that will be presented.</p>
<p>Below is a function for symbolic computation of the linear system,
where <span class="math">\(f(x)\)</span> is given as a <code class="docutils literal"><span class="pre">sympy</span></code> expression <code class="docutils literal"><span class="pre">f</span></code> involving
the symbol <code class="docutils literal"><span class="pre">x</span></code>, <code class="docutils literal"><span class="pre">psi</span></code> is a list of expressions for <span class="math">\(\left\{ {{\psi}}_i \right\}_{i\in{\mathcal{I}_s}}\)</span>,
and <code class="docutils literal"><span class="pre">Omega</span></code> is a 2-tuple/list holding the limits of the domain <span class="math">\(\Omega\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sym</span>

<span class="k">def</span> <span class="nf">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
                                  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="c1"># Note: c is a sympy Matrix object, solution is in c[:,0]</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)):</span>
        <span class="n">u</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">,</span> <span class="n">c</span>
</pre></div>
</div>
<p>Observe that we exploit the symmetry of the coefficient matrix:
only the upper triangular part is computed. Symbolic integration, also in
<code class="docutils literal"><span class="pre">sympy</span></code>, is often time consuming, and (roughly) halving the
work has noticeable effect on the waiting time for the computations to
finish.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>We remark that the symbols in <code class="docutils literal"><span class="pre">sympy</span></code> are created and stored in
a symbol factory that is indexed by the expression used in the construction
and that repeated constructions from the same expression will not create
new objects. The following code illustrates the behavior of the
symbol factory:</p>
<div class="last highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x0</span> <span class="o">=</span> <span class="n">Symbol</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x1</span> <span class="o">=</span> <span class="n">Symbol</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">id</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span> <span class="o">==</span><span class="nb">id</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a0</span> <span class="o">=</span> <span class="mf">3.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a1</span> <span class="o">=</span> <span class="mf">3.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">id</span><span class="p">(</span><span class="n">a0</span><span class="p">)</span> <span class="o">==</span><span class="nb">id</span><span class="p">(</span><span class="n">a1</span><span class="p">)</span>
<span class="go">False</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="fall-back-on-numerical-integration">
<h3>Fall back on numerical integration<a class="headerlink" href="#fall-back-on-numerical-integration" title="Permalink to this headline">¶</a></h3>
<p>Obviously, <code class="docutils literal"><span class="pre">sympy</span></code> may fail to successfully integrate
<span class="math">\(\int_\Omega{\psi}_i{\psi}_j{\, \mathrm{d}x}\)</span>, and
especially <span class="math">\(\int_\Omega f{\psi}_i{\, \mathrm{d}x}\)</span>, symbolically.
Therefore, we should extend
the <code class="docutils literal"><span class="pre">least_squares</span></code> function such that it falls back on
numerical integration if the symbolic integration is unsuccessful.
In the latter case, the returned value from <code class="docutils literal"><span class="pre">sympy</span></code>&#8216;s
<code class="docutils literal"><span class="pre">integrate</span></code> function is an object of type <code class="docutils literal"><span class="pre">Integral</span></code>.
We can test on this type and utilize the <code class="docutils literal"><span class="pre">mpmath</span></code> module in
<code class="docutils literal"><span class="pre">sympy</span></code> to perform numerical integration of high precision.
Even when <code class="docutils literal"><span class="pre">sympy</span></code> manages to integrate symbolically, it can
take an undesirable long time. We therefore include an
argument <code class="docutils literal"><span class="pre">symbolic</span></code> that governs whether or not to try
symbolic integration. Here is a complete and
improved version of the previous function <code class="docutils literal"><span class="pre">least_squares</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
                <span class="n">I</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">symbolic</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sym</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
                <span class="c1"># Could not integrate symbolically,</span>
                <span class="c1"># fall back on numerical integration</span>
                <span class="n">integrand</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
                <span class="n">I</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>

        <span class="n">integrand</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">f</span>
        <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">symbolic</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sym</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>  <span class="c1"># symbolic solve</span>
    <span class="c1"># c is a sympy Matrix object, numbers are in c[i,0]</span>
    <span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">sym</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
    <span class="n">u</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">,</span> <span class="n">c</span>
</pre></div>
</div>
<p>The function is found in the file <code class="docutils literal"><span class="pre">approx1D.py</span></code>.</p>
</div>
<div class="section" id="plotting-the-approximation">
<h3>Plotting the approximation<a class="headerlink" href="#plotting-the-approximation" title="Permalink to this headline">¶</a></h3>
<p>Comparing the given <span class="math">\(f(x)\)</span> and the approximate <span class="math">\(u(x)\)</span> visually is done
by the following function, which utilizes <code class="docutils literal"><span class="pre">sympy</span></code>&#8216;s <code class="docutils literal"><span class="pre">lambdify</span></code> tool to
convert a <code class="docutils literal"><span class="pre">sympy</span></code> expression to a Python function for numerical
computations:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;tmp.pdf&#39;</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">f</span><span class="p">,</span> <span class="n">modules</span><span class="o">=</span><span class="s2">&quot;numpy&quot;</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">u</span><span class="p">,</span> <span class="n">modules</span><span class="o">=</span><span class="s2">&quot;numpy&quot;</span><span class="p">)</span>
    <span class="n">resolution</span> <span class="o">=</span> <span class="mi">401</span>  <span class="c1"># no of points in plot</span>
    <span class="n">xcoor</span>  <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">resolution</span><span class="p">)</span>
    <span class="n">exact</span>  <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">xcoor</span><span class="p">)</span>
    <span class="n">approx</span> <span class="o">=</span> <span class="n">u</span><span class="p">(</span><span class="n">xcoor</span><span class="p">)</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">xcoor</span><span class="p">,</span> <span class="n">approx</span><span class="p">)</span>
    <span class="n">hold</span><span class="p">(</span><span class="s1">&#39;on&#39;</span><span class="p">)</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">xcoor</span><span class="p">,</span> <span class="n">exact</span><span class="p">)</span>
    <span class="n">legend</span><span class="p">([</span><span class="s1">&#39;approximation&#39;</span><span class="p">,</span> <span class="s1">&#39;exact&#39;</span><span class="p">])</span>
    <span class="n">savefig</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal"><span class="pre">modules='numpy'</span></code> argument to <code class="docutils literal"><span class="pre">lambdify</span></code> is important
if there are mathematical functions, such as <code class="docutils literal"><span class="pre">sin</span></code> or <code class="docutils literal"><span class="pre">exp</span></code>
in the symbolic expressions in <code class="docutils literal"><span class="pre">f</span></code> or <code class="docutils literal"><span class="pre">u</span></code>, and these
mathematical functions are to be used with vector arguments, like
<code class="docutils literal"><span class="pre">xcoor</span></code> above.</p>
<p>Both the <code class="docutils literal"><span class="pre">least_squares</span></code> and <code class="docutils literal"><span class="pre">comparison_plot</span></code> functions are found in
the file <a class="reference external" href="http://tinyurl.com/znpudbt/approx1D.py">approx1D.py</a>.  The
<code class="docutils literal"><span class="pre">comparison_plot</span></code> function in this file is more advanced and flexible
than the simplistic version shown above.  The file <code class="docutils literal"><span class="pre">ex_approx1D.py</span></code>
applies the <code class="docutils literal"><span class="pre">approx1D</span></code> module to accomplish the forthcoming examples.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>We remind the reader that the code examples can be found in a
tarball at
<a class="reference external" href="http://hplgit.github.io/fem-book/doc/web/">http://hplgit.github.io/fem-book/doc/web/</a>.
The following command shows a useful way to search for code</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>Terminal&gt; find . -name <span class="s1">&#39;*.py&#39;</span> -exec grep least_squares <span class="o">{}</span> <span class="se">\;</span> -print
</pre></div>
</div>
<p>Here <code class="docutils literal"><span class="pre">'.'</span></code> specifies the directory for the search, <code class="docutils literal"><span class="pre">-name</span> <span class="pre">'*.py'</span></code> that
files with suffix <code class="docutils literal"><span class="pre">*.py</span></code> should be searched through while</p>
<div class="highlight-text"><div class="highlight"><pre><span></span>-exec grep least_squares {} \; -print
</pre></div>
</div>
<p class="last">means that all lines
containing the text <code class="docutils literal"><span class="pre">least_squares</span></code> should be printed to the screen.</p>
</div>
</div>
</div>
<div class="section" id="perfect-approximation">
<span id="fem-approx-global-exact1"></span><h2>Perfect approximation<a class="headerlink" href="#perfect-approximation" title="Permalink to this headline">¶</a></h2>
<p>Let us use the code above to recompute the problem from
the section <a class="reference internal" href="#fem-approx-global-linear"><span class="std std-ref">Example on linear approximation</span></a> where we want to approximate
a parabola. What happens if we add an element <span class="math">\(x^2\)</span> to the basis and test what
the best approximation is if <span class="math">\(V\)</span> is the space of all parabolic functions?
The answer is quickly found by running</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">approx1D</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">],</span> <span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">u</span>
<span class="go">10*x**2 - 20*x + 9</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">sym</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="go">10*x**2 - 20*x + 9</span>
</pre></div>
</div>
<p>Now, what if we use <span class="math">\({\psi}_i(x)=x^i\)</span> for <span class="math">\(i=0,1,\ldots,N=40\)</span>?
The output from <code class="docutils literal"><span class="pre">least_squares</span></code> gives <span class="math">\(c_i=0\)</span> for <span class="math">\(i&gt;2\)</span>, which
means that the method finds the perfect approximation.</p>
<p>In fact, we have a general result that
if <span class="math">\(f\in V\)</span>, the least squares and projection/Galerkin methods compute
the exact solution <span class="math">\(u=f\)</span>.
The proof is straightforward: if <span class="math">\(f\in V\)</span>, <span class="math">\(f\)</span> can be expanded in
terms of the basis functions, <span class="math">\(f=\sum_{j\in{\mathcal{I}_s}} d_j{\psi}_j\)</span>, for
some coefficients <span class="math">\(\left\{ {d}_j \right\}_{j\in{\mathcal{I}_s}}\)</span>,
and the right-hand side then has entries</p>
<div class="math">
\[b_i = (f,{\psi}_i) = \sum_{j\in{\mathcal{I}_s}} d_j({\psi}_j, {\psi}_i) = \sum_{j\in{\mathcal{I}_s}} d_jA_{i,j}
{\thinspace .}\]</div>
<p>The linear system <span class="math">\(\sum_jA_{i,j}c_j = b_i\)</span>, <span class="math">\(i\in{\mathcal{I}_s}\)</span>, is then</p>
<div class="math">
\[\sum_{j\in{\mathcal{I}_s}} c_jA_{i,j} = \sum_{j\in{\mathcal{I}_s}}d_jA_{i,j},
\quad i\in{\mathcal{I}_s},\]</div>
<p>which implies that <span class="math">\(c_i=d_i\)</span> for <span class="math">\(i\in{\mathcal{I}_s}\)</span>.</p>
</div>
<div class="section" id="the-regression-method">
<span id="fem-approx-global-regression"></span><h2>The regression method<a class="headerlink" href="#the-regression-method" title="Permalink to this headline">¶</a></h2>
<p>So far, the function to be approximated has been known in terms of
a formula <span class="math">\(f(x)\)</span>. Very often in applications, no formula is known, but
the function value is known at a set of points. If we use <span class="math">\(N+1\)</span> basis
functions and know exactly <span class="math">\(N+1\)</span> function values, we can determine the
coefficients <span class="math">\(c_i\)</span> by <em>interpolation</em> as explained in the section <a class="reference internal" href="._book006.html#fem-approx-global-interp"><span class="std std-ref">The interpolation (or collocation) principle</span></a>. The approximating function will then
equal the <span class="math">\(f\)</span> values at the points where the <span class="math">\(f\)</span> values are sampled.</p>
<p>However, one normally has <span class="math">\(f\)</span> sampled at a lot of points, here denoted
by <span class="math">\(x_{0},x_{1},\ldots,x_{m}\)</span>, and we assume <span class="math">\(m\gg N\)</span>. What can
we do then to determine the coefficients?  The answer is to find a
least squares approximation.  The resulting method is called
<em>regression</em> and is well known from statistics when fitting a simple
(usually polynomial) function to a set of data points.</p>
<div class="section" id="overdetermined-equation-system">
<h3>Overdetermined equation system<a class="headerlink" href="#overdetermined-equation-system" title="Permalink to this headline">¶</a></h3>
<p>Intuitively, we would demand <span class="math">\(u\)</span> to equal <span class="math">\(f\)</span> at all the
data points <span class="math">\(x_{i}\)</span>, <span class="math">\(i0,1,\ldots,m\)</span>,</p>
<div class="math" id="eq-auto19">
\[\tag{46}
u(x_{i}) = \sum_{j\in{\mathcal{I}_s}} c_j {\psi}_j(x_{i}) = f(x_{i}),
    \quad i=0,1,\ldots,m{\thinspace .}\]</div>
<p>The fundamental problem here is that we have more equations than
unknowns since there are <span class="math">\(N+1\)</span> unknowns and <span class="math">\(m+1&gt;N+1\)</span> equations.
Such a system of equations is called an <em>overdetermined system</em>.
We can write it in matrix form as</p>
<div class="math" id="eq-auto20">
\[\tag{47}
\sum_{j\in{\mathcal{I}_s}} A_{i,j}c_j = b_i,\quad i=0,1,\ldots,m,\]</div>
<p>with coefficient matrix and right-hand side vector given by</p>
<div class="math" id="eq-fem-approx-global-regression-aij">
\[\tag{48}
A_{i,j} = {\psi}_j(x_{i}),\]</div>
<div class="math" id="eq-fem-approx-global-regression-bi">
\[\tag{49}
b_i = f(x_{i}){\thinspace .}\]</div>
<p>Note that the matrix is a <em>rectangular</em> <span class="math">\((m+1)\times(N+1)\)</span>
matrix since <span class="math">\(i=0,\ldots,m\)</span> and <span class="math">\(j=0,\ldots,N\)</span>.</p>
</div>
<div class="section" id="the-normal-equations-derived-from-a-least-squares-principle">
<h3>The normal equations derived from a least squares principle<a class="headerlink" href="#the-normal-equations-derived-from-a-least-squares-principle" title="Permalink to this headline">¶</a></h3>
<p>The least squares method is a common technique for solving
overdetermined equations systems. Let us write the overdetermined
system <span class="math">\(\sum_{j\in{\mathcal{I}_s}} A_{i,j}c_j = b_i\)</span> more compactly in matrix form
as <span class="math">\(Ac=b\)</span>.  Since we have more equations than unknowns, it is (in
general) impossible to find a vector <span class="math">\(c\)</span> that fulfills <span class="math">\(Ac=b\)</span>. The
best we can do is to make the residual <span class="math">\(r=b-Ac\)</span> as small as
possible. That is, we can find <span class="math">\(c\)</span> such that it minimizes the norm
Euclidean norm of <span class="math">\(r\)</span>: <span class="math">\(||r||\)</span>.  The algebra simplifies significantly
by minimizing <span class="math">\(||r||^2\)</span> instead.  This principle corresponds to a
least squares method.</p>
<span class="target" id="index-3"></span><p id="index-4">The <span class="math">\(i\)</span>-th component of <span class="math">\(r\)</span> reads <span class="math">\(r_i = b_i -\sum_jA_{i,j}c_j\)</span>,
so <span class="math">\(||r||^2 = \sum_ir_i^2\)</span>.
Minimizing <span class="math">\(||r||^2\)</span> with respect to the unknowns <span class="math">\(c_0,\ldots,c_N\)</span>
implies that</p>
<div class="math" id="eq-fem-approx-global-regression-r2min">
\[\tag{50}
\frac{\partial}{\partial c_k}||r||^2=0,\quad k=0,\ldots,N,\]</div>
<p>which leads to</p>
<div class="math">
\[\frac{\partial}{\partial c_k}\sum_i r_i^2 =
\sum_i 2r_i\frac{\partial r_i}{\partial c_k}
=\sum_i 2r_i \frac{\partial}{\partial c_k}(b_i -\sum_jA_{i,j}c_j)
= 2\sum_i r_i(-A_{i,k}) = 0{\thinspace .}\]</div>
<p>By inserting <span class="math">\(r_i = b_i -\sum_jA_{i,j}c_j\)</span> in the last expression we
get</p>
<div class="math">
\[\sum_i\left(b_i -\sum_jA_{i,j}c_j\right)\left(-A_{i,k}\right)
= -\sum_i b_iA_{i,k} + \sum_j (\sum_i A_{i,j}A_{i,k})c_j = 0{\thinspace .}\]</div>
<p>Introducing the transpose of <span class="math">\(A\)</span>, <span class="math">\(A^T\)</span>, we know that <span class="math">\(A^T_{i,j}=A_{j,i}\)</span>.
Therefore, the expression <span class="math">\(\sum_i A_{i,j}A_{i,k}\)</span> can be written
as <span class="math">\(\sum_i A^T_{k,i}A_{i,j}\)</span> and be recognized as the formula for the
matrix-matrix product <span class="math">\(A^TA\)</span>. Also, <span class="math">\(\sum_i b_i A_{i,k}\)</span> can be written
<span class="math">\(\sum_i A^T_{k,i}b_i\)</span> and recognized as the matrix-vector product
<span class="math">\(A^Tb\)</span>. These observations imply that <a class="reference internal" href="#eq-fem-approx-global-regression-r2min"><span class="std std-ref">(50)</span></a>
is equivalent to the linear system</p>
<div class="math" id="eq-fem-approx-global-regression-normal1">
\[\tag{51}
\sum_j (\sum_i A^T_{k,i}A_{i,j})c_j=\sum_j(A^TA)_{k,j}
    c_j = \sum_i  A^T_{k,i}b_i=(A^Tb)_k,\quad k=0,\ldots,N,\]</div>
<p>or in matrix form,</p>
<div class="math" id="eq-fem-approx-global-regression-normal2">
\[\tag{52}
A^TA c = A^Tb{\thinspace .}\]</div>
<p>The equation system <a class="reference internal" href="#eq-fem-approx-global-regression-normal1"><span class="std std-ref">(51)</span></a> or
<a class="reference internal" href="#eq-fem-approx-global-regression-normal2"><span class="std std-ref">(52)</span></a> are known as the
<em>normal equations</em>.
With <span class="math">\(A\)</span> as an <span class="math">\((m+1)\times (N+1)\)</span> matrix, <span class="math">\(A^TA\)</span> becomes an <span class="math">\((N+1)\times (N+1)\)</span>
matrix, and <span class="math">\(A^Tb\)</span> becomes a vector of length <span class="math">\(N+1\)</span>. Often, <span class="math">\(m\gg N\)</span>,
so <span class="math">\(A^TA\)</span> is much smaller than <span class="math">\(A\)</span>.</p>
<p>Many prefer to write the linear system
<a class="reference internal" href="#eq-fem-approx-global-regression-normal1"><span class="std std-ref">(51)</span></a> on the standard form
<span class="math">\(\sum_j B_{i,j}c_j=d_i\)</span>, <span class="math">\(i=0,\ldots,N\)</span>.  We can easily do so by
exchanging the <span class="math">\(i\)</span> and <span class="math">\(k\)</span> index (<span class="math">\(i\leftrightarrow k\)</span>), <span class="math">\(\sum_i
A^T_{k,i}A_{i,j} = \sum_k A^T_{i,k}A_{k,j}\)</span>, and setting <span class="math">\(B_{i,j}=\sum_k
A^T_{i,k}A_{k,j}\)</span>. Similarly, we exchange <span class="math">\(i\)</span> and <span class="math">\(k\)</span> in the right-hand
side expression and get <span class="math">\(\sum_k A^T_{i,k}b_k = d_i\)</span>.  Expressing
<span class="math">\(B_{i,j}\)</span> and <span class="math">\(d_i\)</span> in terms of the <span class="math">\({\psi}_i\)</span> and <span class="math">\(x_{i}\)</span>, using
<a class="reference internal" href="#eq-fem-approx-global-regression-aij"><span class="std std-ref">(48)</span></a> and
<a class="reference internal" href="#eq-fem-approx-global-regression-bi"><span class="std std-ref">(49)</span></a>, we end up with the formulas</p>
<div class="math" id="eq-fem-approx-global-regression-bij">
\[\tag{53}
B_{i,j} = \sum_k A^T_{i,k}A_{k,j} = \sum_k A_{k,i}A_{k,j}
    =\sum_{k=0}^m{\psi}_i(x_{k}){\psi}_j(x_{k}),\]</div>
<div class="math" id="eq-fem-approx-global-regression-di">
\[\tag{54}
d_i =\sum_k A^T_{i,k}b_k = \sum_k A_{k,i}b_k =\sum_{k=0}^m
    {\psi}_i(x_{k})f(x_{k})\]</div>
</div>
<div class="section" id="implementation-1">
<h3>Implementation<a class="headerlink" href="#implementation-1" title="Permalink to this headline">¶</a></h3>
<p>The following function defines the matrix entries <span class="math">\(B_{i,j}\)</span> according
to <a class="reference internal" href="#eq-fem-approx-global-regression-bij"><span class="std std-ref">(53)</span></a> and the right-hand side
entries <span class="math">\(d_i\)</span> according
<a class="reference internal" href="#eq-fem-approx-global-regression-di"><span class="std std-ref">(54)</span></a>. Thereafter, it solves the
linear system <span class="math">\(\sum_jB_{i,j}c_j=d_i\)</span>.  The input data <code class="docutils literal"><span class="pre">f</span></code> and <code class="docutils literal"><span class="pre">psi</span></code>
hold <span class="math">\(f(x)\)</span> and <span class="math">\({\psi}_i\)</span>, <span class="math">\(i=0,\ldots,N\)</span>, as symbolic expression, but
since <span class="math">\(m\)</span> is thought to be much larger than <span class="math">\(N\)</span>, and there are loops
from <span class="math">\(0\)</span> to <span class="math">\(m\)</span>, we use numerical computing to speed up the
computations.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">regression</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
    <span class="c1"># Use numpy arrays and numerical computing</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Wrap psi and f in Python functions rather than expressions</span>
    <span class="c1"># so that we can evaluate psi at points[i]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">psi_sym</span> <span class="o">=</span> <span class="n">psi</span>  <span class="c1"># save symbolic expression</span>
    <span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="n">sym</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">f</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">j</span><span class="p">](</span><span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
        <span class="n">d</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">*</span><span class="n">f</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi_sym</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">,</span> <span class="n">c</span>
</pre></div>
</div>
</div>
<div class="section" id="example-1">
<h3>Example<a class="headerlink" href="#example-1" title="Permalink to this headline">¶</a></h3>
<p>We repeat the computational example from the section <a class="reference internal" href="._book006.html#fem-approx-global-interp"><span class="std std-ref">The interpolation (or collocation) principle</span></a>, but this time with many more
points. The parabola <span class="math">\(f(x)=10(x-1)^2-1\)</span> is to be approximated by a
linear function on <span class="math">\(\Omega=[1,2]\)</span>. We divide <span class="math">\(\Omega\)</span> into <span class="math">\(m+2\)</span>
intervals and use the inner <span class="math">\(m+1\)</span> points:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sym</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>
<span class="n">Omega</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">m_values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="c1"># Create m+3 points and use the inner m+1 points</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">m_values</span><span class="p">:</span>
    <span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">m</span><span class="o">+</span><span class="mi">3</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">u</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">regression</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
    <span class="n">comparison_plot</span><span class="p">(</span>
        <span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span>
        <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;parabola_by_regression_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">points</span><span class="o">=</span><span class="n">points</span><span class="p">,</span>
        <span class="n">points_legend</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%d</span><span class="s1"> interpolation points&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">legend_loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Figure <a class="reference internal" href="#fem-approx-global-linear-regression-fig1"><span class="std std-ref">Approximation of a parabola by a regression method with varying number of points</span></a> shows results for
<span class="math">\(m+1=2\)</span> (left), <span class="math">\(m+1=8\)</span> (middle), and <span class="math">\(m+1=64\)</span> (right) data points.
The approximating function is not so sensitive to the number of
points as long as they cover a significant part of the domain (the first 2 point approximation puts too much weight on the center,
while the 8 point approximation cover almost the entire
domain and produces a good approximation which is barely improved with 64 points):</p>
<div class="math">
\[\begin{split}\begin{align*}
u(x) &amp;= 10x - 13.2,\quad 2\hbox{ points}\\
u(x) &amp;= 10x - 12.7,\quad 8\hbox{ points}\\
u(x) &amp;= 10x - 12.7,\quad 64\hbox{ points}
\end{align*}\end{split}\]</div>
<div class="figure" id="id2">
<span id="fem-approx-global-linear-regression-fig1"></span><a class="reference internal image-reference" href="_images/parabola_by_regression.png"><img alt="_images/parabola_by_regression.png" src="_images/parabola_by_regression.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text"><em>Approximation of a parabola by a regression method with varying number of points</em></span></p>
</div>
<p>To explicitly make the link to classical regression in statistics, we
consider <span class="math">\(f=10(x-1)^2 - 1 + \epsilon\)</span>, where <span class="math">\(\epsilon\)</span> is a random,
normally distributed variable. The goal in classical regression is
to find the straight line that best fits the data points (in a least
squares sense). The only difference from the previous setup, is that
the <span class="math">\(f(x_{i})\)</span> values are based on a function formula, here <span class="math">\(10(x-1)^2-1\)</span>,
<em>plus</em> normally distributed noise.
Figure <a class="reference internal" href="#fem-approx-global-linear-regression-fig2"><span class="std std-ref">Approximation of a parabola with noise by a straight line</span></a> shows three sets of
data points, along with the original <span class="math">\(f(x)\)</span> function without noise, and
the straight line that is a least squares approximation to the data points.</p>
<div class="figure" id="id3">
<span id="fem-approx-global-linear-regression-fig2"></span><a class="reference internal image-reference" href="_images/noisy_parabola_by_linear_regression.png"><img alt="_images/noisy_parabola_by_linear_regression.png" src="_images/noisy_parabola_by_linear_regression.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text"><em>Approximation of a parabola with noise by a straight line</em></span></p>
</div>
<p>We can fit a parabola instead of a straight line, as done in
Figure <a class="reference internal" href="#fem-approx-global-linear-regression-fig3"><span class="std std-ref">Approximation of a parabola with noise by a parabola</span></a>. When <span class="math">\(m\)</span> becomes large,
the fitted parabola and the original parabola without noise become very close.</p>
<div class="figure" id="id4">
<span id="fem-approx-global-linear-regression-fig3"></span><a class="reference internal image-reference" href="_images/noisy_parabola_by_quadratic_regression.png"><img alt="_images/noisy_parabola_by_quadratic_regression.png" src="_images/noisy_parabola_by_quadratic_regression.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text"><em>Approximation of a parabola with noise by a parabola</em></span></p>
</div>
<p>The regression method is not much used for approximating differential
equations or a given function, but is central in uncertainty quantification
methods such as polynomial chaos expansions.</p>
<div class="admonition-the-residual-an-indirect-but-computationally-cheap-measure-of-the-error admonition">
<p class="first admonition-title">The residual: an indirect but computationally cheap measure of the error</p>
<p>When attempting to  solve
a system <span class="math">\(A c = b\)</span>, we may question how far off a vector <span class="math">\(c_0\)</span> is.
The error is clearly the difference between <span class="math">\(c\)</span> and <span class="math">\(c_0\)</span>, <span class="math">\(e=c-c_0\)</span>.
The vector <span class="math">\(c_0\)</span> is obviously the solution of the problem <span class="math">\(A c_0 = b_0\)</span>,
where <span class="math">\(b_0\)</span> is easily computable as the matrix vector product <span class="math">\(A c_0\)</span>.
The residual can be seen as the error of the input data, <span class="math">\(b - b_0\)</span>
and is defined</p>
<div class="math">
\[r = b - A c_0 .\]</div>
<p>Clearly, the error and the residual are related by</p>
<div class="math">
\[A e = r .\]</div>
<p>While the computation of the error requires inversion of <span class="math">\(A\)</span>,
which may be computationally expensive, the residual
is easily computable.</p>
<p class="last">[<strong>hpl 1</strong>: Here something is missing? What is actually the point? Try to insert a heading in the notice...]</p>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <center>
            <p class="logo"><a href="http://cbc.simula.no/" title="Go to Center for Biomedical Computing">
              <img class="logo" src="_static/cbc_logo.png" alt="Logo"/>
            </a></p>
            </center>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Approximation principles</a><ul>
<li><a class="reference internal" href="#the-least-squares-method-3">The least squares method</a></li>
<li><a class="reference internal" href="#the-projection-or-galerkin-method">The projection (or Galerkin) method</a></li>
<li><a class="reference internal" href="#example-on-linear-approximation">Example on linear approximation</a></li>
<li><a class="reference internal" href="#implementation-of-the-least-squares-method">Implementation of the least squares method</a><ul>
<li><a class="reference internal" href="#symbolic-integration">Symbolic integration</a></li>
<li><a class="reference internal" href="#fall-back-on-numerical-integration">Fall back on numerical integration</a></li>
<li><a class="reference internal" href="#plotting-the-approximation">Plotting the approximation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#perfect-approximation">Perfect approximation</a></li>
<li><a class="reference internal" href="#the-regression-method">The regression method</a><ul>
<li><a class="reference internal" href="#overdetermined-equation-system">Overdetermined equation system</a></li>
<li><a class="reference internal" href="#the-normal-equations-derived-from-a-least-squares-principle">The normal equations derived from a least squares principle</a></li>
<li><a class="reference internal" href="#implementation-1">Implementation</a></li>
<li><a class="reference internal" href="#example-1">Example</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="._book003.html"
                        title="previous chapter">Approximation of vectors</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="._book005.html"
                        title="next chapter">Orthogonal basis functions</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/._book004.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="._book005.html" title="Orthogonal basis functions"
             >next</a> |</li>
        <li class="right" >
          <a href="._book003.html" title="Approximation of vectors"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Introduction to Numerical Methods for Variational Problems</a> &raquo;</li> 
      </ul>
    </div>
<div class="wrapper">
  <div class="footer">
    <a href="http://cbc.simula.no"><img src="_static/cbc_banner.png" width="100%"><a>
    <br />
    <br />
      &copy;2016, Hans Petter Langtangen, Kent-Andre Mardal. Released under CC Attribution 4.0 license.
  </div>
</div>

  </body>
</html>