
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Variational forms for systems of PDEs</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>

        <script src="http://sagecell.sagemath.org/static/jquery.min.js"></script>
        <script src="http://sagecell.sagemath.org/static/embedded_sagecell.js"></script>

        <script>sagecell.makeSagecell({inputLocation: ".sage"});</script>

        <style type="text/css">
                .sagecell .CodeMirror-scroll {
                        overflow-y: hidden;
                        overflow-x: auto;
                }
                .sagecell .CodeMirror {
                        height: auto;
                }
        </style>

    
    <link rel="top" title="Introduction to Numerical Methods for Variational Problems" href="index.html" />
    <link rel="next" title="Systems of nonlinear algebraic equations" href="._book028.html" />
    <link rel="prev" title="Time-dependent variational forms" href="._book026.html" />
 
  
       <style type="text/css">
         div.admonition {
           background-color: whiteSmoke;
           border: 1px solid #bababa;
         }
       </style>
      </head>
    
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="._book028.html" title="Systems of nonlinear algebraic equations"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="._book026.html" title="Time-dependent variational forms"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Introduction to Numerical Methods for Variational Problems</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="variational-forms-for-systems-of-pdes">
<span id="ch-femsys"></span><h1>Variational forms for systems of PDEs<a class="headerlink" href="#variational-forms-for-systems-of-pdes" title="Permalink to this headline">¶</a></h1>
<p>Many mathematical models involve <span class="math">\(m+1\)</span> unknown functions
governed by a system of <span class="math">\(m+1\)</span> differential equations. In abstract form
we may denote the unknowns by <span class="math">\(u^{(0)},\ldots,
u^{(m)}\)</span> and write the governing equations as</p>
<div class="math">
\[\begin{split}\begin{align*}
\mathcal{L}_0(u^{(0)},\ldots,u^{(m)}) &amp;= 0,\\
&amp;\vdots\\
\mathcal{L}_{m}(u^{(0)},\ldots,u^{(m)}) &amp;= 0,
\end{align*}\end{split}\]</div>
<p>where <span class="math">\(\mathcal{L}_i\)</span> is some differential operator defining differential
equation number <span class="math">\(i\)</span>.</p>
<div class="section" id="variational-forms-3">
<span id="fem-sys-vform"></span><h2>Variational forms<a class="headerlink" href="#variational-forms-3" title="Permalink to this headline">¶</a></h2>
<p>There are basically two ways of formulating a variational form
for a system of differential equations. The first method treats
each equation independently as a scalar equation, while the other
method views the total system as a vector equation with a vector function
as unknown.</p>
<div class="section" id="sequence-of-scalar-pdes-formulation">
<h3>Sequence of scalar PDEs formulation<a class="headerlink" href="#sequence-of-scalar-pdes-formulation" title="Permalink to this headline">¶</a></h3>
<p>Let us start with the approach that treats one equation at a time.
We multiply equation number <span class="math">\(i\)</span> by
some test function <span class="math">\(v^{(i)}\in V^{(i)}\)</span> and integrate over the domain:</p>
<div class="math" id="eq-fem-sys-vform-1by1a">
\[\tag{310}
\int_\Omega \mathcal{L}^{(0)}(u^{(0)},\ldots,u^{(m)}) v^{(0)}{\, \mathrm{d}x} = 0,\]</div>
<div class="math" id="eq-auto128">
\[\tag{311}
\vdots\]</div>
<div class="math" id="eq-fem-sys-vform-1by1b">
\[ \begin{align}\begin{aligned}\tag{312}
\int_\Omega \mathcal{L}^{(m)}(u^{(0)},\ldots,u^{(m)}) v^{(m)}{\, \mathrm{d}x} = 0\\    {\thinspace .}\end{aligned}\end{align} \]</div>
<p>Terms with second-order derivatives may be integrated by parts, with
Neumann conditions inserted in boundary integrals.
Let</p>
<div class="math">
\[V^{(i)} = \hbox{span}\{{\psi}_0^{(i)},\ldots,{\psi}_{N_i}^{(i)}\},\]</div>
<p>such that</p>
<div class="math">
\[u^{(i)} = B^{(i)}(\boldsymbol{x}) + \sum_{j=0}^{N_i} c_j^{(i)} {\psi}_j^{(i)}(\boldsymbol{x}),\]</div>
<p>where <span class="math">\(B^{(i)}\)</span> is a boundary function to handle nonzero Dirichlet conditions.
Observe that different unknowns may live in different spaces with different
basis functions and numbers of degrees of freedom.</p>
<p>From the <span class="math">\(m\)</span> equations in the variational forms we can derive
<span class="math">\(m\)</span> coupled systems of algebraic equations for the
<span class="math">\(\Pi_{i=0}^{m} N_i\)</span> unknown coefficients <span class="math">\(c_j^{(i)}\)</span>, <span class="math">\(j=0,\ldots,N_i\)</span>,
<span class="math">\(i=0,\ldots,m\)</span>.</p>
</div>
<div class="section" id="vector-pde-formulation">
<h3>Vector PDE formulation<a class="headerlink" href="#vector-pde-formulation" title="Permalink to this headline">¶</a></h3>
<p>The alternative method for deriving a variational form for a system of
differential equations introduces a vector of unknown functions</p>
<div class="math">
\[\boldsymbol{u} = (u^{(0)},\ldots,u^{(m)}),\]</div>
<p>a vector of test functions</p>
<div class="math">
\[\boldsymbol{v} = (v^{(0)},\ldots,v^{(m)}),\]</div>
<p>with</p>
<div class="math">
\[\boldsymbol{u}, \boldsymbol{v} \in  \boldsymbol{V} = V^{(0)}\times \cdots \times V^{(m)}
{\thinspace .}\]</div>
<p>With nonzero Dirichlet conditions, we have a vector
<span class="math">\(\boldsymbol{B} = (B^{(0)},\ldots,B^{(m)})\)</span> with boundary functions and then
it is <span class="math">\(\boldsymbol{u} - \boldsymbol{B}\)</span> that lies in <span class="math">\(\boldsymbol{V}\)</span>, not <span class="math">\(\boldsymbol{u}\)</span> itself.</p>
<p>The governing system of differential equations is written</p>
<div class="math">
\[\boldsymbol{\mathcal{L}}(\boldsymbol{u} ) = 0,\]</div>
<p>where</p>
<div class="math">
\[\boldsymbol{\mathcal{L}}(\boldsymbol{u} ) = (\mathcal{L}^{(0)}(\boldsymbol{u}),\ldots, \mathcal{L}^{(m)}(\boldsymbol{u}))
{\thinspace .}\]</div>
<p>The variational form is derived by taking the inner product of
the vector of equations and the test function vector:</p>
<div class="math" id="eq-fem-sys-vform-inner">
\[\tag{313}
\int_\Omega \boldsymbol{\mathcal{L}}(\boldsymbol{u} )\cdot\boldsymbol{v} = 0\quad\forall\boldsymbol{v}\in\boldsymbol{V}{\thinspace .}\]</div>
<p>Observe that <a class="reference internal" href="#eq-fem-sys-vform-inner"><span class="std std-ref">(313)</span></a> is one scalar equation. To derive
systems of algebraic equations for the unknown coefficients in the
expansions of the unknown functions, one chooses <span class="math">\(m\)</span> linearly
independent <span class="math">\(\boldsymbol{v}\)</span> vectors to generate <span class="math">\(m\)</span> independent variational forms
from <a class="reference internal" href="#eq-fem-sys-vform-inner"><span class="std std-ref">(313)</span></a>.  The particular choice <span class="math">\(\boldsymbol{v} =
(v^{(0)},0,\ldots,0)\)</span> recovers <a class="reference internal" href="#eq-fem-sys-vform-1by1a"><span class="std std-ref">(310)</span></a>, <span class="math">\(\boldsymbol{v} =
(0,\ldots,0,v^{(m)}\)</span> recovers <a class="reference internal" href="#eq-fem-sys-vform-1by1b"><span class="std std-ref">(312)</span></a>, and <span class="math">\(\boldsymbol{v} =
(0,\ldots,0,v^{(i)},0,\ldots,0)\)</span> recovers the variational form number
<span class="math">\(i\)</span>, <span class="math">\(\int_\Omega \mathcal{L}^{(i)} v^{(i)}{\, \mathrm{d}x} =0\)</span>, in
<a class="reference internal" href="#eq-fem-sys-vform-1by1a"><span class="std std-ref">(310)</span></a>-<a class="reference internal" href="#eq-fem-sys-vform-1by1b"><span class="std std-ref">(312)</span></a>.</p>
</div>
</div>
<div class="section" id="a-worked-example">
<span id="fem-sys-ut-ex"></span><h2>A worked example<a class="headerlink" href="#a-worked-example" title="Permalink to this headline">¶</a></h2>
<p>We now consider a specific system of two partial differential equations
in two space dimensions:</p>
<div class="math" id="eq-fem-sys-wt-ex-weq">
\[\tag{314}
\mu \nabla^2 w = -\beta,\]</div>
<div class="math" id="eq-fem-sys-wt-ex-teq">
\[\tag{315}
\kappa\nabla^2 T = - \mu ||\nabla w||^2
    {\thinspace .}\]</div>
<p>The unknown functions <span class="math">\(w(x,y)\)</span> and <span class="math">\(T(x,y)\)</span> are defined in a domain <span class="math">\(\Omega\)</span>,
while <span class="math">\(\mu\)</span>, <span class="math">\(\beta\)</span>,
and <span class="math">\(\kappa\)</span> are given constants. The norm in
<a class="reference internal" href="#eq-fem-sys-wt-ex-teq"><span class="std std-ref">(315)</span></a> is the standard Euclidean norm:</p>
<div class="math">
\[||\nabla w||^2 = \nabla w\cdot\nabla w = w_x^2 + w_y^2
{\thinspace .}\]</div>
<p>The boundary conditions associated with
<a class="reference internal" href="#eq-fem-sys-wt-ex-weq"><span class="std std-ref">(314)</span></a>-<a class="reference internal" href="#eq-fem-sys-wt-ex-teq"><span class="std std-ref">(315)</span></a> are <span class="math">\(w=0\)</span> on
<span class="math">\(\partial\Omega\)</span> and <span class="math">\(T=T_0\)</span> on <span class="math">\(\partial\Omega\)</span>.
Each of the equations <a class="reference internal" href="#eq-fem-sys-wt-ex-weq"><span class="std std-ref">(314)</span></a> and <a class="reference internal" href="#eq-fem-sys-wt-ex-teq"><span class="std std-ref">(315)</span></a>
needs one condition at each point on the boundary.</p>
<p>The system <a class="reference internal" href="#eq-fem-sys-wt-ex-weq"><span class="std std-ref">(314)</span></a>-<a class="reference internal" href="#eq-fem-sys-wt-ex-teq"><span class="std std-ref">(315)</span></a> arises
from fluid flow in a straight pipe, with the <span class="math">\(z\)</span> axis in the direction
of the pipe. The domain <span class="math">\(\Omega\)</span> is a cross section of the pipe, <span class="math">\(w\)</span>
is the velocity in the <span class="math">\(z\)</span> direction, <span class="math">\(\mu\)</span>
is the viscosity of the fluid, <span class="math">\(\beta\)</span> is the pressure gradient along
the pipe, <span class="math">\(T\)</span> is the temperature,
and <span class="math">\(\kappa\)</span> is the heat conduction coefficient of the
fluid. The equation <a class="reference internal" href="#eq-fem-sys-wt-ex-weq"><span class="std std-ref">(314)</span></a> comes from the Navier-Stokes
equations, and <a class="reference internal" href="#eq-fem-sys-wt-ex-teq"><span class="std std-ref">(315)</span></a> follows from the energy equation.
The term <span class="math">\(- \mu ||\nabla w||^2\)</span> models heating of the fluid
due to internal friction.</p>
<p>Observe that the system <a class="reference internal" href="#eq-fem-sys-wt-ex-weq"><span class="std std-ref">(314)</span></a>-<a class="reference internal" href="#eq-fem-sys-wt-ex-teq"><span class="std std-ref">(315)</span></a> has
only a one-way coupling: <span class="math">\(T\)</span> depends on <span class="math">\(w\)</span>, but <span class="math">\(w\)</span> does not depend on
<span class="math">\(T\)</span>, because we can solve <a class="reference internal" href="#eq-fem-sys-wt-ex-weq"><span class="std std-ref">(314)</span></a> with respect
to <span class="math">\(w\)</span> and then <a class="reference internal" href="#eq-fem-sys-wt-ex-teq"><span class="std std-ref">(315)</span></a> with respect to <span class="math">\(T\)</span>.
Some may argue that this is not a real system of PDEs, but just two scalar
PDEs. Nevertheless, the one-way coupling
is convenient when comparing different variational forms
and different implementations.</p>
</div>
<div class="section" id="identical-function-spaces-for-the-unknowns">
<h2>Identical function spaces for the unknowns<a class="headerlink" href="#identical-function-spaces-for-the-unknowns" title="Permalink to this headline">¶</a></h2>
<p>Let us first apply the same function space <span class="math">\(V\)</span> for <span class="math">\(w\)</span> and <span class="math">\(T\)</span>
(or more precisely, <span class="math">\(w\in V\)</span> and <span class="math">\(T-T_0 \in V\)</span>).
With</p>
<div class="math">
\[V = \hbox{span}\{{\psi}_0(x,y),\ldots,{\psi}_N(x,y)\},\]</div>
<p>we write</p>
<div class="math" id="eq-fem-sys-wt-ex-sum">
\[\tag{316}
w = \sum_{j=0}^N c^{(w)}_j {\psi}_j,\quad T = T_0 + \sum_{j=0}^N c^{(T)}_j
    {\psi}_j{\thinspace .}\]</div>
<p>Note that <span class="math">\(w\)</span> and <span class="math">\(T\)</span> in <a class="reference internal" href="#eq-fem-sys-wt-ex-weq"><span class="std std-ref">(314)</span></a>-<a class="reference internal" href="#eq-fem-sys-wt-ex-teq"><span class="std std-ref">(315)</span></a>
denote the exact solution of the PDEs, while <span class="math">\(w\)</span> and <span class="math">\(T\)</span>
<a class="reference internal" href="#eq-fem-sys-wt-ex-sum"><span class="std std-ref">(316)</span></a> are the discrete functions that approximate
the exact solution. It should be clear from the context whether a
symbol means the exact or approximate solution, but when we need both
at the same time, we use a subscript e to denote the exact solution.</p>
<div class="section" id="variational-form-of-each-individual-pde">
<h3>Variational form of each individual PDE<a class="headerlink" href="#variational-form-of-each-individual-pde" title="Permalink to this headline">¶</a></h3>
<p>Inserting the expansions <a class="reference internal" href="#eq-fem-sys-wt-ex-sum"><span class="std std-ref">(316)</span></a>
in the governing PDEs, results in a residual in each equation,</p>
<div class="math" id="eq-fem-sys-wt-ex-weq-r">
\[\tag{317}
R_w = \mu \nabla^2 w + \beta,\]</div>
<div class="math" id="eq-fem-sys-wt-ex-teq-r">
\[\tag{318}
R_T = \kappa\nabla^2 T + \mu ||\nabla w||^2
    {\thinspace .}\]</div>
<p>A Galerkin method demands <span class="math">\(R_w\)</span> and <span class="math">\(R_T\)</span> do be orthogonal to <span class="math">\(V\)</span>:</p>
<div class="math">
\[\begin{split}\begin{align*}
\int_\Omega R_w v {\, \mathrm{d}x} &amp;=0\quad\forall v\in V,\\
\int_\Omega R_T v {\, \mathrm{d}x} &amp;=0\quad\forall v\in V
{\thinspace .}
\end{align*}\end{split}\]</div>
<p>Because of the Dirichlet conditions, <span class="math">\(v=0\)</span> on <span class="math">\(\partial\Omega\)</span>.
We integrate the Laplace terms by parts and note that the boundary terms
vanish since <span class="math">\(v=0\)</span> on <span class="math">\(\partial\Omega\)</span>:</p>
<div class="math" id="eq-fem-sys-wt-ex-w-vf1">
\[\tag{319}
\int_\Omega \mu \nabla w\cdot\nabla v {\, \mathrm{d}x} = \int_\Omega \beta v{\, \mathrm{d}x}
    \quad\forall v\in V,\]</div>
<div class="math" id="eq-fem-sys-wt-ex-t-vf1">
\[ \begin{align}\begin{aligned}\tag{320}
\int_\Omega \kappa \nabla T\cdot\nabla v {\, \mathrm{d}x} = \int_\Omega \mu
    \nabla w\cdot\nabla w\, v{\, \mathrm{d}x} \quad\forall v\in V\\    {\thinspace .}\end{aligned}\end{align} \]</div>
<p>The equation <span class="math">\(R_w\)</span> in <a class="reference internal" href="#eq-fem-sys-wt-ex-weq-r"><span class="std std-ref">(317)</span></a> is linear
in <span class="math">\(w\)</span>, while the equation <span class="math">\(R_T\)</span> in <a class="reference internal" href="#eq-fem-sys-wt-ex-teq-r"><span class="std std-ref">(318)</span></a>
is linear in <span class="math">\(T\)</span> and nonlinear in <span class="math">\(w\)</span>.</p>
</div>
<div class="section" id="compound-scalar-variational-form">
<h3>Compound scalar variational form<a class="headerlink" href="#compound-scalar-variational-form" title="Permalink to this headline">¶</a></h3>
<p>The alternative way of deriving the variational from is to
introduce a test vector function <span class="math">\(\boldsymbol{v}\in\boldsymbol{V} = V\times V\)</span> and take
the inner product of <span class="math">\(\boldsymbol{v}\)</span> and the residuals, integrated over the domain:</p>
<div class="math">
\[\int_{\Omega} (R_w, R_T)\cdot\boldsymbol{v} {\, \mathrm{d}x} = 0\quad\forall\boldsymbol{v}\in\boldsymbol{V}
{\thinspace .}\]</div>
<p>With <span class="math">\(\boldsymbol{v} = (v_0,v_1)\)</span> we get</p>
<div class="math">
\[\int_{\Omega} (R_w v_0 + R_T v_1) {\, \mathrm{d}x} = 0\quad\forall\boldsymbol{v}\in\boldsymbol{V}
{\thinspace .}\]</div>
<p>Integrating the Laplace terms by parts results in</p>
<div class="math" id="eq-fem-sys-wt-ex-wt-vf2">
\[\tag{321}
\int_\Omega (\mu\nabla w\cdot\nabla v_0 + \kappa\nabla T\cdot\nabla v_1){\, \mathrm{d}x}
    = \int_\Omega (\beta v_0 + \mu\nabla w\cdot\nabla w\, v_1){\, \mathrm{d}x},
    \quad\forall \boldsymbol{v}\in\boldsymbol{V}
    {\thinspace .}\]</div>
<p>Choosing <span class="math">\(v_0=v\)</span> and <span class="math">\(v_1=0\)</span> gives the variational form
<a class="reference internal" href="#eq-fem-sys-wt-ex-w-vf1"><span class="std std-ref">(319)</span></a>, while <span class="math">\(v_0=0\)</span> and <span class="math">\(v_1=v\)</span> gives
<a class="reference internal" href="#eq-fem-sys-wt-ex-t-vf1"><span class="std std-ref">(320)</span></a>.</p>
<p>With the inner product notation, <span class="math">\((p,q) = \int_\Omega pq{\, \mathrm{d}x}\)</span>, we
can alternatively write <a class="reference internal" href="#eq-fem-sys-wt-ex-w-vf1"><span class="std std-ref">(319)</span></a> and
<a class="reference internal" href="#eq-fem-sys-wt-ex-t-vf1"><span class="std std-ref">(320)</span></a> as</p>
<div class="math">
\[\begin{split}\begin{align*}
 (\mu\nabla w,\nabla v) &amp;= (\beta, v)
\quad\forall v\in V,\\
(\kappa \nabla T,\nabla v) &amp;= (\mu\nabla w\cdot\nabla w, v)\quad\forall v\in V,
\end{align*}\end{split}\]</div>
<p>or since <span class="math">\(\mu\)</span> and <span class="math">\(\kappa\)</span> are considered constant,</p>
<div class="math" id="eq-fem-sys-wt-ex-w-vf1i">
\[\tag{322}
\mu (\nabla w,\nabla v) = (\beta, v)
    \quad\forall v\in V,\]</div>
<div class="math" id="eq-fem-sys-wt-ex-t-vf1i">
\[ \begin{align}\begin{aligned}\tag{323}
\kappa(\nabla T,\nabla v) = \mu(\nabla w\cdot\nabla w, v)\quad\forall v\in V\\    {\thinspace .}\end{aligned}\end{align} \]</div>
<p>Note that the left-hand side of <a class="reference internal" href="#eq-fem-sys-wt-ex-w-vf1i"><span class="std std-ref">(322)</span></a> is
again linear in <span class="math">\(w\)</span>, the left-hand side
of <a class="reference internal" href="#eq-fem-sys-wt-ex-t-vf1i"><span class="std std-ref">(323)</span></a> is linear in <span class="math">\(T\)</span>
and the nonlinearity of <span class="math">\(w\)</span> appears in the right-hand side
of  <a class="reference internal" href="#eq-fem-sys-wt-ex-t-vf1i"><span class="std std-ref">(323)</span></a></p>
</div>
<div class="section" id="decoupled-linear-systems">
<h3>Decoupled linear systems<a class="headerlink" href="#decoupled-linear-systems" title="Permalink to this headline">¶</a></h3>
<p>The linear systems governing the coefficients <span class="math">\(c_j^{(w)}\)</span> and
<span class="math">\(c_j^{(T)}\)</span>, <span class="math">\(j=0,\ldots,N\)</span>, are derived by inserting the
expansions <a class="reference internal" href="#eq-fem-sys-wt-ex-sum"><span class="std std-ref">(316)</span></a> in <a class="reference internal" href="#eq-fem-sys-wt-ex-w-vf1"><span class="std std-ref">(319)</span></a>
and <a class="reference internal" href="#eq-fem-sys-wt-ex-t-vf1"><span class="std std-ref">(320)</span></a>, and choosing <span class="math">\(v={\psi}_i\)</span> for
<span class="math">\(i=0,\ldots,N\)</span>. The result becomes</p>
<div class="math" id="eq-fem-sys-wt-ex-linsys-w1">
\[\tag{324}
\sum_{j=0}^N A^{(w)}_{i,j} c^{(w)}_j = b_i^{(w)},\quad i=0,\ldots,N,\]</div>
<div class="math" id="eq-fem-sys-wt-ex-linsys-t1">
\[\tag{325}
\sum_{j=0}^N A^{(T)}_{i,j} c^{(T)}_j = b_i^{(T)},\quad i=0,\ldots,N,\]</div>
<div class="math" id="eq-auto129">
\[\tag{326}
A^{(w)}_{i,j} = \mu(\nabla {\psi}_j,\nabla {\psi}_i),\]</div>
<div class="math" id="eq-auto130">
\[\tag{327}
b_i^{(w)} = (\beta, {\psi}_i),\]</div>
<div class="math" id="eq-auto131">
\[\tag{328}
A^{(T)}_{i,j} = \kappa(\nabla {\psi}_j,\nabla {\psi}_i),\]</div>
<div class="math" id="eq-auto132">
\[\tag{329}
b_i^{(T)} = \mu((\sum_j c^{(w)}_j\nabla{\psi}_j)\cdot (\sum_k
    c^{(w)}_k\nabla{\psi}_k), {\psi}_i)
    {\thinspace .}\]</div>
<p>It can also be instructive to write the linear systems using matrices
and vectors. Define <span class="math">\(K\)</span> as the matrix corresponding to the Laplace
operator <span class="math">\(\nabla^2\)</span>. That is, <span class="math">\(K_{i,j} = (\nabla {\psi}_j,\nabla {\psi}_i)\)</span>.
Let us introduce the vectors</p>
<div class="math">
\[\begin{split}\begin{align*}
b^{(w)} &amp;= (b_0^{(w)},\ldots,b_{N}^{(w)}),\\
b^{(T)} &amp;= (b_0^{(T)},\ldots,b_{N}^{(T)}),\\
c^{(w)} &amp;= (c_0^{(w)},\ldots,c_{N}^{(w)}),\\
c^{(T)} &amp;= (c_0^{(T)},\ldots,c_{N}^{(T)}){\thinspace .}
\end{align*}\end{split}\]</div>
<p>The system <a class="reference internal" href="#eq-fem-sys-wt-ex-linsys-w1"><span class="std std-ref">(324)</span></a>-<a class="reference internal" href="#eq-fem-sys-wt-ex-linsys-t1"><span class="std std-ref">(325)</span></a>
can now be expressed in matrix-vector form as</p>
<div class="math" id="eq-auto133">
\[\tag{330}
\mu K c^{(w)} = b^{(w)},\]</div>
<div class="math" id="eq-auto134">
\[\tag{331}
\kappa K c^{(T)} = b^{(T)}{\thinspace .}\]</div>
<p>We can solve the first system for <span class="math">\(c^{(w)}\)</span>, and then
the right-hand side <span class="math">\(b^{(T)}\)</span> is known such that we can
solve the second system for <span class="math">\(c^{(T)}\)</span>. Hence, the
decoupling of the unknowns <span class="math">\(w\)</span> and <span class="math">\(T\)</span> reduces the
system of nonlinear PDEs to two linear PDEs.</p>
</div>
<div class="section" id="coupled-linear-systems">
<h3>Coupled linear systems<a class="headerlink" href="#coupled-linear-systems" title="Permalink to this headline">¶</a></h3>
<p>Despite the fact that <span class="math">\(w\)</span> can be computed first, without knowing <span class="math">\(T\)</span>,
we shall now pretend that <span class="math">\(w\)</span> and <span class="math">\(T\)</span> enter a two-way coupling such
that we need to derive the
algebraic equations as <em>one system</em> for all the unknowns
<span class="math">\(c_j^{(w)}\)</span> and <span class="math">\(c_j^{(T)}\)</span>, <span class="math">\(j=0,\ldots,N\)</span>. This system is
nonlinear in <span class="math">\(c_j^{(w)}\)</span> because of the <span class="math">\(\nabla w\cdot\nabla w\)</span> product.
To remove this nonlinearity, imagine that we introduce an iteration
method where we replace <span class="math">\(\nabla w\cdot\nabla w\)</span> by
<span class="math">\(\nabla w_{-}\cdot\nabla w\)</span>, <span class="math">\(w_{-}\)</span> being the <span class="math">\(w\)</span>
computed in the previous iteration. Then the term
<span class="math">\(\nabla w_{-}\cdot\nabla w\)</span> is linear in <span class="math">\(w\)</span> since <span class="math">\(w_{-}\)</span> is
known. The total linear system becomes</p>
<div class="math" id="eq-fem-sys-wt-ex-linsys-w2">
\[\tag{332}
\sum_{j=0}^N A^{(w,w)}_{i,j} c^{(w)}_j + \sum_{j=0}^N A^{(w,T)}_{i,j} c^{(T)}_j
    = b_i^{(w)},\quad i=0,\ldots,N,\]</div>
<div class="math" id="eq-fem-sys-wt-ex-linsys-t2">
\[\tag{333}
\sum_{j=0}^N A^{(T,w)}_{i,j} c^{(w)}_j + \sum_{j=0}^N A^{(T,T)}_{i,j} c^{(T)}_j = b_i^{(T)},\quad i=0,\ldots,N,\]</div>
<div class="math" id="eq-auto135">
\[\tag{334}
A^{(w,w)}_{i,j} = \mu(\nabla {\psi}_j,\nabla {\psi}_i),\]</div>
<div class="math" id="eq-auto136">
\[\tag{335}
A^{(w,T)}_{i,j} = 0,\]</div>
<div class="math" id="eq-auto137">
\[\tag{336}
b_i^{(w)} = (\beta, {\psi}_i),\]</div>
<div class="math" id="eq-auto138">
\[\tag{337}
A^{(w,T)}_{i,j} = \mu((\nabla w_{-})\cdot\nabla{\psi}_j), {\psi}_i),\]</div>
<div class="math" id="eq-auto139">
\[\tag{338}
A^{(T,T)}_{i,j} = \kappa(\nabla {\psi}_j,\nabla {\psi}_i),\]</div>
<div class="math" id="eq-auto140">
\[\tag{339}
b_i^{(T)} = 0
    {\thinspace .}\]</div>
<p>This system can alternatively be written in matrix-vector form as</p>
<div class="math" id="eq-auto141">
\[\tag{340}
\mu K c^{(w)} = b^{(w)},\]</div>
<div class="math" id="eq-auto142">
\[\tag{341}
L c^{(w)} + \kappa K c^{(T)}  =0,\]</div>
<p>with <span class="math">\(L\)</span> as the matrix from the <span class="math">\(\nabla w_{-}\cdot\nabla\)</span> operator:
<span class="math">\(L_{i,j} = A^{(w,T)}_{i,j}\)</span>. The matrix <span class="math">\(K\)</span> is <span class="math">\(K_{i,j} =
A^{(w,w)}_{i,j} = A^{(T,T)}_{i,j}\)</span>.</p>
<p>The matrix-vector equations are often conveniently written in block form:</p>
<div class="math">
\[\begin{split}\left(\begin{array}{cc}
\mu K &amp; 0\\
L &amp; \kappa K
\end{array}\right)
\left(\begin{array}{c}
c^{(w)}\\
c^{(T)}
\end{array}\right) =
\left(\begin{array}{c}
b^{(w)}\\
0
\end{array}\right),\end{split}\]</div>
<p>Note that in the general case where all unknowns enter all equations,
we have to solve the compound system
<a class="reference internal" href="#eq-fem-sys-wt-ex-linsys-w2"><span class="std std-ref">(332)</span></a>-<a class="reference internal" href="#eq-fem-sys-wt-ex-linsys-t2"><span class="std std-ref">(333)</span></a> since
then we cannot utilize the special property that
<a class="reference internal" href="#eq-fem-sys-wt-ex-linsys-w1"><span class="std std-ref">(324)</span></a> does not involve <span class="math">\(T\)</span> and can be solved
first.</p>
<p>When the viscosity depends on the temperature, the
<span class="math">\(\mu\nabla^2w\)</span> term must be replaced by <span class="math">\(\nabla\cdot (\mu(T)\nabla w)\)</span>,
and then <span class="math">\(T\)</span> enters the equation for <span class="math">\(w\)</span>. Now we have a two-way coupling
since both equations contain <span class="math">\(w\)</span> and <span class="math">\(T\)</span> and therefore
must be solved simultaneously.
The equation <span class="math">\(\nabla\cdot (\mu(T)\nabla w)=-\beta\)</span> is nonlinear,
and if some iteration procedure is invoked, where we use a previously
computed <span class="math">\(T_{-}\)</span> in the viscosity (<span class="math">\(\mu(T_{-})\)</span>), the coefficient is known,
and the equation involves only one unknown, <span class="math">\(w\)</span>. In that case we are
back to the one-way coupled set of PDEs.</p>
<p>We may also formulate our PDE system as a vector equation. To this end,
we introduce the vector of unknowns <span class="math">\(\boldsymbol{u} = (u^{(0)},u^{(1)})\)</span>,
where <span class="math">\(u^{(0)}=w\)</span> and <span class="math">\(u^{(1)}=T\)</span>. We then have</p>
<div class="math">
\[\begin{split}\nabla^2 \boldsymbol{u} = \left(\begin{array}{cc}
-{\mu}^{-1}{\beta}\\
-{\kappa}^{-1}\mu \nabla u^{(0)}\cdot\nabla u^{(0)}
\end{array}\right){\thinspace .}\end{split}\]</div>
</div>
</div>
<div class="section" id="different-function-spaces-for-the-unknowns">
<h2>Different function spaces for the unknowns<a class="headerlink" href="#different-function-spaces-for-the-unknowns" title="Permalink to this headline">¶</a></h2>
<p id="index-0">It is easy to generalize the previous formulation to the case where
<span class="math">\(w\in V^{(w)}\)</span> and <span class="math">\(T\in V^{(T)}\)</span>, where <span class="math">\(V^{(w)}\)</span> and <span class="math">\(V^{(T)}\)</span>
can be different spaces with different numbers of degrees of freedom.
For example, we may use quadratic basis functions for <span class="math">\(w\)</span> and linear
for <span class="math">\(T\)</span>. Approximation of the unknowns by different finite element
spaces is known as <em>mixed finite element methods</em>.</p>
<p>We write</p>
<div class="math">
\[\begin{split}\begin{align*}
V^{(w)} &amp;= \hbox{span}\{{\psi}_0^{(w)},\ldots,{\psi}_{N_w}^{(w)}\},\\
V^{(T)} &amp;= \hbox{span}\{{\psi}_0^{(T)},\ldots,{\psi}_{N_T}^{(T)}\}
{\thinspace .}
\end{align*}\end{split}\]</div>
<p>The next step is to
multiply <a class="reference internal" href="#eq-fem-sys-wt-ex-weq"><span class="std std-ref">(314)</span></a> by a test function <span class="math">\(v^{(w)}\in V^{(w)}\)</span>
and <a class="reference internal" href="#eq-fem-sys-wt-ex-teq"><span class="std std-ref">(315)</span></a> by a <span class="math">\(v^{(T)}\in V^{(T)}\)</span>, integrate by
parts and arrive at</p>
<div class="math" id="eq-fem-sys-wt-ex-w-vf3">
\[\tag{342}
\int_\Omega \mu \nabla w\cdot\nabla v^{(w)} {\, \mathrm{d}x} = \int_\Omega \beta v^{(w)}{\, \mathrm{d}x}
    \quad\forall v^{(w)}\in V^{(w)},\]</div>
<div class="math" id="eq-fem-sys-wt-ex-t-vf3">
\[ \begin{align}\begin{aligned}\tag{343}
\int_\Omega \kappa \nabla T\cdot\nabla v^{(T)} {\, \mathrm{d}x} = \int_\Omega \mu
    \nabla w\cdot\nabla w\, v^{(T)}{\, \mathrm{d}x} \quad\forall v^{(T)}\in V^{(T)}\\    {\thinspace .}\end{aligned}\end{align} \]</div>
<p>The compound scalar variational formulation applies a test vector function
<span class="math">\(\boldsymbol{v} = (v^{(w)}, v^{(T)})\)</span> and reads</p>
<div class="math" id="eq-fem-sys-wt-ex-wt-vf3">
\[\tag{344}
\int_\Omega (\mu\nabla w\cdot\nabla v^{(w)} +
    \kappa\nabla T\cdot\nabla v^{(T)}){\, \mathrm{d}x}
    = \int_\Omega (\beta v^{(w)} + \mu\nabla w\cdot\nabla w\, v^{(T)}){\, \mathrm{d}x},\]</div>
<p>valid <span class="math">\(\forall \boldsymbol{v}\in\boldsymbol{V} = V^{(w)}\times V^{(T)}\)</span>.</p>
<p>As earlier, we may decoupled the system in terms
of two linear PDEs as we did with
<a class="reference internal" href="#eq-fem-sys-wt-ex-linsys-w1"><span class="std std-ref">(324)</span></a>-<a class="reference internal" href="#eq-fem-sys-wt-ex-linsys-t1"><span class="std std-ref">(325)</span></a>
or linearize the coupled system by introducing the previous
iterate <span class="math">\(w_{-}\)</span> as in
<a class="reference internal" href="#eq-fem-sys-wt-ex-linsys-w2"><span class="std std-ref">(332)</span></a>-<a class="reference internal" href="#eq-fem-sys-wt-ex-linsys-t2"><span class="std std-ref">(333)</span></a>.
However, we need to distinguish between <span class="math">\({\psi}_i^{(w)}\)</span>
and <span class="math">\({\psi}_i^{(T)}\)</span>, and the range in the sums over <span class="math">\(j\)</span>
must match the number of degrees of freedom in the spaces <span class="math">\(V^{(w)}\)</span>
and <span class="math">\(V^{(T)}\)</span>. The formulas become</p>
<div class="math" id="eq-fem-sys-wt-ex-linsys-w1-mixed">
\[\tag{345}
\sum_{j=0}^{N_w} A^{(w)}_{i,j} c^{(w)}_j = b_i^{(w)},\quad i=0,\ldots,N_w,\]</div>
<div class="math" id="eq-fem-sys-wt-ex-linsys-t1-mixed">
\[\tag{346}
\sum_{j=0}^{N_T} A^{(T)}_{i,j} c^{(T)}_j = b_i^{(T)},\quad i=0,\ldots,N_T,\]</div>
<div class="math" id="eq-auto143">
\[\tag{347}
A^{(w)}_{i,j} = \mu(\nabla {\psi}_j^{(w)},\nabla {\psi}_i^{(w)}),\]</div>
<div class="math" id="eq-auto144">
\[\tag{348}
b_i^{(w)} = (\beta, {\psi}_i^{(w)}),\]</div>
<div class="math" id="eq-auto145">
\[\tag{349}
A^{(T)}_{i,j} = \kappa(\nabla {\psi}_j^{(T)},\nabla {\psi}_i^{(T)}),\]</div>
<div class="math" id="eq-auto146">
\[\tag{350}
b_i^{(T)} = \mu(\sum_{j=0}^{N_w} c^{(w)}_j\nabla{\psi}_j^{(w)})\cdot (\sum_{k=0}^{N_w}
    c^{(w)}_k\nabla{\psi}_k^{(w)}) , {\psi}_i^{(T)})
    {\thinspace .}\]</div>
<p>In the case we formulate one compound linear system involving
both <span class="math">\(c^{(w)}_j\)</span>, <span class="math">\(j=0,\ldots,N_w\)</span>, and <span class="math">\(c^{(T)}_j\)</span>, <span class="math">\(j=0,\ldots,N_T\)</span>,
<a class="reference internal" href="#eq-fem-sys-wt-ex-linsys-w2"><span class="std std-ref">(332)</span></a>-<a class="reference internal" href="#eq-fem-sys-wt-ex-linsys-t2"><span class="std std-ref">(333)</span></a>
becomes</p>
<div class="math" id="eq-fem-sys-wt-ex-linsys-w2b">
\[\tag{351}
\sum_{j=0}^{N_w} A^{(w,w)}_{i,j} c^{(w)}_j + \sum_{j=0}^{N_T} A^{(w,T)}_{i,j} c^{(T)}_j
    = b_i^{(w)},\quad i=0,\ldots,N_w,\]</div>
<div class="math" id="eq-fem-sys-wt-ex-linsys-t2b">
\[\tag{352}
\sum_{j=0}^{N_w} A^{(T,w)}_{i,j} c^{(w)}_j + \sum_{j=0}^{N_T} A^{(T,T)}_{i,j} c^{(T)}_j = b_i^{(T)},\quad i=0,\ldots,N_T,\]</div>
<div class="math" id="eq-auto147">
\[\tag{353}
A^{(w,w)}_{i,j} = \mu(\nabla {\psi}_j^{(w)},\nabla {\psi}_i^{(w)}),\]</div>
<div class="math" id="eq-auto148">
\[\tag{354}
A^{(w,T)}_{i,j} = 0,\]</div>
<div class="math" id="eq-auto149">
\[\tag{355}
b_i^{(w)} = (\beta, {\psi}_i^{(w)}),\]</div>
<div class="math" id="eq-auto150">
\[\tag{356}
A^{(w,T)}_{i,j} = \mu (\nabla w_{-}\cdot\nabla{\psi}_j^{(w)}), {\psi}_i^{(T)}),\]</div>
<div class="math" id="eq-auto151">
\[\tag{357}
A^{(T,T)}_{i,j} = \kappa(\nabla {\psi}_j^{(T)},\nabla {\psi}_i^{(T)}),\]</div>
<div class="math" id="eq-auto152">
\[\tag{358}
b_i^{(T)} = 0
    {\thinspace .}\]</div>
<p>Here, we have again performed a linearization by employing a previous iterate <span class="math">\(w_{-}\)</span>.
The corresponding block form</p>
<div class="math">
\[\begin{split}\left(\begin{array}{cc}
\mu K^{(w)} &amp; 0\\
L &amp; \kappa K^{(T)}
\end{array}\right)
\left(\begin{array}{c}
c^{(w)}\\
c^{(T)}
\end{array}\right) =
\left(\begin{array}{c}
b^{(w)}\\
0
\end{array}\right),\end{split}\]</div>
<p>has square and rectangular block matrices: <span class="math">\(K^{(w)}\)</span> is <span class="math">\(N_w\times N_w\)</span>,
<span class="math">\(K^{(T)}\)</span> is <span class="math">\(N_T\times N_T\)</span>, while <span class="math">\(L\)</span> is <span class="math">\(N_T\times N_w\)</span>,</p>
</div>
<div class="section" id="computations-in-1d">
<span id="femsys-cooling-1d"></span><h2>Computations in 1D<a class="headerlink" href="#computations-in-1d" title="Permalink to this headline">¶</a></h2>
<p>We can reduce the system <a class="reference internal" href="#eq-fem-sys-wt-ex-weq"><span class="std std-ref">(314)</span></a>-<a class="reference internal" href="#eq-fem-sys-wt-ex-teq"><span class="std std-ref">(315)</span></a>
to one space dimension, which corresponds to flow in a channel between
two flat plates. Alternatively, one may consider flow in a circular
pipe, introduce cylindrical coordinates, and utilize the radial symmetry
to reduce the equations to a one-dimensional problem in the radial
coordinate. The former model becomes</p>
<div class="math" id="eq-fem-sys-wt-ex1d-weq">
\[\tag{359}
\mu w_{xx} = -\beta,\]</div>
<div class="math" id="eq-fem-sys-wt-ex1d-teq">
\[\tag{360}
\kappa T_{xx} = - \mu w_x^2,\]</div>
<p>while the model in the radial coordinate <span class="math">\(r\)</span> reads</p>
<div class="math" id="eq-fem-sys-wt-ex1dr-weq">
\[\tag{361}
\mu\frac{1}{r}\frac{d}{dr}\left( r\frac{dw}{dr}\right) = -\beta,\]</div>
<div class="math" id="eq-fem-sys-wt-ex1dr-teq">
\[\tag{362}
\kappa \frac{1}{r}\frac{d}{dr}\left( r\frac{dT}{dr}\right) = - \mu \left(
    \frac{dw}{dr}\right)^2
    {\thinspace .}\]</div>
<p>The domain for <a class="reference internal" href="#eq-fem-sys-wt-ex1d-weq"><span class="std std-ref">(359)</span></a>-<a class="reference internal" href="#eq-fem-sys-wt-ex1d-teq"><span class="std std-ref">(360)</span></a>
is <span class="math">\(\Omega = [0,H]\)</span>, with boundary conditions <span class="math">\(w(0)=w(H)=0\)</span> and
<span class="math">\(T(0)=T(H)=T_0\)</span>. For
<a class="reference internal" href="#eq-fem-sys-wt-ex1dr-weq"><span class="std std-ref">(361)</span></a>-<a class="reference internal" href="#eq-fem-sys-wt-ex1dr-teq"><span class="std std-ref">(362)</span></a> the domain
is <span class="math">\([0,R]\)</span> (<span class="math">\(R\)</span> being the radius of the pipe) and the boundary
conditions are <span class="math">\(du/dr = dT/dr =0\)</span> for <span class="math">\(r=0\)</span>, <span class="math">\(u(R)=0\)</span>, and <span class="math">\(T(R)=T_0\)</span>.</p>
<p>The exact solutions, <span class="math">\(w_e\)</span> and <span class="math">\(T_e\)</span>,  to <a class="reference internal" href="#eq-fem-sys-wt-ex1d-weq"><span class="std std-ref">(359)</span></a>
and <a class="reference internal" href="#eq-fem-sys-wt-ex1d-teq"><span class="std std-ref">(360)</span></a> are computed
as</p>
<div class="math">
\[\begin{split}\begin{align*}
w_{e,x} &amp;= - \int \frac{\beta}{\mu} {\, \mathrm{d}x} + C_w, \\
w_e &amp;= \int w_x {\, \mathrm{d}x} + D_w, \\
T_{e,x} &amp;= - \int \mu w_x^2 {\, \mathrm{d}x} + C_T,\\
w_e &amp;= \int w_x {\, \mathrm{d}x} + D_T, \\
\end{align*}\end{split}\]</div>
<p>where we determine the constants <span class="math">\(C_w\)</span>, <span class="math">\(D_w\)</span>, <span class="math">\(C_T\)</span>, and <span class="math">\(D_T\)</span>
by the boundary conditions <span class="math">\(w(0)=w(H)=0\)</span> and
<span class="math">\(T(0)=T(H)=T_0\)</span>. The calculations
may be performed in  <code class="docutils literal"><span class="pre">sympy</span></code> as</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sym</span>

<span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">T0</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s2">&quot;x mu beta k H C D T0&quot;</span><span class="p">)</span>
<span class="n">wx</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="o">-</span><span class="n">beta</span><span class="o">/</span><span class="n">mu</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">+</span> <span class="n">C</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">wx</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">D</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">solve</span><span class="p">([</span><span class="n">w</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">-</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># x=0 condition</span>
               <span class="n">w</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">H</span><span class="p">)</span><span class="o">-</span><span class="mi">0</span><span class="p">],</span>  <span class="c1"># x=H condition</span>
               <span class="p">[</span><span class="n">C</span><span class="p">,</span> <span class="n">D</span><span class="p">])</span>       <span class="c1"># unknowns</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">])</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="n">D</span><span class="p">])</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">sym</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>

<span class="n">Tx</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="o">-</span><span class="n">mu</span><span class="o">*</span><span class="n">sym</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">C</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">Tx</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">D</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">solve</span><span class="p">([</span><span class="n">T</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">-</span><span class="n">T0</span><span class="p">,</span>  <span class="c1"># x=0 condition</span>
               <span class="n">T</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span><span class="o">-</span><span class="n">T0</span><span class="p">],</span>  <span class="c1"># x=H condition</span>
               <span class="p">[</span><span class="n">C</span><span class="p">,</span> <span class="n">D</span><span class="p">])</span>       <span class="c1"># unknowns</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">])</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="n">D</span><span class="p">])</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">sym</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">T</span><span class="p">))</span>
</pre></div>
</div>
<p>We find that the solutions are</p>
<div class="math">
\[\begin{split}\begin{align*}
w_e(x) &amp;= \frac{\beta x}{2 \mu} \left(H - x\right), \\
T_e(x) &amp;= \frac{\beta^{2}}{\mu} \left(\frac{H^{3} x}{24}  - \frac{H^{2}}{8} x^{2} + \frac{H}{6} x^{3} - \frac{ x^{4}}{12}\right)  + T_{0} {\thinspace .}
\end{align*}\end{split}\]</div>
<p>The figure <a class="reference internal" href="#femsys-cooling-w-plot"><span class="std std-ref">The solution  \( w \)  of :ref:`(359) &lt;Eq:fem:sys:wT:ex1D:weq&gt;` with  \( beta=mu=1 \)  for different mesh resolutions</span></a> shows <span class="math">\(w\)</span> computed by the finite element method using the  decoupled
approach with P1 elements,
that is; implementing <a class="reference internal" href="#eq-fem-sys-wt-ex-linsys-w1"><span class="std std-ref">(324)</span></a>. The analytical solution <span class="math">\(w_e\)</span> is a quadratic
polynomial.  The linear finite elements result in a poor approximation on the
coarse meshes, <span class="math">\(N=2\)</span> and <span class="math">\(N=4\)</span>, but the approximation
improves fast and already at <span class="math">\(N=8\)</span> the
approximation appears adequate.
The figure <a class="reference internal" href="#femsys-cooling-w-plot"><span class="std std-ref">The solution  \( w \)  of :ref:`(359) &lt;Eq:fem:sys:wT:ex1D:weq&gt;` with  \( beta=mu=1 \)  for different mesh resolutions</span></a> shows the approximation of <span class="math">\(T\)</span> and also here
we see that the fourth order polynomial is poorly approximated at coarse resolution, but
that the approximation quickly improves.</p>
<div class="figure" id="id4">
<span id="femsys-cooling-w-plot"></span><a class="reference internal image-reference" href="_images/cooling_w.png"><img alt="_images/cooling_w.png" src="_images/cooling_w.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text"><em>The solution  \( w \)  of :ref:`(359) &lt;Eq:fem:sys:wT:ex1D:weq&gt;` with  \( beta=mu=1 \)  for different mesh resolutions</em></span></p>
</div>
<p>The figure <a class="reference internal" href="#femsys-cooling-w-plot"><span class="std std-ref">The solution  \( w \)  of :ref:`(359) &lt;Eq:fem:sys:wT:ex1D:weq&gt;` with  \( beta=mu=1 \)  for different mesh resolutions</span></a> shows <span class="math">\(T\)</span> for different resolutions. The same tendency is apparent
although the coarse grid solutions are worse for <span class="math">\(T\)</span> than for <span class="math">\(w\)</span>. The solutions at <span class="math">\(N=16\)</span> and <span class="math">\(N=32\)</span>, however,
appear almost identical.</p>
<div class="figure" id="id5">
<span id="femsys-cooling-t-plot"></span><a class="reference internal image-reference" href="_images/cooling_T.png"><img alt="_images/cooling_T.png" src="_images/cooling_T.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text">The solution <span class="math">\(T\)</span> of <a class="reference internal" href="#eq-fem-sys-wt-ex1d-teq"><span class="std std-ref">(360)</span></a> for <span class="math">\(\kappa=H=1\)</span></span></p>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">boundary</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">DOLFIN_EPS</span> <span class="ow">or</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">DOLFIN_EPS</span>

<span class="kn">from</span> <span class="nn">dolfin</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="n">Ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
<span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="n">Ns</span><span class="p">:</span>
    <span class="n">mesh</span> <span class="o">=</span> <span class="n">UnitIntervalMesh</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">V</span> <span class="o">=</span> <span class="n">FunctionSpace</span><span class="p">(</span><span class="n">mesh</span><span class="p">,</span> <span class="s2">&quot;Lagrange&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">TrialFunction</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">TestFunction</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>

    <span class="n">beta</span> <span class="o">=</span> <span class="n">Constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">Constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">bc</span> <span class="o">=</span> <span class="n">DirichletBC</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">Constant</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">boundary</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">mu</span><span class="o">*</span><span class="n">inner</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">grad</span><span class="p">(</span><span class="n">v</span><span class="p">))</span><span class="o">*</span><span class="n">dx</span>
    <span class="n">L</span> <span class="o">=</span> <span class="o">-</span><span class="n">beta</span><span class="o">*</span><span class="n">v</span><span class="o">*</span><span class="n">dx</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">Function</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
    <span class="n">solve</span><span class="p">(</span><span class="n">a</span> <span class="o">==</span> <span class="n">L</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">bc</span><span class="p">)</span>

    <span class="n">T0</span> <span class="o">=</span> <span class="n">Constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">kappa</span> <span class="o">=</span> <span class="n">Constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">bc</span> <span class="o">=</span> <span class="n">DirichletBC</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">T0</span><span class="p">,</span> <span class="n">boundary</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">kappa</span><span class="o">*</span><span class="n">inner</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">grad</span><span class="p">(</span><span class="n">v</span><span class="p">))</span><span class="o">*</span><span class="n">dx</span>
    <span class="n">L</span> <span class="o">=</span> <span class="o">-</span><span class="n">mu</span><span class="o">*</span><span class="n">inner</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">w</span><span class="p">),</span> <span class="n">grad</span><span class="p">(</span><span class="n">w</span><span class="p">))</span><span class="o">*</span><span class="n">v</span><span class="o">*</span><span class="n">dx</span>

    <span class="n">T</span> <span class="o">=</span> <span class="n">Function</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
    <span class="n">solve</span><span class="p">(</span><span class="n">a</span> <span class="o">==</span> <span class="n">L</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">bc</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">V</span><span class="o">.</span><span class="n">dofmap</span><span class="p">()</span><span class="o">.</span><span class="n">tabulate_all_coordinates</span><span class="p">(</span><span class="n">mesh</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">vector</span><span class="p">()</span><span class="o">.</span><span class="n">array</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hold</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;N=</span><span class="si">%d</span><span class="s2">&quot;</span><span class="o">%</span><span class="n">N</span> <span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="n">Ns</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Most of the FEniCS code should be familiar to the reader, but
we remark that we use the function <code class="docutils literal"><span class="pre">V.dofmap().tabulate_all_coordinates(mesh)</span></code> to obtain the coordinates of the nodal points. This is a general
function that works for any finite element implemented in
FEniCS and also in a parallel setting.</p>
<p>[<strong>kam 24</strong>: do not need extensive description as it should be covered elsewhere]</p>
<p>The calculations for <a class="reference internal" href="#eq-fem-sys-wt-ex1dr-weq"><span class="std std-ref">(361)</span></a>
and <a class="reference internal" href="#eq-fem-sys-wt-ex1dr-teq"><span class="std std-ref">(362)</span></a> are similar.
The <code class="docutils literal"><span class="pre">sympy</span></code> code</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sym</span>

<span class="n">r</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s2">&quot;r R&quot;</span><span class="p">)</span>
<span class="n">rwr</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">beta</span><span class="o">/</span><span class="n">mu</span><span class="p">)</span><span class="o">*</span><span class="n">r</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="o">+</span> <span class="n">C</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">rwr</span><span class="o">/</span><span class="n">r</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="o">+</span> <span class="n">D</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">solve</span><span class="p">([</span><span class="n">sym</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">r</span><span class="p">)</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">-</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># r=0 condition</span>
               <span class="n">w</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">r</span><span class="p">,</span><span class="n">R</span><span class="p">)</span><span class="o">-</span><span class="mi">0</span><span class="p">],</span>              <span class="c1"># r=R condition</span>
               <span class="p">[</span><span class="n">C</span><span class="p">,</span> <span class="n">D</span><span class="p">])</span>                      <span class="c1"># unknowns</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">])</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="n">D</span><span class="p">])</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">sym</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>

<span class="n">rTr</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="o">-</span><span class="n">mu</span><span class="o">*</span><span class="n">sym</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">r</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">r</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="o">+</span> <span class="n">C</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">rTr</span><span class="o">/</span><span class="n">r</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="o">+</span> <span class="n">D</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">solve</span><span class="p">([</span><span class="n">sym</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">r</span><span class="p">)</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">-</span><span class="n">T0</span><span class="p">,</span>  <span class="c1"># r=0 condition</span>
               <span class="n">T</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">R</span><span class="p">)</span><span class="o">-</span><span class="n">T0</span><span class="p">],</span>             <span class="c1"># r=R condition</span>
               <span class="p">[</span><span class="n">C</span><span class="p">,</span> <span class="n">D</span><span class="p">])</span>                       <span class="c1"># unknowns</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">])</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="n">D</span><span class="p">])</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">sym</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">T</span><span class="p">))</span>
</pre></div>
</div>
<p>and we obtain the solutions</p>
<div class="math">
\[\begin{split}\begin{align*}
w(r) &amp;= \frac{\beta \left(R^{2} - r^{2}\right)}{4 \mu}, \\
T(r) &amp;= \frac{1}{64 \mu} \left(R^{4} \beta^{2} + 64 T_{0} \mu - \beta^{2} r^{4}\right){\thinspace .}
\end{align*}\end{split}\]</div>
<p>[<strong>kam 25</strong>: so how do we do we conclude this? FEniCS simulation in 3D or FEniCS simulation in 1D with r? Or perhaps both? There are some stuff happening with piecewise integration in the presence of the r.]</p>
<div class="section" id="another-example-in-1d">
<span id="fem-sys-up-1d"></span><h3>Another example in 1D<a class="headerlink" href="#another-example-in-1d" title="Permalink to this headline">¶</a></h3>
<p>Consider the problem</p>
<div class="math" id="eq-femsys-varcoeff-1d">
\[\tag{363}
-(a u')' = 0,\]</div>
<div class="math" id="eq-auto153">
\[\tag{364}
u(0) = 0,\]</div>
<div class="math" id="eq-auto154">
\[\tag{365}
u(1) = 1 {\thinspace .}\]</div>
<p>For any scalar <span class="math">\(a\)</span> (larger than 0), we may easily verify that the solution is <span class="math">\(u(x)=x\)</span>.
In many applications, such as for example porous media flow
or heat conduction, the parameter <span class="math">\(a\)</span> contains a jump that represents
the transition from one material to another. Hence,
let us consider the problem where <span class="math">\(a\)</span> is on the following
form</p>
<div class="math">
\[\begin{split}a(x) = \left\{ \begin{array}{ll}
            1 &amp; \mbox{  if } x\le\frac{1}{2}, \\
            a_0 &amp;  \mbox{  if } x&gt;\frac{1}{2}{\thinspace .}
           \end{array} \right.\end{split}\]</div>
<p>Notice that for such an <span class="math">\(a(x)\)</span>, the equation <a class="reference internal" href="#eq-femsys-varcoeff-1d"><span class="std std-ref">(363)</span></a> does not necessarily make
sense because we cannot differentiate <span class="math">\(a(x)\)</span>. Strictly speaking <span class="math">\(a'(x)\)</span> would
be a Dirac&#8217;s delta function in <span class="math">\(x=\frac{1}{2}\)</span>, that is; <span class="math">\(a'(x)\)</span> is <span class="math">\(\infty\)</span> at <span class="math">\(x=\frac{1}{2}\)</span> and zero
everywhere else.</p>
<p>Hand-calculations do however show that we may be able to
compute the solution. Integrating <a class="reference internal" href="#eq-femsys-varcoeff-1d"><span class="std std-ref">(363)</span></a>
yields the expression</p>
<div class="math">
\[-(a u') = C\]</div>
<p>A trick now is to divide by <span class="math">\(a(x)\)</span> on both sides to obtain</p>
<div class="math">
\[- u' = \frac{C}{a}\]</div>
<p>and hence</p>
<div class="math" id="eq-varcoeff-analytical-solution">
\[\tag{366}
u(x) = \frac{C}{a(x)} x + D\]</div>
<p>The boundary conditions demand that <span class="math">\(u(0) = 0\)</span>, which means that <span class="math">\(D=0\)</span>
and <span class="math">\(u(1) = 1\)</span> fixate <span class="math">\(C\)</span> to be <span class="math">\(a(1) = a_0\)</span>.</p>
<p>To obtain a variational form of this problem suitable for
finite element simulation, we transform the problem
to a homogeneous Dirichlet problem.
Let the solution be <span class="math">\(u(x) = B(x) + \sum_{j\in{\mathcal{I}_s}} c_j{\psi}_j(x)\)</span> where
<span class="math">\(B(x)=x\)</span>.</p>
<p>[<strong>kam 26</strong>: the right hand side is hard to compute. Perhaps find a problem with homogeneous BC. Or perhaps just comment that we take the linear algebra approach. Can take the opportunity to say that the BC trick requires extra regularity and that we instead do the LA approach.]</p>
<p>The variational problem derived from a standard Galerkin method reads: Find <span class="math">\(u\)</span> such that</p>
<div class="math">
\[\int_{\Omega} a u' v' \, dx = \int_\Omega f v dx\]</div>
<p>We observe that in the variational problem, the discontinuity of <span class="math">\(a\)</span> does not cause any problem
as the differentiation is moved from <span class="math">\(a\)</span> (and <span class="math">\(u'\)</span>) to <span class="math">\(v\)</span> by using integration by parts.
Letting <span class="math">\(u=\sum_{j\in{\mathcal{I}_s}} c_j{\psi}_j(x)\)</span> and <span class="math">\(v={\psi}_i(x)\)</span> the corresponding linear system is <span class="math">\(\sum_j A_{i,j}c_j=b_i\)</span>
with</p>
<div class="math">
\[\begin{split}\begin{align*}
A_{i,j} &amp;= (a {\psi}_j', {\psi}_i') = \int_{\Omega} a(x) {\psi}_j'(x)
{\psi}_i'(x){\, \mathrm{d}x},\\
b_i &amp;= (f,{\psi}_i)= 0 {\thinspace .}
\end{align*}\end{split}\]</div>
<p>The solution of the problem is shown in Figure <a class="reference internal" href="#femsys-varcoeff-1d-galerkin-plotu"><span class="std std-ref">Solution of the Darcy problem with discontinuous coefficient for different number of elements </span></a> at different mesh resolutions.
The analytical solution in <a class="reference internal" href="#eq-varcoeff-analytical-solution"><span class="std std-ref">(366)</span></a> is a piecewise polynomial, linear
for <span class="math">\(x\)</span> in <span class="math">\([0,\frac{1}{2})\)</span> and <span class="math">\((\frac{1}{2},1]\)</span> and it seems that the numerical strategy gives a good approximation
of the solution.</p>
<p>The flux <span class="math">\(a u'\)</span> is often a quantity of interest. Because the flux involves differentiation with respect
to <span class="math">\(x\)</span> we do not have an direct access to it and
have to compute it. A natural approach is to take the Galerkin approximation,
that is we seek a <span class="math">\(w \approx a u'\)</span> on the form  <span class="math">\(w=\sum_{j\in{\mathcal{I}_s}} d_j{\psi}_j\)</span> and
require  Galerkin orthogonality. In other words, we require
that <span class="math">\(w-a u'\)</span> is orthogonal to <span class="math">\(\{{\psi}_i\}\)</span>. This is done by solving
the linear system  <span class="math">\(\sum_j M_{i,j}d_j=b_i\)</span> with</p>
<div class="math">
\[\begin{split}\begin{align*}
M_{i,j} &amp;= (a {\psi}_j, {\psi}_i) = \int_{\Omega} a(x) {\psi}_j(x) {\psi}_i(x){\, \mathrm{d}x},\\
b_i &amp;= (a u',{\psi}_i)=  \int_\Omega a(x)  \sum_j c_j{\psi}_j'(x) {\, \mathrm{d}x}{\thinspace .}
\end{align*}\end{split}\]</div>
<p>As shown in Figure <a class="reference internal" href="#femsys-varcoeff-1d-galerkin-plotsux"><span class="std std-ref">The corresponding flux  for the Darcy problem with discontinuous coefficient for different number of elements </span></a>, this
approach does not produce a good approximation of the flux.</p>
<div class="figure" id="id6">
<span id="femsys-varcoeff-1d-galerkin-plotu"></span><a class="reference internal image-reference" href="_images/darcy_a1D.png"><img alt="_images/darcy_a1D.png" src="_images/darcy_a1D.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text">Solution of the Darcy problem with discontinuous coefficient for different number of elements <span class="math">\(N\)</span></span></p>
</div>
<p>To improve the approximation of the flux, it is common to consider an equivalent form
of <a class="reference internal" href="#eq-femsys-varcoeff-1d"><span class="std std-ref">(363)</span></a> where the flux is one of the unknowns.
The equations reads:</p>
<div class="math" id="eq-fem-sys-up-1d-eq-mass">
\[\tag{367}
\frac{\partial w}{\partial x} = 0,\]</div>
<div class="math" id="eq-fem-sys-up-1d-eq-darcy">
\[ \begin{align}\begin{aligned}\tag{368}
w =-a\frac{\partial u}{\partial x}\\    {\thinspace .}\end{aligned}\end{align} \]</div>
<p>A straightforward calculation shows that inserting <a class="reference internal" href="#eq-fem-sys-up-1d-eq-darcy"><span class="std std-ref">(368)</span></a> into <a class="reference internal" href="#eq-fem-sys-up-1d-eq-mass"><span class="std std-ref">(367)</span></a> yields
the equation <a class="reference internal" href="#eq-femsys-varcoeff-1d"><span class="std std-ref">(363)</span></a>. We also note that we have replaced the second order differential
equation with a system of two first order differential equations.</p>
<p>It is common to swap the order of the equations and also divide equation
<a class="reference internal" href="#eq-fem-sys-up-1d-eq-darcy"><span class="std std-ref">(368)</span></a> by <span class="math">\(a\)</span> in order to get a symmetric system of
equations. Then variational formulation of the problem, having the two unknowns <span class="math">\(w\)</span> and <span class="math">\(u\)</span>
and corresponding test functions  <span class="math">\(v^{(w)}\)</span> and <span class="math">\(v^{(u)}\)</span>,</p>
<blockquote>
<div>becomes</div></blockquote>
<div class="math" id="eq-fem-sys-up-1d-eq-darcy-var">
\[\tag{369}
\int_\Omega \frac{1}{a} w v^{(w)} + \frac{\partial u}{\partial x} v^{(w)} {\, \mathrm{d}x} =0,\]</div>
<div class="math" id="eq-fem-sys-up-1d-eq-mass-var">
\[\tag{370}
\int_\Omega \frac{\partial w}{\partial x} v^{(u)} {\, \mathrm{d}x} = 0{\thinspace .}\]</div>
<p>and letting
<span class="math">\(u=\sum_{j\in{\mathcal{I}_s}} c_j{\psi}_j^{(u)}\)</span>,
<span class="math">\(w=\sum_{j\in{\mathcal{I}_s}} c_j{\psi}_j^{(w)}\)</span>,
<span class="math">\(v^{(u)} =  {\psi}_i^{(u)}\)</span>, and
<span class="math">\(v^{(w)} =  {\psi}_i^{(w)}\)</span>, we obtain the following system
of linear equations</p>
<div class="math">
\[\begin{split}A\, c = \left[ \begin{array}{cc} A^{(w,w)} &amp; A^{(w,u)}\\ A^{(u,w)} &amp; 0 \end{array} \right]
\left[ \begin{array}{c} c^{(w)} \\ c^{(u)} \end{array} \right] =
\left[ \begin{array}{c} b^{(w)} \\ b^{(u)} \end{array} \right]
= b,\end{split}\]</div>
<p>where</p>
<div class="math">
\[\begin{split}\begin{align*}
A^{(w,w)}_{i,j} &amp;=  \int_{\Omega} \frac{1}{a(x)} {\psi}^{(w)}_j(x) {\psi}^{(w)}_i(x){\, \mathrm{d}x} &amp; i,j = 0\ldots N^{(w)}-1, \\
A^{(w,u)}_{i,j} &amp;=  \int_{\Omega} \frac{\partial}{\partial x} {\psi}^{(u)}_j(x) {\psi}^{(w)}_i(x){\, \mathrm{d}x} &amp;  i=0\ldots N^{(w)}-1, j=0, \ldots N^{(u)}-1, \\
A^{(u,w)}_{i,j} &amp;= A^{(w,u)}_{j,i}, \\
b^{(w)}_i &amp;= (0,{\psi}^{(w)}_i)= 0, \\
b^{(u)}_i &amp;= (0,{\psi}^{(u)}_i)= 0 {\thinspace .}
\end{align*}\end{split}\]</div>
<p>It is interesting to note that the standard Galerkin formulation
of the problem results in a perfect approximation of <span class="math">\(u\)</span>, while
the flux <span class="math">\(-a u'\)</span> is badly represented. On the other hand,
for the mixed formulation, the flux is well approximated but
<span class="math">\(u\)</span> is approximated only to first order yielding a staircase
approximation. These observations naturally suggest
that we should employ P1 approximation of both <span class="math">\(u\)</span> and
its flux. We should then get a perfect approximation of
both unknowns. This is however not possible. The
linear system we obtain with P1 elements for both variables is singular.</p>
<p>This example shows that when we are solving systems of PDEs with
several unknowns, we can not choose the approximation arbitrary.
The polynomial spaces of the different unknowns have to be compatible
and the accuracy of the different unknowns depend on each other.
We will not discuss the reasons for the need of compatibility here
as it is rather mathematical and
well presented in many books, e.g. <a class="reference internal" href="._book036.html#ref03" id="id1">[Ref03]</a> <a class="reference internal" href="._book036.html#ref04" id="id2">[Ref04]</a> <a class="reference internal" href="._book036.html#ref10" id="id3">[Ref10]</a>.</p>
<div class="figure" id="id7">
<span id="femsys-varcoeff-1d-galerkin-plotsux"></span><a class="reference internal image-reference" href="_images/darcy_adx1D.png"><img alt="_images/darcy_adx1D.png" src="_images/darcy_adx1D.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text">The corresponding flux <span class="math">\(a u'\)</span> for the Darcy problem with discontinuous coefficient for different number of elements <span class="math">\(N\)</span></span></p>
</div>
<p>[<strong>kam 27</strong>: Not sure why the I don&#8217;t get <span class="math">\(a_0\)</span>. Need to debug.]
[<strong>kam 28</strong>: integration by parts done above, but not commented. Also bc, not considered.]
[<strong>kam 29</strong>: wrong figure]</p>
</div>
</div>
<div class="section" id="exercises-6">
<h2>Exercises<a class="headerlink" href="#exercises-6" title="Permalink to this headline">¶</a></h2>
<div class="section" id="problem-39-estimate-order-of-convergence-for-the-cooling-law">
<span id="femsys-exer-cooling-1"></span><h3>Problem 39: Estimate order of convergence for the Cooling law<a class="headerlink" href="#problem-39-estimate-order-of-convergence-for-the-cooling-law" title="Permalink to this headline">¶</a></h3>
<p>Consider the 1D Example of the fluid flow in a straight pipe
coupled to heat conduction in the section <a class="reference internal" href="#femsys-cooling-1d"><span class="std std-ref">Computations in 1D</span></a>.
The example demonstrated fast convergence when using linear elements
for both variables <span class="math">\(w\)</span> and <span class="math">\(T\)</span>. In this exercise we quantify the order
of convergence. That is, we expect that</p>
<div class="math">
\[\begin{split}\begin{align*}
\|w - w_e \|_{L_2} &amp;\le C_w h^{\beta_w}, \\
\|T - T_e \|_{L_2} &amp;\le C_T h^{\beta_T},
\end{align*}\end{split}\]</div>
<p>for some <span class="math">\(C_w\)</span>, <span class="math">\(C_T\)</span>, <span class="math">\(\beta_w\)</span> and <span class="math">\(\beta_T\)</span>.
Assume therefore that</p>
<div class="math">
\[\begin{split}\begin{align*}
\|w - w_e \|_{L_2} &amp;= C_w h^{\beta_w},\\
\|T - T_e \|_{L_2} &amp;= C_T h^{\beta_T},
\end{align*}\end{split}\]</div>
<p>and estimate  <span class="math">\(C_w\)</span>, <span class="math">\(C_T\)</span>, <span class="math">\(\beta_w\)</span> and <span class="math">\(\beta_T\)</span>.</p>
</div>
<div class="section" id="problem-40-estimate-order-of-convergence-for-the-cooling-law">
<span id="femsys-exer-cooling-2"></span><h3>Problem 40: Estimate order of convergence for the Cooling law<a class="headerlink" href="#problem-40-estimate-order-of-convergence-for-the-cooling-law" title="Permalink to this headline">¶</a></h3>
<p>Repeat <a class="reference internal" href="#femsys-exer-cooling-1"><span class="std std-ref">Problem 39: Estimate order of convergence for the Cooling law</span></a> with quadratic finite
elements for both <span class="math">\(w\)</span> and <span class="math">\(T\)</span>.</p>
<p><strong>Calculations to be continued...</strong></p>
</div>
</div>
</div>
<div class="section" id="flexible-implementations-of-boundary-conditions">
<span id="ch-nitsche"></span><h1>Flexible implementations of boundary conditions<a class="headerlink" href="#flexible-implementations-of-boundary-conditions" title="Permalink to this headline">¶</a></h1>
<p>One quickly gets the impression that variational forms can handle only
two types of boundary conditions: essential conditions where the
unknown is prescribed, and natural conditions where flux terms
integrated by parts allow specification of flux conditions. However,
it is possible to treat much more general boundary conditions by
adding their weak form.  That is, one simply adds the variational
formulation of some boundary condition <span class="math">\(\mathcal{B}(u)=0\)</span>:
<span class="math">\(\int_{\Omega_B}\mathcal{B}(u)v{\, \mathrm{d}x}\)</span>, where <span class="math">\(\Omega_B\)</span> is some
boundary, to the variational formulation of the PDE problem.  Or using
the terminology from the chapter <a class="reference internal" href="._book002.html#ch-approx-global"><span class="std std-ref">Function approximation by global functions</span></a>: the residual of
the boundary condition when the discrete solution is inserted is added
to the residual of the entire problem. The present chapter shows
underlying mathematical details.</p>
<div class="section" id="optimization-with-constraint">
<span id="nitsche-fxy-opt"></span><h2>Optimization with constraint<a class="headerlink" href="#optimization-with-constraint" title="Permalink to this headline">¶</a></h2>
<p>newcommand{uN}{u_N}
Suppose we have a function</p>
<div class="math">
\[f(x,y) = x^2 + y^2 {\thinspace .}\]</div>
<p>and want to optimize its values, i.e., find minima and maxima.
The condition for an optimum is that the derivatives vanish in all
directions, which implies</p>
<div class="math">
\[\boldsymbol{n}\cdot\nabla f = 0\quad\forall\boldsymbol{n} \in \mathbb{R}^2,\]</div>
<p>which further implies</p>
<div class="math">
\[\frac{\partial f}{\partial x} = 0,\quad \frac{\partial f}{\partial y} = 0{\thinspace .}\]</div>
<p>These two equations are in general nonlinear and can have many solutions,
one unique solution, or none.
In our specific example, there is only one solution: <span class="math">\(x=0\)</span>, <span class="math">\(y=0\)</span>.</p>
<p>Now we want to optimize <span class="math">\(f(x,y)\)</span> under the constraint <span class="math">\(y=2-x\)</span>.
This means that only <span class="math">\(f\)</span> values along the line <span class="math">\(y=2-x\)</span> are relevant,
and we can imagine we view <span class="math">\(f(x,y)\)</span> along this line and want to find
the optimum value.</p>
<div class="section" id="elimination-of-variables">
<h3>Elimination of variables<a class="headerlink" href="#elimination-of-variables" title="Permalink to this headline">¶</a></h3>
<p>Our <span class="math">\(f\)</span> is obviously a function of one variable along the line.
Inserting <span class="math">\(y=2-x\)</span> in <span class="math">\(f(x,y)\)</span> eliminates <span class="math">\(y\)</span> and leads to <span class="math">\(f\)</span> as
function of <span class="math">\(x\)</span> alone:</p>
<div class="math">
\[f(x,y=2-x) = 4 - 4x + 2x^2{\thinspace .}\]</div>
<p>The condition for an optimum is</p>
<div class="math">
\[\frac{d}{dx}(4 - 4x + 2x^2) = -4 + 4x = 0,\]</div>
<p>so <span class="math">\(x=1\)</span> and <span class="math">\(y=2-x=1\)</span>.</p>
<p>In the general case we have a scalar function <span class="math">\(f(\boldsymbol{x})\)</span>,
<span class="math">\(\boldsymbol{x}=(x_0,\ldots,x_m)\)</span> with <span class="math">\(n+1\)</span> constraints <span class="math">\(g_i(\boldsymbol{x})=0\)</span>,
<span class="math">\(i=0,\ldots,n\)</span>. In theory, we could use the constraints to
express <span class="math">\(n+1\)</span> variables in terms of the remaining <span class="math">\(m-n\)</span> variables,
but this is very seldom possible, because it requires us to solve
the <span class="math">\(g_i=0\)</span> symbolically with respect to <span class="math">\(n+1\)</span> different variables.</p>
</div>
<div class="section" id="lagrange-multiplier-method">
<span id="nitsche-fxy-opt-lagrange"></span><h3>Lagrange multiplier method<a class="headerlink" href="#lagrange-multiplier-method" title="Permalink to this headline">¶</a></h3>
<p>When we cannot easily eliminate variables using the constraint(s),
the Lagrange multiplier method come to aid. Optimization of <span class="math">\(f(x,y)\)</span>
under the constraint <span class="math">\(g(x,y)=0\)</span> then consists in formulating
the <em>Lagrangian</em></p>
<div class="math">
\[\ell(x,y,\lambda) = f(x,y) + \lambda g(x,y),\]</div>
<p>where <span class="math">\(\lambda\)</span> is the Lagrange multiplier, which is unknown.
The conditions for an optimum is that</p>
<div class="math">
\[\frac{\partial\ell}{\partial x}=0,\quad
\frac{\partial\ell}{\partial y}=0,\quad
\frac{\partial\ell}{\partial \lambda}=0{\thinspace .}\]</div>
<p>In our example, we have</p>
<div class="math">
\[\ell(x,y,\lambda) = x^2 + y^2 + \lambda(y - 2 + x),\]</div>
<p>leading to the conditions</p>
<div class="math">
\[2x + \lambda = 0,\quad 2y + \lambda = 0,\quad y - 2+ x = 0{\thinspace .}\]</div>
<p>This is a system of three linear equations in three unknowns with
the solution</p>
<div class="math">
\[x = 1,\quad y = 1,\quad \lambda =2{\thinspace .}\]</div>
<p>In the general case with optimizing <span class="math">\(f(\boldsymbol{x})\)</span> subject to
the constraints <span class="math">\(g_i(\boldsymbol{x})=0\)</span>, <span class="math">\(i=0,\ldots,n\)</span>, the Lagrangian becomes</p>
<div class="math">
\[\ell(\boldsymbol{x},\boldsymbol{\lambda}) = f(\boldsymbol{x}) + \sum_{j=0}^n\lambda_jg_j(\boldsymbol{x}),\]</div>
<p>with <span class="math">\(\boldsymbol{x}=(x_0,\ldots,x_m)\)</span> and <span class="math">\(\boldsymbol{\lambda}=(\lambda_0,\ldots,\lambda_n)\)</span>.
The conditions for an optimum are</p>
<div class="math">
\[\frac{\partial f}{\partial\boldsymbol{x}}=0,\quad
\frac{\partial f}{\partial\boldsymbol{\lambda}}=0{\thinspace .},\]</div>
<p>where</p>
<div class="math">
\[\frac{\partial f}{\partial\boldsymbol{x}}=0\Rightarrow
\frac{\partial f}{\partial x_i}=0,\ i=0,\ldots,m{\thinspace .}\]</div>
<p>Similarly, <span class="math">\(\partial f/\partial\boldsymbol{\lambda}=0\)</span> leads to
<span class="math">\(n+1\)</span> equations <span class="math">\(\partial f/\partial\lambda_i=0\)</span>, <span class="math">\(i=0,\ldots,n\)</span>.</p>
</div>
<div class="section" id="penalty-method">
<span id="nitsche-fxy-opt-penalty"></span><h3>Penalty method<a class="headerlink" href="#penalty-method" title="Permalink to this headline">¶</a></h3>
<p>Instead of incorporating the constraint exactly, as in the
Lagrange multiplier method, the penalty method employs an approximation
at the benefit of avoiding the extra Lagrange multiplier as unknown.
The idea is to add the constraint squared, multiplied by a large
prescribed number <span class="math">\(\lambda\)</span>, called the penalty parameter,</p>
<div class="math">
\[\ell_\lambda (x,y) = f(x,y) + \frac{1}{2}\lambda(y-2+x)^2{\thinspace .}\]</div>
<p>Note that <span class="math">\(\lambda\)</span> is now a given (chosen) number.
The <span class="math">\(\ell_\lambda\)</span> function is just a function of two variables,
so the optimum is found
by solving</p>
<div class="math">
\[\frac{\partial \ell_\lambda}{\partial x} =0,\quad
\frac{\partial \ell_\lambda}{\partial y} =0{\thinspace .}\]</div>
<p>Here we get</p>
<div class="math">
\[2x +\lambda (y-2+x)=0,\quad
2y + \lambda (y-2+x)=0{\thinspace .}\]</div>
<p>The solution becomes</p>
<div class="math">
\[x = y = \frac{1}{1-\frac{1}{2}\lambda^{-1}},\]</div>
<p>which we see approaches the correct solution <span class="math">\(x=y=1\)</span>
as <span class="math">\(\lambda\rightarrow\infty\)</span>.</p>
<p>The penalty method for optimization of a multi-variate function
<span class="math">\(f(\boldsymbol{x})\)</span> with constraints <span class="math">\(g_i(\boldsymbol{x})=0\)</span>, <span class="math">\(i=0,\ldots,n\)</span>,
can be formulated as optimization of the unconstrained function</p>
<div class="math">
\[\ell_\lambda(\boldsymbol{x}) = f(\boldsymbol{x}) + \frac{1}{2}\lambda\sum_{j=0}^n (g_i(\boldsymbol{x}))^2{\thinspace .}\]</div>
<p>Sometimes the symbol <span class="math">\(\epsilon^{-1}\)</span> is used for <span class="math">\(\lambda\)</span> in the
penalty method.</p>
</div>
</div>
<div class="section" id="optimization-of-functionals">
<span id="nitsche-pde-opt"></span><h2>Optimization of functionals<a class="headerlink" href="#optimization-of-functionals" title="Permalink to this headline">¶</a></h2>
<p>The methods above for optimization of scalar functions of a finite
number of variables can be generalized to optimization of
functionals (functions of functions).
We start with the specific example of optimizing</p>
<div class="math" id="eq-nitsche-fu-functional1">
\[\tag{371}
F(u) =
    \int\limits_\Omega ||\nabla u||^2 {\, \mathrm{d}x} -
    \int\limits_\Omega fu {\, \mathrm{d}x} -
    \int\limits_{\partial\Omega_N}gu {\, \mathrm{d}s},\quad
    u\in V,\]</div>
<p>where <span class="math">\(\Omega\subset \mathbb{R}^2\)</span>, and <span class="math">\(u\)</span> and <span class="math">\(f\)</span> are functions of <span class="math">\(x\)</span>
and <span class="math">\(y\)</span> in <span class="math">\(\Omega\)</span>. The norm <span class="math">\(||\nabla u||^2\)</span> is defined as <span class="math">\(u_{x}^2
+ u_{y}^2\)</span>, with <span class="math">\(u_x\)</span> denoting the derivative with respect to <span class="math">\(x\)</span>.
The vector space <span class="math">\(V\)</span> contains the relevant functions for this problem,
and more specifically, <span class="math">\(V\)</span> is the Hilbert space <span class="math">\(H^1_0\)</span> consisting of
all functions for which <span class="math">\(\int\limits_\Omega (u^2 + ||\nabla u||^2){\, \mathrm{d}x}\)</span>
is finite and <span class="math">\(u=0\)</span> on <span class="math">\(\partial\Omega_D\)</span>, which is some part of the
boundary <span class="math">\(\partial\Omega\)</span> of <span class="math">\(\Omega\)</span>.  The remaining part of the
boundary is denoted by <span class="math">\(\partial\Omega_N\)</span>
(<span class="math">\(\partial\Omega_N\cup\partial\Omega_D=\partial\Omega\)</span>,
<span class="math">\(\partial\Omega_N\cap\partial\Omega_D=\emptyset\)</span>), over which <span class="math">\(F(u)\)</span>
involves a line integral.  Note that <span class="math">\(F\)</span> is a mapping from any <span class="math">\(u\in
V\)</span> to a real number in <span class="math">\(\mathbb{R}\)</span>.</p>
<div class="section" id="classical-calculus-of-variations">
<span id="nitsche-pde-opt-varcalculus"></span><h3>Classical calculus of variations<a class="headerlink" href="#classical-calculus-of-variations" title="Permalink to this headline">¶</a></h3>
<p>Optimization of the functional
<span class="math">\(F\)</span> makes use of the machinery from <a class="reference external" href="http://en.wikipedia.org/wiki/Variational_calculus">variational calculus</a>. The essence is to demand that the
functional derivative of <span class="math">\(F\)</span> with respect to <span class="math">\(u\)</span> is zero.
Technically, this is carried out by writing a general function <span class="math">\(\tilde u\in V\)</span>
as <span class="math">\(\tilde u=u+\epsilon v\)</span>, where <span class="math">\(u\)</span> is the exact solution of the optimization
problem, <span class="math">\(v\)</span> is an arbitrary function in <span class="math">\(V\)</span>,
and <span class="math">\(\epsilon\)</span> is a scalar parameter. The
functional derivative in the direction of <span class="math">\(v\)</span> (also known as the
<a class="reference external" href="http://en.wikipedia.org/wiki/G%C3%A2teaux_derivative">Gateaux derivative</a>)
is defined as</p>
<div class="math" id="eq-nitcshe-functional-derivative">
\[\tag{372}
\frac{\delta F}{\delta u} = \lim_{\epsilon\rightarrow 0}\frac{d}{d\epsilon}
    F(u+\epsilon v)
    {\thinspace .}\]</div>
<p>As an example,
the functional derivative to the term
<span class="math">\(\int\limits_\Omega fu{\, \mathrm{d}x}\)</span> in <span class="math">\(F(u)\)</span>
is computed by finding</p>
<div class="math" id="eq-nitcshe-varform-poisson1">
\[\tag{373}
\frac{d}{d\epsilon} \int\limits_\Omega f\cdot(u+\epsilon v){\, \mathrm{d}x}
    = \int\limits_\Omega fv {\, \mathrm{d}x},\]</div>
<p>and then let <span class="math">\(\epsilon\)</span> go to zero, which just results in <span class="math">\(\int\limits_\Omega fv{\, \mathrm{d}x}\)</span>.
The functional derivative of the other area integral becomes</p>
<div class="math">
\[\frac{d}{d\epsilon} \int\limits_\Omega ((u_x + \epsilon v_x)^2 +
(u_y + \epsilon v_y)^2){\, \mathrm{d}x} = \int\limits_\Omega (2(u_x + \epsilon v_x)v_x
+ 2(u_v+\epsilon v_y)v_y){\, \mathrm{d}x},\]</div>
<p>which leads to</p>
<div class="math" id="eq-nitcshe-varform-poisson2">
\[\tag{374}
\int\limits_\Omega (u_xv_x + u_yv_y){\, \mathrm{d}x} = \int\limits_\Omega \nabla u\cdot\nabla v {\, \mathrm{d}x},\]</div>
<p>as <span class="math">\(\epsilon\rightarrow 0\)</span>.</p>
<p>The functional derivative of the boundary term
becomes</p>
<div class="math" id="eq-nitcshe-varform-poisson3">
\[\tag{375}
\frac{d}{d\epsilon} \int\limits_{\partial\Omega_N} g \cdot (u+\epsilon v) {\, \mathrm{d}s}
    = \int\limits_{\partial\Omega_N} g v {\, \mathrm{d}s},\]</div>
<p>for any <span class="math">\(\epsilon\)</span>. From <a class="reference internal" href="#eq-nitcshe-varform-poisson1"><span class="std std-ref">(373)</span></a>-<a class="reference internal" href="#eq-nitcshe-varform-poisson3"><span class="std std-ref">(375)</span></a> we then get the result</p>
<div class="math" id="eq-nitcshe-varform-poisson">
\[\tag{376}
\frac{\delta F}{\delta u} =
    \int\limits_\Omega \nabla u\cdot\nabla v {\, \mathrm{d}x} -
    \int\limits_\Omega fv {\, \mathrm{d}x} -
    \int\limits_{\partial\Omega_N} g v {\, \mathrm{d}s} =0{\thinspace .}\]</div>
<p>Since <span class="math">\(v\)</span> is arbitrary, this equation must hold <span class="math">\(\forall v\in V\)</span>. Many
will recognize <a class="reference internal" href="#eq-nitcshe-varform-poisson"><span class="std std-ref">(376)</span></a> as the variational
formulation of a Poisson problem, which can be directly discretized
and solved by a finite element method.</p>
<p>Variational calculus goes one more step and derives a partial differential
equation problem from <a class="reference internal" href="#eq-nitcshe-varform-poisson"><span class="std std-ref">(376)</span></a>, known as the
<a class="reference external" href="http://en.wikipedia.org/wiki/Euler-Lagrange_equation">Euler-Lagrange equation</a> corresponding to optimization of <span class="math">\(F(u)\)</span>. To find the differential
equation, one manipulates the variational form
<a class="reference internal" href="#eq-nitcshe-varform-poisson"><span class="std std-ref">(376)</span></a> such that no derivatives of <span class="math">\(v\)</span>
appear and the equation <a class="reference internal" href="#eq-nitcshe-varform-poisson"><span class="std std-ref">(376)</span></a> can be
written as <span class="math">\(\int\limits_\Omega \mathcal{L}v{\, \mathrm{d}x} =0\)</span>, <span class="math">\(\forall v\in\)</span>, from which
it follows that <span class="math">\(\mathcal{L}=0\)</span> is the differential equation.</p>
<p>Performing integration by parts of the term
<span class="math">\(\int\limits_\Omega\nabla u\cdot\nabla v {\, \mathrm{d}x}\)</span> in <a class="reference internal" href="#eq-nitcshe-varform-poisson"><span class="std std-ref">(376)</span></a>
moves the derivatives of <span class="math">\(v\)</span> over to <span class="math">\(u\)</span>:</p>
<div class="math">
\[\begin{split}\begin{align*}
 \int\limits_\Omega\nabla u\cdot\nabla v {\, \mathrm{d}x} &amp;=
-\int\limits_\Omega (\nabla^2 u)v{\, \mathrm{d}x} + \int\limits_{\partial\Omega}\frac{\partial u}{\partial n}v {\, \mathrm{d}s}\\
&amp; = -\int\limits_\Omega (\nabla^2 u)v{\, \mathrm{d}x} +
\int\limits_{\partial\Omega_D}\frac{\partial u}{\partial n}v {\, \mathrm{d}s} +
\int\limits_{\partial\Omega_N}\frac{\partial u}{\partial n}v {\, \mathrm{d}s}\\
&amp; = -\int\limits_\Omega (\nabla^2 u)v{\, \mathrm{d}x} +
\int\limits_{\partial\Omega_D}\frac{\partial u}{\partial n}0 {\, \mathrm{d}s} +
\int\limits_{\partial\Omega_N}\frac{\partial u}{\partial n}v {\, \mathrm{d}s}\\
&amp; = -\int\limits_\Omega (\nabla^2 u)v{\, \mathrm{d}x} +
\int\limits_{\partial\Omega_N}\frac{\partial u}{\partial n}v {\, \mathrm{d}s}{\thinspace .}
\end{align*}\end{split}\]</div>
<p>Using this rewrite in <a class="reference internal" href="#eq-nitcshe-varform-poisson"><span class="std std-ref">(376)</span></a> gives</p>
<div class="math">
\[-\int\limits_\Omega (\nabla^2 u)v{\, \mathrm{d}x} +
\int\limits_{\partial\Omega_N}\frac{\partial u}{\partial n}v {\, \mathrm{d}s}
-\int\limits_\Omega fv{\, \mathrm{d}x}
-\int\limits_{\partial\Omega_N} g v {\, \mathrm{d}s},\]</div>
<p>which equals</p>
<div class="math">
\[\int\limits_\Omega (\nabla^2 u + f)v{\, \mathrm{d}x} +
\int\limits_{\partial\Omega_N}\left(\frac{\partial u}{\partial n}-g\right)v {\, \mathrm{d}s}
=0{\thinspace .}\]</div>
<p>This is to hold for any <span class="math">\(v\in V\)</span>, which means that the integrands
must vanish, and we get the famous Poisson problem</p>
<div class="math">
\[\begin{split}\begin{align*}
-\nabla^2u &amp;= f,\quad (x,y)\in\Omega,\\
u &amp;=0,\quad (x,y)\in\partial\Omega_D,\\
\frac{\partial u}{\partial n} &amp;=g,\quad (x,y)\in\partial\Omega_N{\thinspace .}
\end{align*}\end{split}\]</div>
<div class="admonition-some-remarks admonition">
<p class="first admonition-title">Some remarks</p>
<ul class="last simple">
<li>Specifying <span class="math">\(u\)</span> on some part of the boundary (<span class="math">\(\partial\Omega_D\)</span>)
implies a specification of <span class="math">\(\partial u/\partial n\)</span> on the rest
of the boundary. In particular, if such a specification is not
explicitly done, the mathematics above implies <span class="math">\(\partial u/\partial n=0\)</span>
on <span class="math">\(\partial\Omega_N\)</span>.</li>
<li>If a non-zero condition on <span class="math">\(u=u_0\)</span> on <span class="math">\(\partial\Omega_D\)</span> is wanted, one
can write <span class="math">\(u = u_0 + \bar u\)</span> and express the functional
<span class="math">\(F\)</span> in terms of <span class="math">\(\bar u\)</span>, which obviously must vanish on
<span class="math">\(\partial\Omega_D\)</span> since <span class="math">\(u\)</span> is the exact solution that is <span class="math">\(u_0\)</span>
on <span class="math">\(\partial\Omega_D\)</span>.</li>
<li>The boundary conditions on <span class="math">\(u\)</span> must be implemented in the space <span class="math">\(V\)</span>,
i.e., we can only work with functions that <em>must</em> be zero on
<span class="math">\(\partial\Omega_D\)</span> (so-called <em>essential boundary condition</em>).
The condition involving <span class="math">\(\partial u/\partial n\)</span> is easier to
implement since it is just a matter of computing a line integral.</li>
<li>The solution is not unique if <span class="math">\(\partial\Omega_D = \emptyset\)</span>
(any solution <span class="math">\(u+\hbox{const}\)</span> is also a solution).</li>
</ul>
</div>
</div>
<div class="section" id="penalty-method-for-optimization-with-constraints">
<span id="nitsche-pde-opt-penalty"></span><h3>Penalty method for optimization with constraints<a class="headerlink" href="#penalty-method-for-optimization-with-constraints" title="Permalink to this headline">¶</a></h3>
<p>The attention is now on optimization of a functional <span class="math">\(F(u)\)</span>
with a given constraint that <span class="math">\(u=\uN\)</span> on <span class="math">\(\partial\Omega_N\)</span>.
We could, of course, just extend the Dirichlet condition on <span class="math">\(u\)</span> in the
previous set-up by saying that <span class="math">\(\partial\Omega_D\)</span> is the
complete boundary <span class="math">\(\partial\Omega\)</span> and that <span class="math">\(u\)</span> takes on
the values of <span class="math">\(0\)</span> and <span class="math">\(\uN\)</span> at the different parts of the
boundary. However, this also implies that all the functions
in <span class="math">\(V\)</span> must vanish on the entire boundary. We want to relax
this condition (and by relaxing it, we will derive a method
that can be used for many other types of boundary conditions!).
The goal is, therefore, to incorporate <span class="math">\(u=\uN\)</span> on
<span class="math">\(\partial\Omega_N\)</span> without demanding anything from the functions
in <span class="math">\(V\)</span>. We can achieve this by enforcing the constraint</p>
<div class="math" id="eq-nitsche-essbc-constraint">
\[\tag{377}
\int\limits_{\partial\Omega_N} |u-\uN| {\, \mathrm{d}s} = 0{\thinspace .}\]</div>
<p>However, this constraint is cumbersome to implement. Note that
the absolute sign here is needed as in general there
are many functions <span class="math">\(u\)</span> such that
<span class="math">\(\int\limits_{\partial\Omega_N} u-\uN {\, \mathrm{d}s} = 0\)</span>.</p>
<p><strong>A penalty method.</strong>
The idea is to add a penalization term <span class="math">\(\frac{1}{2}\lambda(u-\uN)^2\)</span>,
integrated over the boundary <span class="math">\(\partial\Omega_N\)</span>, to
the functional <span class="math">\(F(u)\)</span>, just as we do in the penalty method (the
factor <span class="math">\(\frac{1}{2}\)</span> can be incorporated in <span class="math">\(\lambda\)</span>, but makes the
final result look nicer).
The condition <span class="math">\(\partial u/\partial n=g\)</span>
on <span class="math">\(\partial\Omega_N\)</span> is no longer relevant, so we replace
the <span class="math">\(g\)</span> by the unknown <span class="math">\(\partial u/\partial n\)</span> in the
boundary integral term in <a class="reference internal" href="#eq-nitsche-fu-functional1"><span class="std std-ref">(371)</span></a>.
The new functional becomes</p>
<p>[<strong>kam 30</strong>: there is a mismatch between text and equations here. If we replace <span class="math">\(g\)</span> with <span class="math">\(\partial u/\partial n\)</span> it seems we get a  symmetric form right away as we get <span class="math">\(u  \partial u/\partial n\)</span>.]</p>
<div class="math" id="eq-nitsche-fu-functional2">
\[\tag{378}
F(u) =
    \int\limits_\Omega ||\nabla u||^2 {\, \mathrm{d}x} -
    \int\limits_\Omega fu {\, \mathrm{d}x} -
    \int\limits_{\partial\Omega_N} \frac{\partial u}{\partial n}  u {\, \mathrm{d}s} + \,
    \frac{1}{2}\int\limits_{\partial\Omega_N}\lambda (u-\uN)^2 {\, \mathrm{d}s},\quad
    u\in V,\]</div>
<p>In <span class="math">\(F(\tilde u)\)</span>, insert <span class="math">\(\tilde u=u+\epsilon v\)</span>,
differentiate with respect
to <span class="math">\(\epsilon\)</span>, and let <span class="math">\(\epsilon\rightarrow 0\)</span>.
The result becomes</p>
<div class="math" id="eq-nitcshe-varform-poisson2s">
\[\tag{379}
\frac{\delta F}{\delta u} =
    \int\limits_\Omega \nabla u\cdot\nabla v {\, \mathrm{d}x} -
    \int\limits_\Omega fv {\, \mathrm{d}x} -
    \int\limits_{\partial\Omega_N}\frac{\partial u}{\partial n}v {\, \mathrm{d}s} +
    \int\limits_{\partial\Omega_N}\lambda (u-\uN)v {\, \mathrm{d}s}
    =0{\thinspace .}\]</div>
<div class="admonition-remark admonition">
<p class="first admonition-title">Remark</p>
<p class="last">We can drop the essential condition <span class="math">\(u=0\)</span> on <span class="math">\(\partial\Omega_E\)</span> and
just use the method above to enforce <span class="math">\(u=\uN\)</span> on the entire boundary
<span class="math">\(\partial\Omega\)</span>.</p>
</div>
<p><strong>Symmetrization.</strong>
Using the formulation <a class="reference internal" href="#eq-nitcshe-varform-poisson2s"><span class="std std-ref">(379)</span></a> for finite
element computations has one disadvantage: the variational form
is no longer symmetric, and the coefficient matrix in the associated
linear system becomes non-symmetric. We see this if we
rewrite <a class="reference internal" href="#eq-nitcshe-varform-poisson2s"><span class="std std-ref">(379)</span></a> as</p>
<div class="math">
\[a(u,v) = L(v),\quad\forall v\in V,\]</div>
<p>with</p>
<div class="math">
\[\begin{split}\begin{align*}
a(u,v) &amp;=
\int\limits_\Omega \nabla u\cdot\nabla v {\, \mathrm{d}x}
-\int\limits_{\partial\Omega_N}\frac{\partial u}{\partial n}v {\, \mathrm{d}s}
+ \int\limits_{\partial\Omega_N}\lambda uv {\, \mathrm{d}s},\\
L(v) &amp;= \int\limits_\Omega fv {\, \mathrm{d}x} +
\int\limits_{\partial\Omega_N}\lambda \uN v {\, \mathrm{d}s}
{\thinspace .}
\end{align*}\end{split}\]</div>
<p>The lack of symmetry is
evident in that we cannot interchange <span class="math">\(u\)</span> and <span class="math">\(v\)</span> in <span class="math">\(a(u,v)\)</span>, that is;
<span class="math">\(a(u,v)\not=a(v,u)\)</span>.
The standard finite element method results in a symmetric bilinear form
and a corresponding matrix for
the Poisson problem and we would like to regain this property.
The problematic non-symmetric term
is the line integral of <span class="math">\(v \partial u/\partial n\)</span>.
If we had another term <span class="math">\(u \partial v/\partial n\)</span>, the sum would be
symmetric. The idea is therefore to subtract <span class="math">\(\int_{\partial\Omega_N}
u \partial v/\partial n{\, \mathrm{d}s}\)</span> from both <span class="math">\(a(u,v)\)</span> and <span class="math">\(L(v)\)</span>.
Since <span class="math">\(u=\uN\)</span> on <span class="math">\(\partial\Omega_N\)</span> we subtract
<span class="math">\(\int_{\partial\Omega_N}
u\partial v/\partial n{\, \mathrm{d}s} = \int_{\partial\Omega_N}
\uN\partial v/\partial n{\, \mathrm{d}s}\)</span> in <span class="math">\(L(v)\)</span>:</p>
<div class="math">
\[\begin{split}\begin{align*}
a(u,v) &amp;=
\int\limits_\Omega \nabla u\cdot\nabla v {\, \mathrm{d}x}
-\int\limits_{\partial\Omega_N}\frac{\partial u}{\partial n}v {\, \mathrm{d}s}
- \int\limits_{\partial\Omega_N}\frac{\partial v}{\partial n}u {\, \mathrm{d}s}
+ \int\limits_{\partial\Omega_N}\lambda uv {\, \mathrm{d}s},\\
L(v) &amp;= \int\limits_\Omega fv {\, \mathrm{d}x}
- \int\limits_{\partial\Omega_N}\frac{\partial v}{\partial n}\uN {\, \mathrm{d}s}
+ \int\limits_{\partial\Omega_N}\lambda \uN v {\, \mathrm{d}s}
{\thinspace .}
\end{align*}\end{split}\]</div>
<p>This formulation is known as Nitsche&#8217;s method, but it is actually
a standard penalty method.</p>
<p>We can also easily derive this formulation from the partial differential
equation problem. We multiply <span class="math">\(-\nabla^2 u=f\)</span> by <span class="math">\(v\)</span> and integrate over
<span class="math">\(\Omega\)</span>. Integration by parts leads to</p>
<div class="math">
\[\int\limits_\Omega (\nabla^2 u)v{\, \mathrm{d}x} =
-\int\limits_\Omega \nabla u\cdot \nabla v{\, \mathrm{d}x}
+ \int\limits_{\partial\Omega} \frac{\partial u}{\partial n}v{\, \mathrm{d}s}{\thinspace .}\]</div>
<p>Now, <span class="math">\(u=0\)</span> and therefore <span class="math">\(v=0\)</span> on <span class="math">\(\partial\Omega_D\)</span> so the
line integral reduces to an integral over <span class="math">\(\partial\Omega_N\)</span>, where
we have no condition and hence no value for <span class="math">\(\partial u/\partial n\)</span>,
so we leave the integral as is.
Then we add the boundary penalization term <span class="math">\(\lambda\int_{\partial\Omega_N}
(u-\uN)v{\, \mathrm{d}s}\)</span>. The result becomes identical to <a class="reference internal" href="#eq-nitcshe-varform-poisson2s"><span class="std std-ref">(379)</span></a>.
We can thereafter add the symmetrization terms if desired.</p>
</div>
<div class="section" id="lagrange-multiplier-method-for-optimization-with-constraints">
<span id="nitsche-pde-opt-lagrange"></span><h3>Lagrange multiplier method for optimization with constraints<a class="headerlink" href="#lagrange-multiplier-method-for-optimization-with-constraints" title="Permalink to this headline">¶</a></h3>
<p>We consider the same problem as in the section <a class="reference internal" href="#nitsche-pde-opt-penalty"><span class="std std-ref">Penalty method for optimization with constraints</span></a>,
but this time we want to apply a Lagrange multiplier method so we can
solve for a <em>multiplier function</em> rather than specifying a large number for a
penalty parameter and getting an approximate result.</p>
<p>The functional to be optimized reads</p>
<div class="math">
\[F(u) =
\int\limits_\Omega ||\nabla u||^2 {\, \mathrm{d}x} -
\int\limits_\Omega fu {\, \mathrm{d}x} -
\int\limits_{\partial\Omega_N}\uN {\, \mathrm{d}s} +
\int\limits_{\partial\Omega_N}\lambda(u-\uN){\, \mathrm{d}s},\quad
u\in V{\thinspace .}\]</div>
<p>Here we have two unknown functions: <span class="math">\(u\in V\)</span> in <span class="math">\(\Omega\)</span> and <span class="math">\(\lambda\in Q\)</span> on
<span class="math">\(\partial\Omega_N\)</span>. The optimization criteria are</p>
<div class="math">
\[\frac{\delta F}{\delta u} = 0,\quad\frac{\delta F}{\delta\lambda} = 0{\thinspace .}\]</div>
<p>We write <span class="math">\(\tilde u = u + \epsilon_u v\)</span> and <span class="math">\(\tilde\lambda = \lambda +
\epsilon_\lambda p\)</span>, where <span class="math">\(v\)</span> is an arbitrary function in <span class="math">\(V\)</span> and <span class="math">\(p\)</span> is an
arbitrary function in <span class="math">\(Q\)</span>. Notice that <span class="math">\(V\)</span> is here a usual
function space with functions defined on <span class="math">\(\Omega\)</span>, while on
the other hand is a function space defined only on the
surface <span class="math">\(\Omega_N\)</span>.
We insert the expressions for <span class="math">\(\tilde u\)</span> and
<span class="math">\(\tilde\lambda\)</span> for <span class="math">\(u\)</span> and <span class="math">\(\lambda\)</span> and compute</p>
<div class="math">
\[\begin{split}\begin{align*}
\frac{\delta F}{\delta u} &amp;=
\lim_{\epsilon_u\rightarrow 0}\frac{dF}{d\epsilon_u} =
\int\limits_{\Omega}\nabla u\cdot\nabla v{\, \mathrm{d}x} -
\int\limits_\Omega fv {\, \mathrm{d}x} -
\int\limits_{\partial\Omega_N}\frac{\partial u}{\partial n}v{\, \mathrm{d}s}  +
\int\limits_{\partial\Omega_N}\lambda(u-\uN){\, \mathrm{d}s} = 0,\\
\frac{\delta F}{\delta \lambda} &amp;=
\lim_{\epsilon_\lambda\rightarrow 0}\frac{dF}{d\epsilon_\lambda} =
\int\limits_{\partial\Omega_N} (u-\uN) p{\, \mathrm{d}s} = 0 {\thinspace .}
\end{align*}\end{split}\]</div>
<p>These equations can be written as a linear system of equations:
Find <span class="math">\(u, \lambda \in V\times Q\)</span> such that</p>
<div class="math">
\[\begin{split}\begin{align*}
a(u,v) + b(\lambda, v) &amp;= L(v), \\
b(u, p)                &amp;= 0,
\end{align*}\end{split}\]</div>
<p>for all test functions <span class="math">\(v\in V\)</span> and <span class="math">\(p \in Q\)</span> and</p>
<div class="math">
\[\begin{split}\begin{align*}
a(u,v)        &amp;= \int\limits_{\Omega}\nabla u\cdot\nabla v{\, \mathrm{d}x} - \int\limits_{\partial\Omega_N}\frac{\partial u}{\partial n}v{\, \mathrm{d}s}, \\
b(\lambda, v) &amp;= \int\limits_\Omega \lambda v {\, \mathrm{d}s}, \\
L(v)          &amp;= \int\limits_\Omega fv {\, \mathrm{d}x}, \\
L(\lambda)    &amp;= \int\limits_\Omega \uN \lambda {\, \mathrm{d}s} .
\end{align*}\end{split}\]</div>
<p>Letting
<span class="math">\(u=\sum_{j\in{\mathcal{I}_s}} c_j{\psi}^{(u)}_j\)</span>,
<span class="math">\(\lambda=\sum_{j\in{\mathcal{I}_s}} c_j{\psi}^{(\lambda)}_j\)</span>,
<span class="math">\(v =  {\psi}^{(v)}_i\)</span>, and
<span class="math">\(p =  {\psi}^{(p)}_i\)</span>, we obtain the following system
of linear equations</p>
<div class="math">
\[\begin{split}A\, c = \left[ \begin{array}{cc} A^{(u,u)} &amp; A^{(\lambda,u)}\\ A^{(u,\lambda)} &amp; 0 \end{array} \right]
\left[ \begin{array}{c} c^{(u)} \\ c^{(\lambda)} \end{array} \right] =
\left[ \begin{array}{c} b^{(u)} \\ b^{(\lambda)} \end{array} \right]
= b,\end{split}\]</div>
<p>where</p>
<div class="math">
\[\begin{split}\begin{align*}
A^{(u,u)}_{i,j} &amp;=  a({\psi}^{(w)}_j, {\psi}^{(w)}_i),  \\
A^{(u,\lambda)}_{i,j} &amp;=  b({\psi}^{(u)}_j, {\psi}^{(w)}_i),  \\
A^{(\lambda,u)}_{i,j} &amp;= A^{(u,\lambda)}_{j,i}, \\
b^{(w)}_i &amp;= (f,{\psi}^{(w)}_i), \\
b^{(u)}_i &amp;= 0 {\thinspace .}
\end{align*}\end{split}\]</div>
<p>[<strong>kam 31</strong>: <span class="math">\(a\)</span> should be symmetric. Check why not. Also here <span class="math">\(\partial \Omega_N\)</span> is used almost everywhere. Should probably be <span class="math">\(\partial \Omega\)</span>.]</p>
</div>
<div class="section" id="example-1d-problem">
<span id="nitsche-pde-opt-1dex"></span><h3>Example: 1D problem<a class="headerlink" href="#example-1d-problem" title="Permalink to this headline">¶</a></h3>
<p><strong>Penalty method.</strong></p>
<p>Let us do hand calculations to demonstrate weakly enforced boundary
conditions via a penalty method and via the Lagrange multiplier method.
We study the simple problem <span class="math">\(-u'' = 2\)</span> on <span class="math">\([0,1]\)</span> with boundary
conditions <span class="math">\(u(0)=0\)</span> and <span class="math">\(u(1)=1\)</span>.</p>
<div class="math">
\[\begin{split}\begin{align*}
a(u,v) &amp;=
\int_0^1 \nabla u\cdot\nabla v {\, \mathrm{d}x}
-[u_x v]_0^1
-[v_x u]_0^1
+[\lambda uv]_0^1  \\
L(v) &amp;= \int_0^1 fv {\, \mathrm{d}x}
- [v_x \uN]_0^1
+ [\lambda \uN v]_0^1
{\thinspace .}
\end{align*}\end{split}\]</div>
<p>A uniform mesh with nodes
<span class="math">\(x_i=i\Delta x\)</span> is introduced, numbered from left to right:
<span class="math">\(i=0,\ldots,N_x\)</span>. The approximate value of <span class="math">\(u\)</span> at <span class="math">\(x_i\)</span> is denoted
by <span class="math">\(c_i\)</span>, and in general the approximation to <span class="math">\(u\)</span> is <span class="math">\(\sum_{i=0}^{N_x}
\varphi_i(x)c_i\)</span>.</p>
<p>The elements at the boundaries needs special attention. Let us consider
the element 0 defined on <span class="math">\([0,h]\)</span>. The basis functions are
<span class="math">\(\varphi_0(x) = 1 - x/h\)</span> and
<span class="math">\(\varphi_1(x) = x/h\)</span>. Hence,
<span class="math">\(\varphi_0|_{x=0} = 1\)</span>,
<span class="math">\(\varphi'_0|_{x=0} = -1/h\)</span>,
<span class="math">\(\varphi_1|_{x=0} = 0\)</span>, and
<span class="math">\(\varphi'_1|_{x=0} = 1/h\)</span>. Therefore, for element 0 we obtain the element matrix</p>
<div class="math">
\[\begin{split}\begin{align*}
A^{(0)}_{0, 0} &amp;= \lambda + \frac{3}{h}, \\
A^{(0)}_{0, 1} &amp;= - \frac{2}{h}, \\
A^{(0)}_{1, 0} &amp;= - \frac{2}{h}, \\
A^{(0)}_{1, 1} &amp;= \frac{1}{h} {\thinspace .}
\end{align*}\end{split}\]</div>
<p>The interior elements (<span class="math">\(e=1\ldots N_e-2\)</span>) result in the following element matrices</p>
<div class="math">
\[\begin{split}\begin{align*}
A^{(e)}_{0, 0} &amp;= \frac{1}{h},
&amp;A^{(e)}_{0, 1} = - \frac{1}{h},\\
A^{(e)}_{1, 0} &amp;= - \frac{1}{h},
&amp;A^{(e)}_{1, 1} = \frac{1}{h} {\thinspace .}
\end{align*}\end{split}\]</div>
<p>While the element at the boundary <span class="math">\(x=1\)</span> result in a element matrix similar to <span class="math">\(A^0\)</span>
except that 0 and 1 are swapped. The calculations are straightforward in <code class="docutils literal"><span class="pre">sympy</span></code></p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sym</span>
<span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">lam</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s2">&quot;x h \lambda&quot;</span><span class="p">)</span>
<span class="n">basis</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="o">/</span><span class="n">h</span><span class="p">,</span> <span class="n">x</span><span class="o">/</span><span class="n">h</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">basis</span><span class="p">)):</span>
  <span class="n">phi_i</span> <span class="o">=</span> <span class="n">basis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">basis</span><span class="p">)):</span>
    <span class="n">phi_j</span> <span class="o">=</span> <span class="n">basis</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
    <span class="n">a</span>  <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">sym</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">phi_i</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">sym</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">phi_j</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
    <span class="n">a</span> <span class="o">-=</span> <span class="p">(</span><span class="n">sym</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">phi_i</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">phi_j</span><span class="p">)</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">-=</span> <span class="p">(</span><span class="n">sym</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">phi_j</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">phi_i</span><span class="p">)</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">+=</span> <span class="p">(</span><span class="n">lam</span><span class="o">*</span><span class="n">phi_j</span><span class="o">*</span><span class="n">phi_i</span><span class="p">)</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>[<strong>kam 32</strong>: Do the thing in FEniCS. Check results for different <span class="math">\(\lambda\)</span>.]</p>
<p><strong>Lagrange multiplier method.</strong></p>
<p>For the Lagrange multiplier method we need a function space <span class="math">\(Q\)</span> defined on the boundary
of the domain. In 1D with <span class="math">\(\Omega=(0,1)\)</span> the boundary is <span class="math">\(x=0\)</span> and <span class="math">\(x=1\)</span>. Hence, <span class="math">\(Q\)</span>
can be spanned by two basis functions <span class="math">\(\lambda_0\)</span> and <span class="math">\(\lambda_1\)</span>. These functions
should be such that <span class="math">\(\lambda_0=1\)</span> for <span class="math">\(x=0\)</span> and zero everywhere else, while
<span class="math">\(\lambda_1=1\)</span> for <span class="math">\(x=1\)</span> and zero everywhere else.
Now, set</p>
<div class="math">
\[\lambda(x) = \lambda_0 \varphi_0(x) + \lambda_{N_x}\varphi_{N_x}(x){\thinspace .}\]</div>
<p>[<strong>kam 33</strong>: ok, write this up in detail]</p>
</div>
<div class="section" id="example-adding-a-constraint-in-a-neumann-problem">
<h3>Example: adding a constraint in a Neumann problem<a class="headerlink" href="#example-adding-a-constraint-in-a-neumann-problem" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li>Neumann problem: add <span class="math">\(\int_\Omega u{\, \mathrm{d}x} =0\)</span> as constraint.</li>
<li>Set up Nitsche and Lagrange multiplier method and the simple
trick <span class="math">\(u\)</span> fixed at a point. Compare in 1D.</li>
</ul>
</div></blockquote>
<p>[<strong>kam 34</strong>: penalty is kind of hard, at least in fenics, it involves the terms <span class="math">\(\int_\Omega u \times \int_\Omega v\)</span> rather than <span class="math">\(\int_\Omega u v\)</span>.]</p>
</div>
</div>
</div>
<div class="section" id="nonlinear-problems">
<span id="ch-nonlin"></span><h1>Nonlinear problems<a class="headerlink" href="#nonlinear-problems" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction-of-basic-concepts">
<span id="nonlin-timediscrete-logistic"></span><h2>Introduction of basic concepts<a class="headerlink" href="#introduction-of-basic-concepts" title="Permalink to this headline">¶</a></h2>
<div class="section" id="linear-versus-nonlinear-equations">
<h3>Linear versus nonlinear equations<a class="headerlink" href="#linear-versus-nonlinear-equations" title="Permalink to this headline">¶</a></h3>
<div class="section" id="algebraic-equations">
<h4>Algebraic equations<a class="headerlink" href="#algebraic-equations" title="Permalink to this headline">¶</a></h4>
<p>A linear, scalar, algebraic equation in <span class="math">\(x\)</span> has the form</p>
<div class="math">
\[ax + b = 0,\]</div>
<p>for arbitrary real constants <span class="math">\(a\)</span> and <span class="math">\(b\)</span>. The unknown is a number <span class="math">\(x\)</span>.
All other algebraic equations, e.g., <span class="math">\(x^2 + ax + b = 0\)</span>, are nonlinear.
The typical feature in a nonlinear algebraic equation is that the unknown
appears in products with itself, like <span class="math">\(x^2\)</span> or
in functions that are infinite sums of products, like <span class="math">\(e^x = 1 + x +\frac{1}{2} x^2 +
\frac{1}{3!}x^3 + \cdots\)</span>.</p>
<p>We know how to solve a linear algebraic equation, <span class="math">\(x=-b/a\)</span>, but there are
no general closed formulas for finding the exact solutions of
nonlinear algebraic equations, except for very special cases (quadratic
equations constitute a primary example). A nonlinear algebraic equation
may have no solution, one solution, or many solutions. The tools for
solving nonlinear algebraic equations are <em>iterative methods</em>, where
we construct a series of linear equations, which we know how to solve,
and hope that the solutions of the linear equations converge to a
solution of the nonlinear equation we want to solve.
Typical methods for nonlinear algebraic equation equations are
Newton&#8217;s method, the Bisection method, and the Secant method.</p>
</div>
<div class="section" id="differential-equations">
<h4>Differential equations<a class="headerlink" href="#differential-equations" title="Permalink to this headline">¶</a></h4>
<p>The unknown in a differential equation is a function and not a number.
In a linear differential equation, all terms involving the unknown function
are linear in the unknown function or its derivatives. Linear here means that
the unknown function, or a derivative of it, is multiplied by a number or
a known function. All other differential equations are non-linear.</p>
<p>The easiest way to see if an equation is nonlinear, is to spot nonlinear terms
where the unknown function or its derivatives are multiplied by
each other. For example, in</p>
<div class="math">
\[u^{\prime}(t) = -a(t)u(t) + b(t),\]</div>
<p>the terms involving the unknown function <span class="math">\(u\)</span> are linear: <span class="math">\(u^{\prime}\)</span> contains
the derivative of the unknown function multiplied by unity, and <span class="math">\(au\)</span> contains
the unknown function multiplied by a known function.
However,</p>
<div class="math">
\[u^{\prime}(t) = u(t)(1 - u(t)),\]</div>
<p>is nonlinear because of the term <span class="math">\(-u^2\)</span> where the unknown function is
multiplied by itself. Also</p>
<div class="math">
\[\frac{\partial u}{\partial t} + u\frac{\partial u}{\partial x} = 0,\]</div>
<p>is nonlinear because of the term <span class="math">\(uu_x\)</span> where the unknown
function appears in a product with its derivative.
(Note here that we use different notations for derivatives: <span class="math">\(u^{\prime}\)</span>
or <span class="math">\(du/dt\)</span> for a function <span class="math">\(u(t)\)</span> of one variable,
<span class="math">\(\frac{\partial u}{\partial t}\)</span> or <span class="math">\(u_t\)</span> for a function of more than one
variable.)</p>
<p>Another example of a nonlinear equation is</p>
<div class="math">
\[u^{\prime\prime} + \sin(u) =0,\]</div>
<p>because <span class="math">\(\sin(u)\)</span> contains products of <span class="math">\(u\)</span>, which becomes clear
if we expand the function in a Taylor series:</p>
<div class="math">
\[\sin(u) = u - \frac{1}{3} u^3 + \ldots\]</div>
<div class="admonition-mathematical-proof-of-linearity admonition">
<p class="first admonition-title">Mathematical proof of linearity</p>
<p>To really prove mathematically that some differential equation
in an unknown <span class="math">\(u\)</span> is linear,
show for each term <span class="math">\(T(u)\)</span> that with <span class="math">\(u = au_1 + bu_2\)</span> for
constants <span class="math">\(a\)</span> and <span class="math">\(b\)</span>,</p>
<div class="math">
\[T(au_1 + bu_2) = aT(u_1) + bT(u_2){\thinspace .}\]</div>
<p>For example, the term <span class="math">\(T(u) = (\sin^2 t)u'(t)\)</span> is linear because</p>
<div class="math">
\[\begin{split}\begin{align*}
T(au_1 + bu_2) &amp;= (\sin^2 t)(au_1(t) + b u_2(t))'\\
&amp; = a(\sin^2 t)u_1'(t) + b(\sin^2 t)u_2'(t)\\
&amp; =aT(u_1) + bT(u_2){\thinspace .}
\end{align*}\end{split}\]</div>
<p>However, <span class="math">\(T(u)=\sin u\)</span> is nonlinear because</p>
<div class="last math">
\[T(au_1 + bu_2) = \sin (au_1 + bu_2) \neq a\sin u_1 + b\sin u_2{\thinspace .}\]</div>
</div>
</div>
</div>
<div class="section" id="a-simple-model-problem">
<h3>A simple model problem<a class="headerlink" href="#a-simple-model-problem" title="Permalink to this headline">¶</a></h3>
<p>A series of forthcoming examples will explain how to tackle
nonlinear differential equations with various techniques.
We start with the (scaled) logistic equation as model problem:</p>
<div class="math" id="eq-nonlin-timediscrete-logistic-eq">
\[\tag{380}
u^{\prime}(t) = u(t)(1 - u(t)) {\thinspace .}\]</div>
<p>This is a nonlinear ordinary differential equation (ODE)
which will be solved by
different strategies in the following.
Depending on the chosen
time discretization of <a class="reference internal" href="#eq-nonlin-timediscrete-logistic-eq"><span class="std std-ref">(380)</span></a>,
the mathematical problem to be solved at every time level will
either be a linear algebraic equation or a nonlinear
algebraic equation.
In the former case, the time discretization method transforms
the nonlinear ODE into linear subproblems at each time level, and
the solution is straightforward to find since linear algebraic equations
are easy to solve. However,
when the time discretization leads to nonlinear algebraic equations, we
cannot (except in very rare cases) solve these without turning to
approximate, iterative solution methods.</p>
<p>The next subsections introduce various methods
for solving nonlinear differential equations,
using <a class="reference internal" href="#eq-nonlin-timediscrete-logistic-eq"><span class="std std-ref">(380)</span></a> as model. We shall go through
the following set of cases:</p>
<blockquote>
<div><ul class="simple">
<li>explicit time discretization methods (with no need to
solve nonlinear algebraic equations)</li>
<li>implicit Backward Euler time discretization, leading to nonlinear
algebraic equations solved by</li>
</ul>
<blockquote>
<div><ul class="simple">
<li>an exact analytical technique</li>
<li>Picard iteration based on manual linearization</li>
<li>a single Picard step</li>
<li>Newton&#8217;s method</li>
</ul>
</div></blockquote>
<ul class="simple">
<li>implicit Crank-Nicolson time discretization and linearization
via a geometric mean formula</li>
</ul>
</div></blockquote>
<p>Thereafter, we compare the performance of the various approaches. Despite
the simplicity of <a class="reference internal" href="#eq-nonlin-timediscrete-logistic-eq"><span class="std std-ref">(380)</span></a>, the conclusions
reveal typical features of the various methods in much more complicated
nonlinear PDE problems.</p>
</div>
<div class="section" id="linearization-by-explicit-time-discretization">
<span id="nonlin-timediscrete-logistic-fe"></span><h3>Linearization by explicit time discretization<a class="headerlink" href="#linearization-by-explicit-time-discretization" title="Permalink to this headline">¶</a></h3>
<p id="index-1">Time discretization methods are divided into explicit and implicit
methods. Explicit methods lead to a closed-form formula for
finding new values of the unknowns, while implicit methods give
a linear or nonlinear system of equations that couples (all) the
unknowns at a new time level. Here we shall demonstrate that
explicit methods may constitute an efficient way to deal with nonlinear
differential equations.</p>
<p>The Forward Euler
method is an explicit method. When applied to
<a class="reference internal" href="#eq-nonlin-timediscrete-logistic-eq"><span class="std std-ref">(380)</span></a>, sampled at <span class="math">\(t=t_n\)</span>, it results in</p>
<div class="math">
\[\frac{u^{n+1} - u^n}{\Delta t} = u^n(1 - u^n),\]</div>
<p>which is a <em>linear</em> algebraic
equation for the unknown value <span class="math">\(u^{n+1}\)</span> that we can easily solve:</p>
<div class="math">
\[u^{n+1} = u^n + \Delta t\,u^n(1 - u^n){\thinspace .}\]</div>
<p>The nonlinearity in the original equation poses in this case no difficulty
in the discrete algebraic equation.
Any other explicit scheme in time will also give only linear
algebraic equations
to solve. For example, a typical 2nd-order Runge-Kutta method
for <a class="reference internal" href="#eq-nonlin-timediscrete-logistic-eq"><span class="std std-ref">(380)</span></a> leads to the following
formulas:</p>
<div class="math">
\[\begin{split}\begin{align*}
u^* &amp;= u^n + \Delta t u^n(1 - u^n),\\
u^{n+1} &amp;= u^n + \Delta t \frac{1}{2} \left(
u^n(1 - u^n) + u^*(1 - u^*))
\right){\thinspace .}
\end{align*}\end{split}\]</div>
<p>The first step is linear in the unknown <span class="math">\(u^*\)</span>. Then <span class="math">\(u^*\)</span> is
known in the next step, which is linear in the unknown <span class="math">\(u^{n+1}\)</span> .</p>
</div>
<div class="section" id="exact-solution-of-nonlinear-algebraic-equations">
<span id="nonlin-timediscrete-logistic-roots"></span><h3>Exact solution of nonlinear algebraic equations<a class="headerlink" href="#exact-solution-of-nonlinear-algebraic-equations" title="Permalink to this headline">¶</a></h3>
<p>Switching to a Backward Euler scheme for
<a class="reference internal" href="#eq-nonlin-timediscrete-logistic-eq"><span class="std std-ref">(380)</span></a>,</p>
<div class="math" id="eq-nonlin-timediscrete-logistic-eq-be">
\[\tag{381}
\frac{u^{n} - u^{n-1}}{\Delta t} = u^n(1 - u^n),\]</div>
<p>results in a nonlinear algebraic equation for the unknown value <span class="math">\(u^n\)</span>.
The equation is of quadratic type:</p>
<div class="math">
\[\Delta t (u^n)^2 + (1-\Delta t)u^n - u^{n-1} = 0,\]</div>
<p>and may be solved exactly by the well-known formula for such equations.
Before we do so, however, we will
introduce a shorter, and often cleaner, notation for
nonlinear algebraic equations at a given time level. The notation is
inspired by the natural notation (i.e., variable names) used in a
program, especially in more advanced partial differential equation
problems. The unknown in the algebraic equation is denoted by <span class="math">\(u\)</span>,
while <span class="math">\(u^{(1)}\)</span> is the value of the unknown at the previous time level
(in general, <span class="math">\(u^{(\ell)}\)</span> is the value of the unknown <span class="math">\(\ell\)</span> levels
back in time). The notation will be frequently used in later
sections. What is meant by <span class="math">\(u\)</span> should be evident from the context: <span class="math">\(u\)</span>
may be 1) the exact solution of the ODE/PDE problem,
2) the numerical approximation to the exact solution, or 3) the unknown
solution at a certain time level.</p>
<p>The quadratic equation for the unknown <span class="math">\(u^n\)</span> in
<a class="reference internal" href="#eq-nonlin-timediscrete-logistic-eq-be"><span class="std std-ref">(381)</span></a> can, with the new
notation, be written</p>
<div class="math" id="eq-nonlin-timediscrete-logistic-eq-f">
\[\tag{382}
F(u) = \Delta t u^2 + (1-\Delta t)u - u^{(1)} = 0{\thinspace .}\]</div>
<p>The solution is readily found to be</p>
<div class="math" id="eq-nonlin-timediscrete-logistic-eq-roots">
\[\tag{383}
u = \frac{1}{2\Delta t}
    \left(-1+\Delta t \pm \sqrt{(1-\Delta t)^2 - 4\Delta t u^{(1)}}\right)
    {\thinspace .}\]</div>
<p>Now we encounter a fundamental challenge with nonlinear
algebraic equations:
the equation may have more than one solution. How do we pick the right
solution? This is in general a hard problem.
In the present simple case, however, we can analyze the roots mathematically
and provide an answer. The idea is to expand the roots
in a series in <span class="math">\(\Delta t\)</span> and truncate after the linear term since
the Backward Euler scheme will introduce an error proportional to
<span class="math">\(\Delta t\)</span> anyway. Using <code class="docutils literal"><span class="pre">sympy</span></code> we find the following Taylor series
expansions of the roots:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sym</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dt</span><span class="p">,</span> <span class="n">u_1</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s1">&#39;dt u_1 u&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r1</span><span class="p">,</span> <span class="n">r2</span> <span class="o">=</span> <span class="n">sym</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">dt</span><span class="o">*</span><span class="n">u</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">dt</span><span class="p">)</span><span class="o">*</span><span class="n">u</span> <span class="o">-</span> <span class="n">u_1</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span>  <span class="c1"># find roots</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r1</span>
<span class="go">(dt - sqrt(dt**2 + 4*dt*u_1 - 2*dt + 1) - 1)/(2*dt)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2</span>
<span class="go">(dt + sqrt(dt**2 + 4*dt*u_1 - 2*dt + 1) - 1)/(2*dt)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">r1</span><span class="o">.</span><span class="n">series</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>    <span class="c1"># 2 terms in dt, around dt=0</span>
<span class="go">-1/dt + 1 - u_1 + dt*(u_1**2 - u_1) + O(dt**2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">r2</span><span class="o">.</span><span class="n">series</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">u_1 + dt*(-u_1**2 + u_1) + O(dt**2)</span>
</pre></div>
</div>
<p>We see that the <code class="docutils literal"><span class="pre">r1</span></code> root, corresponding to
a minus sign in front of the square root in
<a class="reference internal" href="#eq-nonlin-timediscrete-logistic-eq-roots"><span class="std std-ref">(383)</span></a>,
behaves as <span class="math">\(1/\Delta t\)</span> and will therefore
blow up as <span class="math">\(\Delta t\rightarrow 0\)</span>! Since we know that <span class="math">\(u\)</span> takes on
finite values, actually it is less than or equal to 1,
only the <code class="docutils literal"><span class="pre">r2</span></code> root is of relevance in this case: as <span class="math">\(\Delta t\rightarrow 0\)</span>,
<span class="math">\(u\rightarrow u^{(1)}\)</span>, which is the expected result.</p>
<p>For those who are not well experienced with approximating mathematical
formulas by series expansion, an alternative method of investigation
is simply to compute the limits of the two roots as <span class="math">\(\Delta t\rightarrow 0\)</span>
and see if a limit unreasonable:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">r1</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="go">-oo</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">r2</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="go">u_1</span>
</pre></div>
</div>
</div>
<div class="section" id="linearization">
<h3>Linearization<a class="headerlink" href="#linearization" title="Permalink to this headline">¶</a></h3>
<p>When the time integration of an ODE results in a nonlinear algebraic
equation, we must normally find its solution by defining a sequence
of linear equations and hope that the solutions of these linear equations
converge to the desired solution of the nonlinear algebraic equation.
Usually, this means solving the linear equation repeatedly in an
iterative fashion.
Alternatively, the nonlinear equation can sometimes be approximated by one
linear equation, and consequently there is no need for iteration.</p>
<p id="index-2">Constructing a linear equation from a nonlinear one requires
<em>linearization</em> of each nonlinear term. This can be done manually
as in Picard iteration, or fully algorithmically as in Newton&#8217;s method.
Examples will best illustrate how to linearize nonlinear problems.</p>
</div>
<div class="section" id="picard-iteration-1">
<span id="nonlin-timediscrete-logistic-picard"></span><h3>Picard iteration<a class="headerlink" href="#picard-iteration-1" title="Permalink to this headline">¶</a></h3>
<span class="target" id="index-3"></span><span class="target" id="index-4"></span><span class="target" id="index-5"></span><span class="target" id="index-6"></span><span class="target" id="index-7"></span><p id="index-8">Let us write <a class="reference internal" href="#eq-nonlin-timediscrete-logistic-eq-f"><span class="std std-ref">(382)</span></a> in a
more compact form</p>
<div class="math">
\[F(u) = au^2 + bu + c = 0,\]</div>
<p>with <span class="math">\(a=\Delta t\)</span>, <span class="math">\(b=1-\Delta t\)</span>, and <span class="math">\(c=-u^{(1)}\)</span>.
Let <span class="math">\(u^{-}\)</span> be an available approximation of the unknown <span class="math">\(u\)</span>.</p>
<p>Then we can linearize the term <span class="math">\(u^2\)</span> simply by writing
<span class="math">\(u^{-}u\)</span>. The resulting equation, <span class="math">\(\hat F(u)=0\)</span>, is now linear
and hence easy to solve:</p>
<div class="math">
\[F(u)\approx\hat F(u) = au^{-}u + bu + c = 0{\thinspace .}\]</div>
<p>Since the equation <span class="math">\(\hat F=0\)</span> is only approximate, the solution <span class="math">\(u\)</span>
does not equal the exact solution <span class="math">\({u_{\small\mbox{e}}}\)</span> of the exact
equation <span class="math">\(F({u_{\small\mbox{e}}})=0\)</span>, but we can hope that <span class="math">\(u\)</span> is closer to
<span class="math">\({u_{\small\mbox{e}}}\)</span> than <span class="math">\(u^{-}\)</span> is, and hence it makes sense to repeat the
procedure, i.e., set <span class="math">\(u^{-}=u\)</span> and solve <span class="math">\(\hat F(u)=0\)</span> again.
There is no guarantee that <span class="math">\(u\)</span> is closer to <span class="math">\({u_{\small\mbox{e}}}\)</span> than <span class="math">\(u^{-}\)</span>,
but this approach has proven to be effective in a wide range of
applications.</p>
<p>The idea of turning a nonlinear equation into a linear one by
using an approximation <span class="math">\(u^{-}\)</span> of <span class="math">\(u\)</span> in nonlinear terms is
a widely used approach that goes under many names:
<em>fixed-point iteration</em>, the method of <em>successive substitutions</em>,
<em>nonlinear Richardson iteration</em>, and <em>Picard iteration</em>.
We will stick to the latter name.</p>
<p>Picard iteration for solving the nonlinear equation
arising from the Backward Euler discretization of the logistic
equation can be written as</p>
<div class="math">
\[u = -\frac{c}{au^{-} + b},\quad u^{-}\ \leftarrow\ u{\thinspace .}\]</div>
<p>The <span class="math">\(\leftarrow\)</span> symbols means assignment (we set <span class="math">\(u^{-}\)</span> equal to
the value of <span class="math">\(u\)</span>).
The iteration is started with the value of the unknown at the
previous time level: <span class="math">\(u^{-}=u^{(1)}\)</span>.</p>
<p>Some prefer an explicit iteration counter as superscript
in the mathematical notation. Let <span class="math">\(u^k\)</span> be the computed approximation
to the solution in iteration <span class="math">\(k\)</span>. In iteration <span class="math">\(k+1\)</span> we want
to solve</p>
<div class="math">
\[au^k u^{k+1} + bu^{k+1} + c = 0\quad\Rightarrow\quad u^{k+1}
= -\frac{c}{au^k + b},\quad k=0,1,\ldots\]</div>
<p>Since we need to perform the iteration at every time level, the
time level counter is often also included:</p>
<div class="math">
\[au^{n,k} u^{n,k+1} + bu^{n,k+1} - u^{n-1} = 0\quad\Rightarrow\quad u^{n,k+1}
= \frac{u^{n-1}}{au^{n,k} + b},\quad k=0,1,\ldots,\]</div>
<p>with the start value <span class="math">\(u^{n,0}=u^{n-1}\)</span> and the final converged value
<span class="math">\(u^{n}=u^{n,k}\)</span> for sufficiently large <span class="math">\(k\)</span>.</p>
<p>However, we will normally apply a mathematical notation in our
final formulas that is as close as possible to what we aim to write
in a computer code and then it becomes natural to use <span class="math">\(u\)</span> and <span class="math">\(u^{-}\)</span>
instead of <span class="math">\(u^{k+1}\)</span> and <span class="math">\(u^k\)</span> or <span class="math">\(u^{n,k+1}\)</span> and <span class="math">\(u^{n,k}\)</span>.</p>
<div class="section" id="stopping-criteria-1">
<span id="index-9"></span><h4>Stopping criteria<a class="headerlink" href="#stopping-criteria-1" title="Permalink to this headline">¶</a></h4>
<p>The iteration method can typically be terminated when the change
in the solution is smaller than a tolerance <span class="math">\(\epsilon_u\)</span>:</p>
<div class="math">
\[|u - u^{-}| \leq\epsilon_u,\]</div>
<p>or when the residual in the equation is sufficiently small (<span class="math">\(&lt; \epsilon_r\)</span>),</p>
<div class="math">
\[|F(u)|= |au^2+bu + c| &lt; \epsilon_r{\thinspace .}\]</div>
</div>
<div class="section" id="a-single-picard-iteration">
<span id="index-10"></span><h4>A single Picard iteration<a class="headerlink" href="#a-single-picard-iteration" title="Permalink to this headline">¶</a></h4>
<p>Instead of iterating until a stopping criterion is fulfilled, one may
iterate a specific number of times. Just one Picard iteration is
popular as this corresponds to the intuitive idea of approximating a
nonlinear term like <span class="math">\((u^n)^2\)</span> by <span class="math">\(u^{n-1}u^n\)</span>. This follows from the
linearization <span class="math">\(u^{-}u^n\)</span> and the initial choice of <span class="math">\(u^{-}=u^{n-1}\)</span> at
time level <span class="math">\(t_n\)</span>. In other words, a single Picard iteration
corresponds to using the solution at the previous time level to
linearize nonlinear terms. The resulting discretization becomes (using
proper values for <span class="math">\(a\)</span>, <span class="math">\(b\)</span>, and <span class="math">\(c\)</span>)</p>
<div class="math" id="eq-nonlin-timediscrete-logistic-be-picard-1it">
\[\tag{384}
\frac{u^{n} - u^{n-1}}{\Delta t} = u^n(1 - u^{n-1}),\]</div>
<p>which is a linear algebraic equation in the unknown <span class="math">\(u^n\)</span>, making
it easy to solve for <span class="math">\(u^n\)</span> without any need for
any alternative notation.</p>
<p>We shall later refer to the strategy of taking one Picard step, or
equivalently, linearizing terms with use of the solution at the
previous time step, as the <em>Picard1</em> method. It is a widely used
approach in science and technology, but with some limitations if
<span class="math">\(\Delta t\)</span> is not sufficiently small (as will be illustrated later).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Equation <a class="reference internal" href="#eq-nonlin-timediscrete-logistic-be-picard-1it"><span class="std std-ref">(384)</span></a> does not
correspond to a &#8220;pure&#8221; finite difference method where the equation
is sampled at a point and derivatives replaced by differences (because
the <span class="math">\(u^{n-1}\)</span> term on the right-hand side must then be <span class="math">\(u^n\)</span>). The
best interpretation of the scheme
<a class="reference internal" href="#eq-nonlin-timediscrete-logistic-be-picard-1it"><span class="std std-ref">(384)</span></a> is a Backward Euler
difference combined with a single (perhaps insufficient) Picard
iteration at each time level, with the value at the previous time
level as start for the Picard iteration.</p>
</div>
</div>
</div>
<div class="section" id="linearization-by-a-geometric-mean">
<span id="nonlin-timediscrete-logistic-geometric-mean"></span><h3>Linearization by a geometric mean<a class="headerlink" href="#linearization-by-a-geometric-mean" title="Permalink to this headline">¶</a></h3>
<p>We consider now a Crank-Nicolson discretization of
<a class="reference internal" href="#eq-nonlin-timediscrete-logistic-eq"><span class="std std-ref">(380)</span></a>. This means that the
time derivative is approximated by a centered
difference,</p>
<div class="math">
\[[D_t u = u(1-u)]^{n+\frac{1}{2}},\]</div>
<p>written out as</p>
<div class="math" id="eq-nonlin-timediscrete-logistic-geometric-mean-scheme">
\[\tag{385}
\frac{u^{n+1}-u^n}{\Delta t} = u^{n+\frac{1}{2}} -
    (u^{n+\frac{1}{2}})^2{\thinspace .}\]</div>
<p>The first term <span class="math">\(u^{n+\frac{1}{2}}\)</span> is normally approximated by an arithmetic
mean,</p>
<div class="math">
\[u^{n+\frac{1}{2}}\approx \frac{1}{2}(u^n + u^{n+1}),\]</div>
<p>such that the scheme involves the unknown function only at the time levels
where we actually compute it.
The same arithmetic mean applied to the second term gives</p>
<div class="math">
\[(u^{n+\frac{1}{2}})^2\approx \frac{1}{4}(u^n + u^{n+1})^2,\]</div>
<p>which is nonlinear in the unknown <span class="math">\(u^{n+1}\)</span>.
However, using a <em>geometric mean</em> for <span class="math">\((u^{n+\frac{1}{2}})^2\)</span>
is a way of linearizing the nonlinear term in
<a class="reference internal" href="#eq-nonlin-timediscrete-logistic-geometric-mean-scheme"><span class="std std-ref">(385)</span></a>:</p>
<div class="math">
\[(u^{n+\frac{1}{2}})^2\approx u^nu^{n+1}{\thinspace .}\]</div>
<p>Using an arithmetic mean on the linear <span class="math">\(u^{n+\frac{1}{2}}\)</span> term in
<a class="reference internal" href="#eq-nonlin-timediscrete-logistic-geometric-mean-scheme"><span class="std std-ref">(385)</span></a> and a geometric
mean for the second term, results in a linearized equation for the
unknown <span class="math">\(u^{n+1}\)</span>:</p>
<div class="math">
\[\frac{u^{n+1}-u^n}{\Delta t} =
\frac{1}{2}(u^n + u^{n+1}) - u^nu^{n+1},\]</div>
<p>which can readily be solved:</p>
<div class="math">
\[u^{n+1} = \frac{1 + \frac{1}{2}\Delta t}{1+\Delta t u^n - \frac{1}{2}\Delta t}
u^n{\thinspace .}\]</div>
<p>This scheme can be coded directly, and since
there is no nonlinear algebraic equation to iterate over,
we skip the simplified notation with <span class="math">\(u\)</span> for <span class="math">\(u^{n+1}\)</span>
and <span class="math">\(u^{(1)}\)</span> for <span class="math">\(u^n\)</span>. The technique with using
a geometric average is an example of transforming a nonlinear
algebraic equation to a linear one, without any need for iterations.</p>
<p>The geometric mean approximation is often very effective for
linearizing quadratic nonlinearities. Both the arithmetic and geometric mean
approximations have truncation errors of order <span class="math">\(\Delta t^2\)</span> and are
therefore compatible with the truncation error <span class="math">\({\mathcal{O}(\Delta t^2)}\)</span>
of the centered difference approximation for <span class="math">\(u^\prime\)</span> in the Crank-Nicolson
method.</p>
<p>Applying the operator notation for the means and finite differences,
the linearized Crank-Nicolson scheme for the logistic equation can be
compactly expressed as</p>
<div class="math">
\[[D_t u = \overline{u}^{t} + \overline{u^2}^{t,g}]^{n+\frac{1}{2}}{\thinspace .}\]</div>
<div class="admonition-remark admonition">
<p class="first admonition-title">Remark</p>
<p class="last">If we use an arithmetic instead of a geometric mean
for the nonlinear term in
<a class="reference internal" href="#eq-nonlin-timediscrete-logistic-geometric-mean-scheme"><span class="std std-ref">(385)</span></a>,
we end up with a nonlinear term <span class="math">\((u^{n+1})^2\)</span>.
This term can be linearized as <span class="math">\(u^{-}u^{n+1}\)</span> in a Picard iteration
approach and in particular as
<span class="math">\(u^nu^{n+1}\)</span> in a Picard1 iteration approach.
The latter gives a scheme almost identical to the one arising from
a geometric mean (the difference in <span class="math">\(u^{n+1}\)</span>
being <span class="math">\(\frac{1}{4}\Delta t u^n(u^{n+1}-u^n)\approx \frac{1}{4}\Delta t^2
u^\prime u\)</span>, i.e., a difference of size <span class="math">\(\Delta t^2\)</span>).</p>
</div>
<p>[<strong>kam 35</strong>: this is the first time I&#8217;ve seen this <span class="math">\(\overline{u}^t\)</span> notation. It is not in the appendix either.]</p>
</div>
<div class="section" id="newton-s-method-1">
<span id="nonlin-timediscrete-logistic-newton"></span><h3>Newton&#8217;s method<a class="headerlink" href="#newton-s-method-1" title="Permalink to this headline">¶</a></h3>
<p>The Backward Euler scheme <a class="reference internal" href="#eq-nonlin-timediscrete-logistic-eq-be"><span class="std std-ref">(381)</span></a>
for the logistic equation leads to a nonlinear algebraic equation
<a class="reference internal" href="#eq-nonlin-timediscrete-logistic-eq-f"><span class="std std-ref">(382)</span></a>. Now we write any nonlinear
algebraic equation in the general and compact form</p>
<div class="math">
\[F(u) = 0{\thinspace .}\]</div>
<p>Newton&#8217;s method linearizes this equation by approximating <span class="math">\(F(u)\)</span> by
its Taylor series expansion around a computed value <span class="math">\(u^{-}\)</span>
and keeping only the linear part:</p>
<div class="math">
\[\begin{split}\begin{align*}
F(u) &amp;= F(u^{-}) + F^{\prime}(u^{-})(u - u^{-}) + {\frac{1}{2}}F^{\prime\prime}(u^{-})(u-u^{-})^2
+\cdots\\
&amp; \approx F(u^{-}) + F^{\prime}(u^{-})(u - u^{-}) = \hat F(u){\thinspace .}
\end{align*}\end{split}\]</div>
<p>The linear equation <span class="math">\(\hat F(u)=0\)</span> has the solution</p>
<div class="math">
\[u = u^{-} - \frac{F(u^{-})}{F^{\prime}(u^{-})}{\thinspace .}\]</div>
<p>Expressed with an iteration index in the unknown, Newton&#8217;s method takes
on the more familiar mathematical form</p>
<div class="math">
\[u^{k+1} = u^k - \frac{F(u^k)}{F^{\prime}(u^k)},\quad k=0,1,\ldots\]</div>
<p>It can be shown that the error in iteration <span class="math">\(k+1\)</span> of Newton&#8217;s method is
proportional to
the square of the error in iteration <span class="math">\(k\)</span>, a result referred to as
<em>quadratic convergence</em>. This means that for
small errors the method converges very fast, and in particular much
faster than Picard iteration and other iteration methods.
(The proof of this result is found in most textbooks on numerical analysis.)
However, the quadratic convergence appears only if <span class="math">\(u^k\)</span> is sufficiently
close to the solution. Further away from the solution the method can
easily converge very slowly or diverge. The reader is encouraged to do
<a class="reference internal" href="._book032.html#nonlin-exer-newton-problems1"><span class="std std-ref">Problem 43: Experience the behavior of Newton&#8217;s method</span></a> to get a better understanding
for the behavior of the method.</p>
<p>Application of Newton&#8217;s method to the logistic equation discretized
by the Backward Euler method is straightforward
as we have</p>
<div class="math">
\[F(u) = au^2 + bu + c,\quad a=\Delta t,\ b = 1-\Delta t,\ c=-u^{(1)},\]</div>
<p>and then</p>
<div class="math">
\[F^{\prime}(u) = 2au + b{\thinspace .}\]</div>
<p>The iteration method becomes</p>
<div class="math" id="eq-nonlin-timediscrete-logistic-newton-alg1">
\[\tag{386}
u = u^{-} + \frac{a(u^{-})^2 + bu^{-} + c}{2au^{-} + b},\quad
    u^{-}\ \leftarrow u{\thinspace .}\]</div>
<p>At each time level, we start the iteration by setting <span class="math">\(u^{-}=u^{(1)}\)</span>.
Stopping criteria as listed for the Picard iteration can be used also
for Newton&#8217;s method.</p>
<p>An alternative mathematical form, where we write out <span class="math">\(a\)</span>, <span class="math">\(b\)</span>, and <span class="math">\(c\)</span>,
and use a time level counter <span class="math">\(n\)</span> and an iteration counter <span class="math">\(k\)</span>, takes
the form</p>
<div class="math" id="eq-nonlin-timediscrete-logistic-newton-alg2">
\[\tag{387}
u^{n,k+1} = u^{n,k} +
    \frac{\Delta t (u^{n,k})^2 + (1-\Delta t)u^{n,k} - u^{n-1}}
    {2\Delta t u^{n,k} + 1 - \Delta t},\quad u^{n,0}=u^{n-1},\]</div>
<p>for <span class="math">\(k=0,1,\ldots\)</span>.
A program implementation is much closer to <a class="reference internal" href="#eq-nonlin-timediscrete-logistic-newton-alg1"><span class="std std-ref">(386)</span></a> than to <a class="reference internal" href="#eq-nonlin-timediscrete-logistic-newton-alg2"><span class="std std-ref">(387)</span></a>, but
the latter is better aligned with the established mathematical
notation used in the literature.</p>
</div>
<div class="section" id="relaxation">
<span id="nonlin-timediscrete-logistic-relaxation"></span><h3>Relaxation<a class="headerlink" href="#relaxation" title="Permalink to this headline">¶</a></h3>
<p id="index-11">One iteration in Newton&#8217;s method or
Picard iteration consists of solving a linear problem <span class="math">\(\hat F(u)=0\)</span>.
Sometimes convergence problems arise because the new solution <span class="math">\(u\)</span>
of <span class="math">\(\hat F(u)=0\)</span> is &#8220;too far away&#8221; from the previously computed
solution <span class="math">\(u^{-}\)</span>. A remedy is to introduce a relaxation, meaning that
we first solve <span class="math">\(\hat F(u^*)=0\)</span> for a suggested value <span class="math">\(u^*\)</span> and
then we take <span class="math">\(u\)</span> as a weighted mean of what we had, <span class="math">\(u^{-}\)</span>, and
what our linearized equation <span class="math">\(\hat F=0\)</span> suggests, <span class="math">\(u^*\)</span>:</p>
<div class="math">
\[u = \omega u^* + (1-\omega) u^{-}{\thinspace .}\]</div>
<p>The parameter <span class="math">\(\omega\)</span>
is known as a <em>relaxation parameter</em>, and a choice <span class="math">\(\omega &lt; 1\)</span>
may prevent divergent iterations.</p>
<p>Relaxation in Newton&#8217;s method can be directly incorporated
in the basic iteration formula:</p>
<div class="math" id="eq-nonlin-timediscrete-logistic-relaxation-newton-formula">
\[\tag{388}
u = u^{-} - \omega \frac{F(u^{-})}{F^{\prime}(u^{-})}{\thinspace .}\]</div>
</div>
<div class="section" id="implementation-and-experiments">
<span id="nonlin-timediscrete-logistic-impl"></span><h3>Implementation and experiments<a class="headerlink" href="#implementation-and-experiments" title="Permalink to this headline">¶</a></h3>
<p>The program <a class="reference external" href="http://tinyurl.com/znpudbt/logistic.py">logistic.py</a> contains
implementations of all the methods described above.
Below is an extract of the file showing how the Picard and Newton
methods are implemented for a Backward Euler discretization of
the logistic equation.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">BE_logistic</span><span class="p">(</span><span class="n">u0</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">Nt</span><span class="p">,</span> <span class="n">choice</span><span class="o">=</span><span class="s1">&#39;Picard&#39;</span><span class="p">,</span>
                <span class="n">eps_r</span><span class="o">=</span><span class="mf">1E-3</span><span class="p">,</span> <span class="n">omega</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">choice</span> <span class="o">==</span> <span class="s1">&#39;Picard1&#39;</span><span class="p">:</span>
        <span class="n">choice</span> <span class="o">=</span> <span class="s1">&#39;Picard&#39;</span>
        <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Nt</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">iterations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">u</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">u0</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Nt</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">dt</span>
        <span class="n">b</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">dt</span>
        <span class="n">c</span> <span class="o">=</span> <span class="o">-</span><span class="n">u</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">choice</span> <span class="o">==</span> <span class="s1">&#39;Picard&#39;</span><span class="p">:</span>

            <span class="k">def</span> <span class="nf">F</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">a</span><span class="o">*</span><span class="n">u</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">b</span><span class="o">*</span><span class="n">u</span> <span class="o">+</span> <span class="n">c</span>

            <span class="n">u_</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="nb">abs</span><span class="p">(</span><span class="n">F</span><span class="p">(</span><span class="n">u_</span><span class="p">))</span> <span class="o">&gt;</span> <span class="n">eps_r</span> <span class="ow">and</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">:</span>
                <span class="n">u_</span> <span class="o">=</span> <span class="n">omega</span><span class="o">*</span><span class="p">(</span><span class="o">-</span><span class="n">c</span><span class="o">/</span><span class="p">(</span><span class="n">a</span><span class="o">*</span><span class="n">u_</span> <span class="o">+</span> <span class="n">b</span><span class="p">))</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">omega</span><span class="p">)</span><span class="o">*</span><span class="n">u_</span>
                <span class="n">k</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">u</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">u_</span>
            <span class="n">iterations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">choice</span> <span class="o">==</span> <span class="s1">&#39;Newton&#39;</span><span class="p">:</span>

            <span class="k">def</span> <span class="nf">F</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">a</span><span class="o">*</span><span class="n">u</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">b</span><span class="o">*</span><span class="n">u</span> <span class="o">+</span> <span class="n">c</span>

            <span class="k">def</span> <span class="nf">dF</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
                <span class="k">return</span> <span class="mi">2</span><span class="o">*</span><span class="n">a</span><span class="o">*</span><span class="n">u</span> <span class="o">+</span> <span class="n">b</span>

            <span class="n">u_</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="nb">abs</span><span class="p">(</span><span class="n">F</span><span class="p">(</span><span class="n">u_</span><span class="p">))</span> <span class="o">&gt;</span> <span class="n">eps_r</span> <span class="ow">and</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">:</span>
                <span class="n">u_</span> <span class="o">=</span> <span class="n">u_</span> <span class="o">-</span> <span class="n">F</span><span class="p">(</span><span class="n">u_</span><span class="p">)</span><span class="o">/</span><span class="n">dF</span><span class="p">(</span><span class="n">u_</span><span class="p">)</span>
                <span class="n">k</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">u</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">u_</span>
            <span class="n">iterations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">,</span> <span class="n">iterations</span>
</pre></div>
</div>
<p>The Crank-Nicolson method utilizing a linearization based on the
geometric mean gives a simpler algorithm:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">CN_logistic</span><span class="p">(</span><span class="n">u0</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">Nt</span><span class="p">):</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Nt</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">u</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">u0</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">Nt</span><span class="p">):</span>
        <span class="n">u</span><span class="p">[</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">dt</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">dt</span><span class="o">*</span><span class="n">u</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">-</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">dt</span><span class="p">)</span><span class="o">*</span><span class="n">u</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
<p>We may run experiments with the model problem
<a class="reference internal" href="#eq-nonlin-timediscrete-logistic-eq"><span class="std std-ref">(380)</span></a> and the different strategies for
dealing with nonlinearities as described above. For a quite coarse
time resolution, <span class="math">\(\Delta t=0.9\)</span>, use of a tolerance <span class="math">\(\epsilon_r=0.05\)</span>
in the stopping criterion introduces an iteration error, especially in
the Picard iterations, that is visibly much larger than the
time discretization error due to a large <span class="math">\(\Delta t\)</span>. This is illustrated
by comparing the upper two plots in
Figure <a class="reference internal" href="#nonlin-timediscrete-logistic-impl-fig-u"><span class="std std-ref">Impact of solution strategy and time step length on the solution</span></a>. The one to
the right has a stricter tolerance <span class="math">\(\epsilon = 10^{-3}\)</span>, which leads
to all the curves corresponding to Picard and Newton iteration to be
on top of each other (and no changes can be visually observed by
reducing <span class="math">\(\epsilon_r\)</span> further). The reason why Newton&#8217;s method does
much better than Picard iteration in the upper left plot is that
Newton&#8217;s method with one step comes far below the <span class="math">\(\epsilon_r\)</span> tolerance,
while the Picard iteration needs on average 7 iterations to bring the
residual down to <span class="math">\(\epsilon_r=10^{-1}\)</span>, which gives insufficient
accuracy in the solution of the nonlinear equation. It is obvious
that the Picard1 method gives significant errors in addition to
the time discretization unless the time step is as small as in
the lower right plot.</p>
<p>The <em>BE exact</em> curve corresponds to using the exact solution of the
quadratic equation at each time level, so this curve is only affected
by the Backward Euler time discretization.  The <em>CN gm</em> curve
corresponds to the theoretically more accurate Crank-Nicolson
discretization, combined with a geometric mean for linearization.
This curve appears more accurate, especially if we take the plot in
the lower right with a small <span class="math">\(\Delta t\)</span> and an appropriately small
<span class="math">\(\epsilon_r\)</span> value as the exact curve.</p>
<p>When it comes to the need for iterations, Figure
<a class="reference internal" href="#nonlin-timediscrete-logistic-impl-fig-iter"><span class="std std-ref">Comparison of the number of iterations at various time levels for Picard and Newton iteration</span></a> displays the number of
iterations required at each time level for Newton&#8217;s method and
Picard iteration. The smaller <span class="math">\(\Delta t\)</span> is, the better starting value
we have for the iteration, and the faster the convergence is.
With <span class="math">\(\Delta t = 0.9\)</span> Picard iteration requires on average 32 iterations
per time step for the stricter convergence criterion, but this number is dramatically reduced as <span class="math">\(\Delta t\)</span>
is reduced.</p>
<p>However, introducing relaxation and a parameter <span class="math">\(\omega=0.8\)</span>
immediately reduces the average of 32 to 7, indicating that for the large
<span class="math">\(\Delta t=0.9\)</span>, Picard iteration takes too long steps. An approximately optimal
value for <span class="math">\(\omega\)</span> in this case is 0.5, which results in an average of only
2 iterations! An even more dramatic impact of <span class="math">\(\omega\)</span> appears when
<span class="math">\(\Delta t = 1\)</span>: Picard iteration does not convergence in 1000 iterations,
but <span class="math">\(\omega=0.5\)</span> again brings the average number of iterations down to 2.</p>
<div class="figure" id="id8">
<span id="nonlin-timediscrete-logistic-impl-fig-u"></span><a class="reference internal image-reference" href="_images/logistic_u.png"><img alt="_images/logistic_u.png" src="_images/logistic_u.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text"><em>Impact of solution strategy and time step length on the solution</em></span></p>
</div>
<div class="figure" id="id9">
<span id="nonlin-timediscrete-logistic-impl-fig-iter"></span><a class="reference internal image-reference" href="_images/logistic_iter.png"><img alt="_images/logistic_iter.png" src="_images/logistic_iter.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text"><em>Comparison of the number of iterations at various time levels for Picard and Newton iteration</em></span></p>
</div>
<p>[<strong>hpl 36</strong>: Is this remark really relevant now? Compare with text.]</p>
<p><strong>Remark.</strong>
The simple Crank-Nicolson method with a geometric mean for the quadratic
nonlinearity gives visually more accurate solutions than the
Backward Euler discretization. Even with a tolerance of <span class="math">\(\epsilon_r=10^{-3}\)</span>,
all the methods for treating the nonlinearities in the Backward Euler
discretization give graphs that cannot be distinguished. So for
accuracy in this problem, the time discretization is much more crucial
than <span class="math">\(\epsilon_r\)</span>. Ideally, one should estimate the error in the
time discretization, as the solution progresses, and set <span class="math">\(\epsilon_r\)</span>
accordingly.</p>
</div>
<div class="section" id="generalization-to-a-general-nonlinear-ode">
<span id="nonlin-ode-generic"></span><h3>Generalization to a general nonlinear ODE<a class="headerlink" href="#generalization-to-a-general-nonlinear-ode" title="Permalink to this headline">¶</a></h3>
<p>Let us see how the various methods in the previous sections
can be applied to the more generic model</p>
<div class="math" id="eq-nonlin-ode-generic-model">
\[\tag{389}
u^{\prime} = f(u, t),\]</div>
<p>where <span class="math">\(f\)</span> is a nonlinear function of <span class="math">\(u\)</span>.</p>
<div class="section" id="explicit-time-discretization">
<h4>Explicit time discretization<a class="headerlink" href="#explicit-time-discretization" title="Permalink to this headline">¶</a></h4>
<p>Explicit ODE methods like the Forward Euler scheme, Runge-Kutta methods,
Adams-Bashforth methods all evaluate <span class="math">\(f\)</span> at time levels where
<span class="math">\(u\)</span> is already computed, so nonlinearities in <span class="math">\(f\)</span> do not
pose any difficulties.</p>
</div>
<div class="section" id="backward-euler-discretization-2">
<h4>Backward Euler discretization<a class="headerlink" href="#backward-euler-discretization-2" title="Permalink to this headline">¶</a></h4>
<p>Approximating <span class="math">\(u^{\prime}\)</span> by a backward difference leads to a Backward Euler
scheme, which can be written as</p>
<div class="math">
\[F(u^n) = u^{n} - \Delta t\, f(u^n, t_n) - u^{n-1}=0,\]</div>
<p>or alternatively</p>
<div class="math">
\[F(u) = u - \Delta t\, f(u, t_n) - u^{(1)} = 0{\thinspace .}\]</div>
<p>A simple Picard iteration, not knowing anything about the nonlinear
structure of <span class="math">\(f\)</span>, must approximate <span class="math">\(f(u,t_n)\)</span> by <span class="math">\(f(u^{-},t_n)\)</span>:</p>
<div class="math">
\[\hat F(u) = u - \Delta t\, f(u^{-},t_n) - u^{(1)}{\thinspace .}\]</div>
<p>The iteration starts with <span class="math">\(u^{-}=u^{(1)}\)</span> and proceeds with repeating</p>
<div class="math">
\[u^* = \Delta t\, f(u^{-},t_n) + u^{(1)},\quad u = \omega u^* + (1-\omega)u^{-},
\quad u^{-}\ \leftarrow\ u,\]</div>
<p>until a stopping criterion is fulfilled.</p>
<div class="admonition-explicit-vs-implicit-treatment-of-nonlinear-terms admonition">
<p class="first admonition-title">Explicit vs implicit treatment of nonlinear terms</p>
<p>Evaluating <span class="math">\(f\)</span> for a known <span class="math">\(u^{-}\)</span> is referred to as <em>explicit</em> treatment of
<span class="math">\(f\)</span>, while if <span class="math">\(f(u,t)\)</span> has some structure, say <span class="math">\(f(u,t) = u^3\)</span>, parts of
<span class="math">\(f\)</span> can involve the known <span class="math">\(u\)</span>, as in the manual linearization
like <span class="math">\((u^{-})^2u\)</span>, and then the treatment of <span class="math">\(f\)</span> is &#8220;more implicit&#8221;
and &#8220;less explicit&#8221;. This terminology is inspired by time discretization
of <span class="math">\(u^{\prime}=f(u,t)\)</span>, where evaluating <span class="math">\(f\)</span> for known <span class="math">\(u\)</span> values gives
explicit schemes, while treating <span class="math">\(f\)</span> or parts of <span class="math">\(f\)</span> implicitly,
makes <span class="math">\(f\)</span> contribute to the unknown terms in the equation at the new
time level.</p>
<p>Explicit treatment of <span class="math">\(f\)</span> usually means stricter conditions on
<span class="math">\(\Delta t\)</span> to achieve stability of time discretization schemes. The same
applies to iteration techniques for nonlinear algebraic equations: the &#8220;less&#8221;
we linearize <span class="math">\(f\)</span> (i.e., the more we keep of <span class="math">\(u\)</span> in the original formula),
the faster the convergence may be.</p>
<p>We may say that <span class="math">\(f(u,t)=u^3\)</span> is treated explicitly if we evaluate <span class="math">\(f\)</span>
as <span class="math">\((u^{-})^3\)</span>, partially implicit if we linearize as <span class="math">\((u^{-})^2u\)</span>
and fully implicit if we represent <span class="math">\(f\)</span> by <span class="math">\(u^3\)</span>. (Of course, the
fully implicit representation will require further linearization,
but with <span class="math">\(f(u,t)=u^2\)</span> a fully implicit treatment is possible if
the resulting quadratic equation is solved with a formula.)</p>
<p>For the ODE <span class="math">\(u^{\prime}=-u^3\)</span> with <span class="math">\(f(u,t)=-u^3\)</span> and coarse
time resolution <span class="math">\(\Delta t = 0.4\)</span>, Picard iteration with <span class="math">\((u^{-})^2u\)</span>
requires 8 iterations with <span class="math">\(\epsilon_r = 10^{-3}\)</span> for the first
time step, while <span class="math">\((u^{-})^3\)</span> leads to 22 iterations. After about 10
time steps both approaches are down to about 2 iterations per time
step, but this example shows a potential of treating <span class="math">\(f\)</span> more
implicitly.</p>
<p class="last">A trick to treat <span class="math">\(f\)</span> implicitly in Picard iteration is to
evaluate it as <span class="math">\(f(u^{-},t)u/u^{-}\)</span>. For a polynomial <span class="math">\(f\)</span>, <span class="math">\(f(u,t)=u^m\)</span>,
this corresponds to <span class="math">\((u^{-})^{m}u/u^{-}=(u^{-})^{m-1}u\)</span>. Sometimes this more implicit
treatment has no effect, as with <span class="math">\(f(u,t)=\exp(-u)\)</span> and <span class="math">\(f(u,t)=\ln (1+u)\)</span>,
but with <span class="math">\(f(u,t)=\sin(2(u+1))\)</span>, the <span class="math">\(f(u^{-},t)u/u^{-}\)</span> trick
leads to 7, 9, and 11 iterations during the first three steps, while
<span class="math">\(f(u^{-},t)\)</span> demands 17, 21, and 20 iterations.
(Experiments can be done with the code <a class="reference external" href="http://tinyurl.com/znpudbt/ODE_Picard_tricks.py">ODE_Picard_tricks.py</a>.)</p>
</div>
<p>Newton&#8217;s method applied to a Backward Euler discretization of
<span class="math">\(u^{\prime}=f(u,t)\)</span>
requires the computation of the derivative</p>
<div class="math">
\[F^{\prime}(u) = 1 - \Delta t\frac{\partial f}{\partial u}(u,t_n){\thinspace .}\]</div>
<p>Starting with the solution at the previous time level, <span class="math">\(u^{-}=u^{(1)}\)</span>,
we can just use the standard formula</p>
<div class="math" id="eq-nonlin-ode-generic-newton">
\[\tag{390}
u = u^{-} - \omega \frac{F(u^{-})}{F^{\prime}(u^{-})}
    = u^{-} - \omega \frac{u^{-} - \Delta t\, f(u^{-}, t_n) - u^{(1)}}{1 - \Delta t
    \frac{\partial}{\partial u}f(u^{-},t_n)}
    {\thinspace .}\]</div>
</div>
<div class="section" id="crank-nicolson-discretization-1">
<h4>Crank-Nicolson discretization<a class="headerlink" href="#crank-nicolson-discretization-1" title="Permalink to this headline">¶</a></h4>
<p>The standard Crank-Nicolson scheme with arithmetic mean approximation of
<span class="math">\(f\)</span> takes the form</p>
<div class="math">
\[\frac{u^{n+1} - u^n}{\Delta t} = \frac{1}{2}(f(u^{n+1}, t_{n+1})
+ f(u^n, t_n)){\thinspace .}\]</div>
<p>We can write the scheme as a nonlinear algebraic equation</p>
<div class="math" id="eq-nonlin-ode-generic-newton2">
\[\tag{391}
F(u) = u - u^{(1)} - \Delta t{\frac{1}{2}}f(u,t_{n+1}) -
    \Delta t{\frac{1}{2}}f(u^{(1)},t_{n}) = 0{\thinspace .}\]</div>
<p>A Picard iteration scheme must in general employ the linearization</p>
<div class="math">
\[\hat F(u) = u - u^{(1)} - \Delta t{\frac{1}{2}}f(u^{-},t_{n+1}) -
\Delta t{\frac{1}{2}}f(u^{(1)},t_{n}),\]</div>
<p>while Newton&#8217;s method can apply the general formula
<a class="reference internal" href="#eq-nonlin-ode-generic-newton"><span class="std std-ref">(390)</span></a> with <span class="math">\(F(u)\)</span> given in
<a class="reference internal" href="#eq-nonlin-ode-generic-newton2"><span class="std std-ref">(391)</span></a> and</p>
<div class="math">
\[F^{\prime}(u)= 1 - \frac{1}{2}\Delta t\frac{\partial f}{\partial u}(u,t_{n+1}){\thinspace .}\]</div>
</div>
</div>
<div class="section" id="systems-of-odes">
<span id="nonlin-ode-generic-sys-pendulum"></span><h3>Systems of ODEs<a class="headerlink" href="#systems-of-odes" title="Permalink to this headline">¶</a></h3>
<p>We may write a system of ODEs</p>
<div class="math">
\[\begin{split}\begin{align*}
\frac{d}{dt}u_0(t) &amp;= f_0(u_0(t),u_1(t),\ldots,u_N(t),t),\\
\frac{d}{dt}u_1(t) &amp;= f_1(u_0(t),u_1(t),\ldots,u_N(t),t),\\
&amp;\vdots\\
\frac{d}{dt}u_m(t) &amp;= f_m(u_0(t),u_1(t),\ldots,u_N(t),t),
\end{align*}\end{split}\]</div>
<p>as</p>
<div class="math" id="eq-auto155">
\[\tag{392}
u^{\prime} = f(u,t),\quad u(0)=U_0,\]</div>
<p>if we interpret <span class="math">\(u\)</span> as a vector <span class="math">\(u=(u_0(t),u_1(t),\ldots,u_N(t))\)</span>
and <span class="math">\(f\)</span> as a vector function with components
<span class="math">\((f_0(u,t),f_1(u,t),\ldots,f_N(u,t))\)</span>.</p>
<p>[<strong>kam 37</strong>: Here we don&#8217;t use bf]</p>
<p>Most solution methods for scalar ODEs, including
the Forward and Backward Euler schemes and the
Crank-Nicolson method, generalize in a
straightforward way to systems of ODEs simply by using vector
arithmetics instead of scalar arithmetics, which corresponds to
applying the scalar scheme to each component of the system.  For
example, here is a backward difference scheme applied to each
component,</p>
<p>[<strong>kam 38</strong>: I think we should write $f_0(u_0^n, ldots, u_N,t_n)$]</p>
<div class="math">
\[\begin{split}\begin{align*}
\frac{u_0^n- u_0^{n-1}}{\Delta t} &amp;= f_0(u^n,t_n),\\
\frac{u_1^n- u_1^{n-1}}{\Delta t} &amp;= f_1(u^n,t_n),\\
&amp;\vdots\\
\frac{u_N^n- u_N^{n-1}}{\Delta t} &amp;= f_N(u^n,t_n),
\end{align*}\end{split}\]</div>
<p>which can be written more compactly in vector form as</p>
<div class="math">
\[\frac{u^n- u^{n-1}}{\Delta t} = f(u^n,t_n){\thinspace .}\]</div>
<p>This is a <em>system of algebraic equations</em>,</p>
<div class="math">
\[u^n - \Delta t\,f(u^n,t_n) - u^{n-1}=0,\]</div>
<p>or written out</p>
<div class="math">
\[\begin{split}\begin{align*}
u_0^n - \Delta t\, f_0(u^n,t_n) - u_0^{n-1} &amp;= 0,\\
&amp;\vdots\\
u_N^n - \Delta t\, f_N(u^n,t_n) - u_N^{n-1} &amp;= 0{\thinspace .}
\end{align*}\end{split}\]</div>
<div class="section" id="example-5">
<h4>Example<a class="headerlink" href="#example-5" title="Permalink to this headline">¶</a></h4>
<p>We shall address the <span class="math">\(2\times 2\)</span> ODE system for
oscillations of a pendulum
subject to gravity and air drag. The system can be written as</p>
<div class="math" id="eq-auto156">
\[\tag{393}
\dot\omega = -\sin\theta -\beta \omega |\omega|,\]</div>
<div class="math" id="eq-auto157">
\[\tag{394}
\dot\theta = \omega,\]</div>
<p>where <span class="math">\(\beta\)</span> is a dimensionless parameter (this is the scaled, dimensionless
version of the original, physical model). The unknown components of the
system are the
angle <span class="math">\(\theta(t)\)</span> and the angular velocity <span class="math">\(\omega(t)\)</span>.
We introduce <span class="math">\(u_0=\omega\)</span> and <span class="math">\(u_1=\theta\)</span>, which leads to</p>
<div class="math">
\[\begin{split}\begin{align*}
u_0^{\prime} = f_0(u,t) &amp;= -\sin u_1 - \beta u_0|u_0|,\\
u_1^{\prime} = f_1(u,t) &amp;= u_0{\thinspace .}
\end{align*}\end{split}\]</div>
<p>A Crank-Nicolson scheme reads</p>
<div class="math">
\[\frac{u_0^{n+1}-u_0^{n}}{\Delta t} = -\sin u_1^{n+\frac{1}{2}}
- \beta u_0^{n+\frac{1}{2}}|u_0^{n+\frac{1}{2}}|\nonumber\]</div>
<div class="math" id="eq-auto158">
\[\tag{395}
\approx -\sin\left(\frac{1}{2}(u_1^{n+1} + u_1^n)\right)
    - \beta\frac{1}{4} (u_0^{n+1} + u_0^n)|u_0^{n+1}+u_0^n|,\]</div>
<div class="math" id="eq-auto159">
\[\tag{396}
\frac{u_1^{n+1}-u_1^n}{\Delta t} = u_0^{n+\frac{1}{2}}\approx
    \frac{1}{2} (u_0^{n+1}+u_0^n){\thinspace .}\]</div>
<p>This is a <em>coupled system</em> of two nonlinear algebraic equations
in two unknowns <span class="math">\(u_0^{n+1}\)</span> and <span class="math">\(u_1^{n+1}\)</span>.</p>
<p>Using the notation <span class="math">\(u_0\)</span> and <span class="math">\(u_1\)</span> for the unknowns <span class="math">\(u_0^{n+1}\)</span> and
<span class="math">\(u_1^{n+1}\)</span> in this system, writing <span class="math">\(u_0^{(1)}\)</span> and
<span class="math">\(u_1^{(1)}\)</span> for the previous values <span class="math">\(u_0^n\)</span> and <span class="math">\(u_1^n\)</span>, multiplying
by <span class="math">\(\Delta t\)</span> and moving the terms to the left-hand sides, gives</p>
<div class="math" id="eq-nonlin-ode-generic-sys-pendulum-u0">
\[\tag{397}
u_0 - u_0^{(1)} + \Delta t\,\sin\left(\frac{1}{2}(u_1 + u_1^{(1)})\right)
    + \frac{1}{4}\Delta t\beta (u_0 + u_0^{(1)})|u_0 + u_0^{(1)}| =0,\]</div>
<div class="math" id="eq-nonlin-ode-generic-sys-pendulum-u1">
\[\tag{398}
u_1 - u_1^{(1)} -\frac{1}{2}\Delta t(u_0 + u_0^{(1)}) =0{\thinspace .}\]</div>
<p>Obviously, we have a need for solving systems of nonlinear algebraic
equations, which is the topic of the next section.</p>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <center>
            <p class="logo"><a href="http://cbc.simula.no/" title="Go to Center for Biomedical Computing">
              <img class="logo" src="_static/cbc_logo.png" alt="Logo"/>
            </a></p>
            </center>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Variational forms for systems of PDEs</a><ul>
<li><a class="reference internal" href="#variational-forms-3">Variational forms</a><ul>
<li><a class="reference internal" href="#sequence-of-scalar-pdes-formulation">Sequence of scalar PDEs formulation</a></li>
<li><a class="reference internal" href="#vector-pde-formulation">Vector PDE formulation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#a-worked-example">A worked example</a></li>
<li><a class="reference internal" href="#identical-function-spaces-for-the-unknowns">Identical function spaces for the unknowns</a><ul>
<li><a class="reference internal" href="#variational-form-of-each-individual-pde">Variational form of each individual PDE</a></li>
<li><a class="reference internal" href="#compound-scalar-variational-form">Compound scalar variational form</a></li>
<li><a class="reference internal" href="#decoupled-linear-systems">Decoupled linear systems</a></li>
<li><a class="reference internal" href="#coupled-linear-systems">Coupled linear systems</a></li>
</ul>
</li>
<li><a class="reference internal" href="#different-function-spaces-for-the-unknowns">Different function spaces for the unknowns</a></li>
<li><a class="reference internal" href="#computations-in-1d">Computations in 1D</a><ul>
<li><a class="reference internal" href="#another-example-in-1d">Another example in 1D</a></li>
</ul>
</li>
<li><a class="reference internal" href="#exercises-6">Exercises</a><ul>
<li><a class="reference internal" href="#problem-39-estimate-order-of-convergence-for-the-cooling-law">Problem 39: Estimate order of convergence for the Cooling law</a></li>
<li><a class="reference internal" href="#problem-40-estimate-order-of-convergence-for-the-cooling-law">Problem 40: Estimate order of convergence for the Cooling law</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#flexible-implementations-of-boundary-conditions">Flexible implementations of boundary conditions</a><ul>
<li><a class="reference internal" href="#optimization-with-constraint">Optimization with constraint</a><ul>
<li><a class="reference internal" href="#elimination-of-variables">Elimination of variables</a></li>
<li><a class="reference internal" href="#lagrange-multiplier-method">Lagrange multiplier method</a></li>
<li><a class="reference internal" href="#penalty-method">Penalty method</a></li>
</ul>
</li>
<li><a class="reference internal" href="#optimization-of-functionals">Optimization of functionals</a><ul>
<li><a class="reference internal" href="#classical-calculus-of-variations">Classical calculus of variations</a></li>
<li><a class="reference internal" href="#penalty-method-for-optimization-with-constraints">Penalty method for optimization with constraints</a></li>
<li><a class="reference internal" href="#lagrange-multiplier-method-for-optimization-with-constraints">Lagrange multiplier method for optimization with constraints</a></li>
<li><a class="reference internal" href="#example-1d-problem">Example: 1D problem</a></li>
<li><a class="reference internal" href="#example-adding-a-constraint-in-a-neumann-problem">Example: adding a constraint in a Neumann problem</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#nonlinear-problems">Nonlinear problems</a><ul>
<li><a class="reference internal" href="#introduction-of-basic-concepts">Introduction of basic concepts</a><ul>
<li><a class="reference internal" href="#linear-versus-nonlinear-equations">Linear versus nonlinear equations</a><ul>
<li><a class="reference internal" href="#algebraic-equations">Algebraic equations</a></li>
<li><a class="reference internal" href="#differential-equations">Differential equations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#a-simple-model-problem">A simple model problem</a></li>
<li><a class="reference internal" href="#linearization-by-explicit-time-discretization">Linearization by explicit time discretization</a></li>
<li><a class="reference internal" href="#exact-solution-of-nonlinear-algebraic-equations">Exact solution of nonlinear algebraic equations</a></li>
<li><a class="reference internal" href="#linearization">Linearization</a></li>
<li><a class="reference internal" href="#picard-iteration-1">Picard iteration</a><ul>
<li><a class="reference internal" href="#stopping-criteria-1">Stopping criteria</a></li>
<li><a class="reference internal" href="#a-single-picard-iteration">A single Picard iteration</a></li>
</ul>
</li>
<li><a class="reference internal" href="#linearization-by-a-geometric-mean">Linearization by a geometric mean</a></li>
<li><a class="reference internal" href="#newton-s-method-1">Newton&#8217;s method</a></li>
<li><a class="reference internal" href="#relaxation">Relaxation</a></li>
<li><a class="reference internal" href="#implementation-and-experiments">Implementation and experiments</a></li>
<li><a class="reference internal" href="#generalization-to-a-general-nonlinear-ode">Generalization to a general nonlinear ODE</a><ul>
<li><a class="reference internal" href="#explicit-time-discretization">Explicit time discretization</a></li>
<li><a class="reference internal" href="#backward-euler-discretization-2">Backward Euler discretization</a></li>
<li><a class="reference internal" href="#crank-nicolson-discretization-1">Crank-Nicolson discretization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#systems-of-odes">Systems of ODEs</a><ul>
<li><a class="reference internal" href="#example-5">Example</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="._book026.html"
                        title="previous chapter">Time-dependent variational forms</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="._book028.html"
                        title="next chapter">Systems of nonlinear algebraic equations</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/._book027.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="._book028.html" title="Systems of nonlinear algebraic equations"
             >next</a> |</li>
        <li class="right" >
          <a href="._book026.html" title="Time-dependent variational forms"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Introduction to Numerical Methods for Variational Problems</a> &raquo;</li> 
      </ul>
    </div>
<div class="wrapper">
  <div class="footer">
    <a href="http://cbc.simula.no"><img src="_static/cbc_banner.png" width="100%"><a>
    <br />
    <br />
      &copy;2016, Hans Petter Langtangen, Kent-Andre Mardal. Released under CC Attribution 4.0 license.
  </div>
</div>

  </body>
</html>