
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Uncertainty quantification and polynomial chaos expansions</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>

        <script src="http://sagecell.sagemath.org/static/jquery.min.js"></script>
        <script src="http://sagecell.sagemath.org/static/embedded_sagecell.js"></script>

        <script>sagecell.makeSagecell({inputLocation: ".sage"});</script>

        <style type="text/css">
                .sagecell .CodeMirror-scroll {
                        overflow-y: hidden;
                        overflow-x: auto;
                }
                .sagecell .CodeMirror {
                        height: auto;
                }
        </style>

    
    <link rel="top" title="Introduction to Numerical Methods for Variational Problems" href="index.html" />
    <link rel="next" title="Variational methods for linear systems" href="._book034.html" />
    <link rel="prev" title="Exercises" href="._book032.html" />
 
  
       <style type="text/css">
         div.admonition {
           background-color: whiteSmoke;
           border: 1px solid #bababa;
         }
       </style>
      </head>
    
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="._book034.html" title="Variational methods for linear systems"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="._book032.html" title="Exercises"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Introduction to Numerical Methods for Variational Problems</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="uncertainty-quantification-and-polynomial-chaos-expansions">
<span id="ch-pc"></span><h1>Uncertainty quantification and polynomial chaos expansions<a class="headerlink" href="#uncertainty-quantification-and-polynomial-chaos-expansions" title="Permalink to this headline">¶</a></h1>
<p id="index-0">Differential equations often contain unknown parameters, but
mathematically these must be prescribed to run the solution method.
If some parameters are uncertain, how uncertain is then the answer?
The simplest <em>conceptual</em> approach to this question is to let each
parameter vary in an interval and use <em>interval arithmetics</em> to
compute the interval of solution at the vertices of the
mesh. Unfortunately, this approach is terribly inaccurate and not
feasible. Also, any deterministic approach to the question hides fact
that uncertainty is strongly connected to statistical
variations. Therefore, a more sound approach is to prescribe some
statistics of the input parameters and then compute some statistics of
the output. This is called <em>stochastic uncertainty quantification</em>, or
just the name uncertainty quantification, abbreviated UQ, implies a
stochastic description of the input of the model. There has been a
heavy development of the UQ field during the last couple of decades.</p>
<p>One of the most exciting and promising methods of UQ for differential
equation is <em>polynomial chaos expansions</em>. The literature on this method
might seem complicated unless one has firm background in probability
theory. However, it turns out that all the seemingly different variations
of this method are all strongly connected if one knows the approximation
framework of the chapter <a class="reference internal" href="._book002.html#ch-approx-global"><span class="std std-ref">Function approximation by global functions</span></a> of this book and some very basic
probability theory. It is therefore natural to present polynomial chaos
expansions from perspective and make the ideas more accessible to a larger
audience. This is exactly the purpose of the present chapter.</p>
<p>There are some excellent expositions of polynomial chaos in the recent
literature by Dongbin Xiu <a class="reference internal" href="._book036.html#ref12" id="id1">[Ref12]</a> <a class="reference internal" href="._book036.html#ref13" id="id2">[Ref13]</a>. However, for the reader
with an understanding of the chapter <a class="reference internal" href="._book002.html#ch-approx-global"><span class="std std-ref">Function approximation by global functions</span></a> in this book, the authors
think the <em>ideas</em> can be conveyed much faster using those approximation
concepts rather than the more traditional exposition in the literature.</p>
<p><strong>Remark on a major probabilistic simplification.</strong></p>
<p>We assume that we have some function <span class="math">\(u(\boldsymbol{x},t;\zeta)\)</span>, where <span class="math">\(\zeta\)</span> is
a vector of <em>random parameters</em> <span class="math">\((\zeta_0,\ldots,\zeta_N)\)</span> that
introduces uncertainty in the problem. Note that the uncertainty is
described by <span class="math">\(M+1\)</span> stochastic scalar parameters and is therefore
<em>discretized</em> from a statistical point of view.  If we have temporal
or spatial stochastic processes or stochastic space-time fields, these
are continuous, and the mathematical formulations become considerably
more complicated. Assuming the uncertainty to be described by a set of
discrete stochastic <em>variables</em> represents the same simplification as
we introduced in earlier chapters where we assumed the solution to be
discrete, <span class="math">\(u(\boldsymbol{x})\approx\sum_ic_i{\psi}_i(\boldsymbol{x})\)</span>, and worked with
variational forms in finite-dimensional spaces. We could, as briefly
shown in the chapter <a class="reference internal" href="._book002.html#ch-approx-global"><span class="std std-ref">Function approximation by global functions</span></a>, equally well worked with
variational forms in <em>infinite-dimensional</em> spaces, but the theory
would involve Sobolev spaces rather than the far more intuitive vector
spaces. In the same manner, stochastic processes and fields and their
mathematical theory are avoided when assuming the uncertainty to be
already discretized in terms of random variables.</p>
<div class="section" id="sample-problems">
<h2>Sample problems<a class="headerlink" href="#sample-problems" title="Permalink to this headline">¶</a></h2>
<p>We shall look at two driving examples to illustrate the methods.</p>
<div class="section" id="ode-for-decay-processes">
<h3>ODE for decay processes<a class="headerlink" href="#ode-for-decay-processes" title="Permalink to this headline">¶</a></h3>
<p>A simple ODE, governing decay processes <a class="reference internal" href="._book036.html#ref14" id="id3">[Ref14]</a>
in space or time, reads</p>
<div class="math" id="eq-auto187">
\[\tag{461}
u'(t) = a(t)u(t),\quad u(0)=I,\]</div>
<p>where <span class="math">\(a\)</span> and <span class="math">\(I\)</span> can be uncertain input parameter, making <span class="math">\(u\)</span> an
uncertain output parameter for each <span class="math">\(t\)</span>.</p>
<p>If <span class="math">\(a\)</span> is uncertain, we assume that it
consists of uncertain piecewise constants: <span class="math">\(a=a_i\)</span> is a random variable
in some time interval <span class="math">\([t_i,t_{i+1}]\)</span>. Typically, we can write
<span class="math">\(a(t) = \sum_{i=0}^M a_i\hat{\psi}_i(\boldsymbol{x})\)</span>, with <span class="math">\(\hat{\psi}_i\)</span> being P0
elements in time, and <span class="math">\(a_i\)</span> are the unknown coefficients (in this case we
count to <span class="math">\(i\)</span> from 0 to <span class="math">\(M\)</span> and consider <span class="math">\(I\)</span> as certain).</p>
<div class="admonition-stochastic-ode admonition">
<p class="first admonition-title">Stochastic ODE</p>
<p>To be specific, we let <span class="math">\(a\)</span> be a scalar uncertain constant and let also
<span class="math">\(I\)</span> be uncertain. Then
we have two stochastic variables, <span class="math">\(M=2\)</span>: <span class="math">\(\zeta_0=a\)</span> and <span class="math">\(\zeta_1=I\)</span>.</p>
<p>The analytical solution to this ODE is <span class="math">\(u(t)=Ie^{-at}\)</span>, regardless of
which variables that are random or not. With only <span class="math">\(I\)</span> as
random variable, we see that the solution is simply a linear function
of <span class="math">\(I\)</span>, so if <span class="math">\(I\)</span> has a Gaussian probability distribution, <span class="math">\(u\)</span> is for
any <span class="math">\(t\)</span>, the well-known transformation of expectation and variance
a normally distributed random variable:</p>
<div class="math">
\[\begin{split}\begin{align*}
{\hbox{E}\lbrack u \rbrack} &amp;= {\hbox{E}\lbrack I \rbrack}e^{-at},\\
{\hbox{Var}\lbrack u \rbrack} &amp;= {\hbox{Var}\lbrack I \rbrack}e^{2at}{\thinspace .}
\end{align*}\end{split}\]</div>
<p>However, as soon as <span class="math">\(a\)</span> is stochastic, the problem is, from a stochastic
view point <em>nonlinear</em>, so there is no simple transformation of the
probability distribution for <span class="math">\(a\)</span> nor its statistics.</p>
<p>The basic statistics of expectance and variance for a random variable <span class="math">\(x\)</span>
varying continuously on the interval <span class="math">\(\Omega_X\)</span> is as</p>
<div class="last math">
\[\begin{split}\begin{align*}
{\hbox{E}\lbrack u(x) \rbrack} &amp;= \int_\Omega u(x)p(x){\, \mathrm{d}x},\\
{\hbox{Var}\lbrack u \rbrack} &amp;= \int_\Omega (u(x)-{\hbox{E}\lbrack u \rbrack})^2 p(x){\, \mathrm{d}x}{\thinspace .}
\end{align*}\end{split}\]</div>
</div>
</div>
<div class="section" id="the-stochastic-poisson-equation">
<h3>The stochastic Poisson equation<a class="headerlink" href="#the-stochastic-poisson-equation" title="Permalink to this headline">¶</a></h3>
<p>We also address the stationary PDE</p>
<div class="math" id="eq-auto188">
\[\tag{462}
-\nabla\cdot({\alpha}(\boldsymbol{x})\nabla u(\boldsymbol{x})) = f(\boldsymbol{x})\mbox{in }\Omega,\]</div>
<p>with appropriate Dirichlet, Neumann, or Robin conditions at the
boundary, The coefficients <span class="math">\({\alpha}\)</span> and <span class="math">\(f\)</span> are assumed to be stochastic
quantities discretized in terms of expansions, e.g., <span class="math">\({\alpha} =
\sum_{i=0}^M{\alpha}_i\hat{\psi}_i(\boldsymbol{x})\)</span>, where <span class="math">\(\hat{\psi}_i(\boldsymbol{x})\)</span> is
some spatial discretization - think of, for instance, of piecewise
constant P0 finite elements or global sine functions, and the
parameters <span class="math">\({\alpha}_i\)</span> as the random uncertain variables in the
problem. We form some final vector <span class="math">\((\zeta_0,\ldots,\zeta_M)\)</span> with all
the random parameters, from <span class="math">\({\alpha}(\boldsymbol{x})\)</span> only, from <span class="math">\(f(\boldsymbol{x})\)</span> only, or as
a combination of randomness in <span class="math">\({\alpha}\)</span> and <span class="math">\(f\)</span>. Here, one can obviously
include randomness in boundary conditions as well.</p>
<div class="admonition-d-model-problem admonition">
<p class="first admonition-title">1D model problem</p>
<p>A specific 1D problem for heat conduction,</p>
<div class="math">
\[\frac{\partial}{\partial x}\left({\alpha}(x)\frac{\partial u}{\partial x}
\right) = 0,\quad x\in\Omega = [0,L],\]</div>
<p class="last">may have two materials with <span class="math">\({\alpha}\)</span> as an uncertain constant in each
material. Let <span class="math">\(\Omega = \Omega_0 = [0,\hat L] \cup\Omega_1 = [\hat L,
0]\)</span>, where <span class="math">\(\Omega_i\)</span> is material number <span class="math">\(i\)</span>. Let <span class="math">\({\alpha}_i\)</span> be the
corresponding uncertain heat conduction coefficient value.  Now we
have <span class="math">\(M=2\)</span>, and <span class="math">\(\zeta_0={\alpha}_0\)</span> and <span class="math">\(\zeta_1={\alpha}_1\)</span>.</p>
</div>
</div>
</div>
<div class="section" id="basic-principles">
<h2>Basic principles<a class="headerlink" href="#basic-principles" title="Permalink to this headline">¶</a></h2>
<p>The <em>fundamental idea</em> in polynomial chaos theory is that we now
assume the mapping from an input parameter
<span class="math">\(\boldsymbol{\zeta}=(\zeta_0,\ldots,\zeta_M) \in W\)</span> to <span class="math">\(u\)</span>, to be <em>smooth</em>,
because we known that smooth mappings can efficiently be approximated
by <em>the sum</em></p>
<div class="math" id="eq-pc-fem-approx-ufem2">
\[\tag{463}
u(\boldsymbol{x};\boldsymbol{\zeta}) = \sum_{i=0}^{N} c_i{\psi}_i(\boldsymbol{\zeta})
    =\ \sum_{j\in{\mathcal{I}_s}} c_j{\psi}_j \in V {\thinspace .}\]</div>
<p>This is the same formula as we used for approximation in Chapter
<a class="reference internal" href="#eq-pc-fem-approx-ufem2"><span class="std std-ref">(463)</span></a>.
Note that <span class="math">\(\hbox{dim} W = M+1\)</span>, while <span class="math">\(\hbox{dim} V = N+1\)</span>.</p>
<p>Another basic principle in polynomial chaos theory is to choose the
basis functions in <span class="math">\(V\)</span>, <span class="math">\({\psi}_i(\boldsymbol{x})\)</span>, as <em>orthogonal
polynomials</em>. The reason is that this choice has the potential that
the sum <a class="reference internal" href="#eq-pc-fem-approx-ufem2"><span class="std std-ref">(463)</span></a> may converge very fast so <span class="math">\(N\)</span> can
be kept small.  [<strong>kam 46</strong>: I don&#8217;t get this. I arrested Jonathan also on this earlier and he did not provide an answer. I think orthogonality leads to easy or direct computations of moments such as E and Var.]</p>
<div class="admonition-polynomial-chaos-expansions-may-involve-many-unknowns admonition">
<p class="first admonition-title">Polynomial chaos expansions may involve many unknowns</p>
<p class="last">We have <span class="math">\(M+1\)</span> uncertain parameters so the approximation problem
takes place in an <span class="math">\(N+1\)</span> dimensional space, contrary to previous chapters
where <span class="math">\(N\)</span> would be physical space, <span class="math">\(N=1,2,3\)</span>. For each variable, we
will need a set of basis functions to represent the variation in that
variable. Suppose we use polynomials of order <span class="math">\(Q\)</span> and lower in each
variable <span class="math">\(\zeta_i\)</span>, <span class="math">\(i=0,\ldots,M\)</span>. The total number of terms in the
expansion is then</p>
</div>
<div class="math" id="eq-auto189">
\[ \begin{align}\begin{aligned} \tag{464}
 N + 1 = \frac{(Q + M)!}{Q!M!}{\thinspace .}\\Suppose we have 10 uncertain input variables ( \( M+1=10 \) ) and want to
approximate each variable by a cubic polynomial ( \( Q=3 \) ). This results
in  \( N+1=220 \)  terms in the expansion. And a cubic variation is modest,
so going to degree 10, demands 92,378 terms. Consequently, for the
polynomial chaos method to be effective, we need very fast convergence
and that lower-order polynomial variation is sufficient. First of all
this demands that the mapping from  \( \boldsymbol{\zeta} \)  to  \( u \)  is smooth, but
the parameter is very often smooth even though the solution  \( u(\boldsymbol{x}) \)  in
physical space is non-smooth.\end{aligned}\end{align} \]</div>
<div class="admonition-remark-on-terminology admonition">
<p class="first admonition-title">Remark on terminology</p>
<p class="last">The development of the theory in this chapter builds on the seminal
work on polynomial chaos theory by Roger Ghanem and co-workers. This
theory expands functions in Hermite polynomials, which was a great
success for a range of linear Gaussian engineering safety problems.
To obtain faster convergence in non-Gaussian problems, functions were
expanded in other families of orthogonal polynomials, which is the
view we take here, but that method is known as <em>generalized</em>
polynomial chaos, often abbreviated gPC.  In this text, however, we
use the shorter term polynomial chaos for all expansions of stochastic
parameter dependence in terms of global orthogonal polynomials.</p>
</div>
<div class="section" id="basic-statistical-results">
<h3>Basic statistical results<a class="headerlink" href="#basic-statistical-results" title="Permalink to this headline">¶</a></h3>
<p>Our task is to compute the coefficients <span class="math">\(c_i\)</span>. When these are known, we
can easily compute the statistics of the response <span class="math">\(u\)</span> of the differential
equation, or any other quantity derived from <span class="math">\(u\)</span>. For example, the
expectation of <span class="math">\(u\)</span> is</p>
<div class="math" id="eq-auto190">
\[\tag{465}
{\hbox{E}\lbrack u \rbrack} = {\hbox{E}\lbrack \sum_{j\in{\mathcal{I}_s} \rbrack} c_j{\psi}_j} = \sum_{j\in{\mathcal{I}_s}} {\hbox{E}\lbrack c_j \rbrack}{\psi}_j\]</div>
<p>A third pillar among assumption for the polynomial chaos method is that
the <em>random input variables are stochastically independent</em>. There are
methods to come around this problem, but these are very recent and we
keep the traditional assumption in the present of the theory here.</p>
<p>There are four methods that have been used to compute <span class="math">\(c_i\)</span>:</p>
<ol class="arabic simple">
<li>Least squares minimization or Galerkin projection with exact
computation of integrals</li>
<li>Least-squares minimization or Galerkin projection with numerical
computation of integrals</li>
<li>Interpolation or collocation</li>
<li>Regression</li>
</ol>
<p>Method 2 and 4 are the dominating ones. These go under the names
pseudo-spectral methods and stochastic collocation methods, respectively.</p>
</div>
<div class="section" id="least-squares-methods">
<h3>Least-squares methods<a class="headerlink" href="#least-squares-methods" title="Permalink to this headline">¶</a></h3>
<p>A major difference for deterministic approximation methods and
polynomial chaos based on least squares is that we introduce
probabilistic information in the inner product in the latter case.
This means that <em>we must know the joint probability distribution</em>
<span class="math">\(p(\boldsymbol{\zeta})\)</span> for the input parameters! Then we define the
inner product between two elements <span class="math">\(u\)</span> and <span class="math">\(w\)</span> in <span class="math">\(V\)</span> as</p>
<div class="math" id="eq-auto191">
\[\tag{466}
(u,v) = {\hbox{E}\lbrack uv \rbrack} = \int_\Omega u(\boldsymbol{\zeta})v(\boldsymbol{\zeta}) p(\boldsymbol{\zeta})d\boldsymbol{\zeta}\]</div>
<p>with the associated norm</p>
<div class="math">
\[|| u ||^2 = (u,u){\thinspace .}\]</div>
<p>The domain <span class="math">\(\Omega\)</span> is the hypercube of input parameters:</p>
<div class="math">
\[\Omega = [\zeta_{0,\min},\zeta_{0,\max}]\times
[\zeta_{1,\min},\zeta_{1,\max}]\times\cdots\times
[\zeta_{N,\min},\zeta_{N,\max}]{\thinspace .}\]</div>
<p>Since the random input variables are independent, we can factorize
the joint probability distribution as</p>
<div class="math">
\[p(\boldsymbol{\zeta}) = \Pi_{i=0}^N p_i(\zeta_i){\thinspace .}\]</div>
<p>We then have</p>
<div class="math">
\[{\hbox{E}\lbrack \boldsymbol{\zeta \rbrack}} = {\hbox{E}\lbrack \zeta_0 \rbrack}{\hbox{E}\lbrack \zeta_1 \rbrack}\cdots{\hbox{E}\lbrack \zeta_0 \rbrack}
= \Pi_{i=0}^N
\int\limits_{\zeta_{i,\,min}}^{\zeta_{i,max}}\zeta_i p_i(\zeta_0)d\zeta_i{\thinspace .}\]</div>
<p>Requiring that the polynomials are orthogonal means that</p>
<div class="math">
\[(u,v) = {\delta_{ij}}||u||,\]</div>
<p>where <span class="math">\(\delta_{ij}\)</span> is the Kronecker delta: <span class="math">\(\delta_{ij}=1\)</span> if and only if
<span class="math">\(i=j\)</span>, otherwise <span class="math">\(\delta_{ij}=0\)</span>.</p>
<p>Let <span class="math">\(f\)</span> be the solution computed by our mathematical model, either
approximately by a numerical method or exact.
When we do the least squares minimization, we know from the chapter <a class="reference internal" href="._book002.html#ch-approx-global"><span class="std std-ref">Function approximation by global functions</span></a> that the associated linear system is diagonal
and its solution is</p>
<div class="math" id="eq-pc-ci-ls">
\[\tag{467}
c_i = \frac{({\psi}_i, f)}{||{\psi}||^2} =
             \frac{{\hbox{E}\lbrack f{\psi}_i \rbrack}}{{\hbox{E}\lbrack {\psi}^2 \rbrack}}{\thinspace .}\]</div>
<p>In case of orthonormal polynomials <span class="math">\({\psi}_i\)</span> we simply have
<span class="math">\(c_i = {\hbox{E}\lbrack f{\psi}_i \rbrack}\)</span>.</p>
<p>Galerkin&#8217;s method or project gives</p>
<div class="math">
\[(f-\sum_i c_i {\psi}_i, v) = 0,\quad\forall v\in V,\]</div>
<p>which is equivalent to</p>
<div class="math">
\[(f-\sum_i c_i {\psi}_i, {\psi}_j) = 0,\quad j=0,\ldots,N,\]</div>
<p>and consequently the formula <a class="reference internal" href="#eq-pc-ci-ls"><span class="std std-ref">(467)</span></a> for <span class="math">\(c_i\)</span>.</p>
<p>The major question, from a computational point of view, is how to
evaluate the integrals in the formula for <span class="math">\(c_i\)</span>. Let us look at our
two primary examples.</p>
</div>
<div class="section" id="example-least-squares-applied-to-the-decay-ode">
<h3>Example: Least squares applied to the decay ODE<a class="headerlink" href="#example-least-squares-applied-to-the-decay-ode" title="Permalink to this headline">¶</a></h3>
<p>In this model problem, we are interested in the statistics of the
solution <span class="math">\(u(t)\)</span>. The response is <span class="math">\(u(t)=Ie^{-at} =
\zeta_0e^{-\zeta_1 t}\)</span> as our <span class="math">\(f(\zeta)\)</span> function.
Consequently,</p>
<div class="math">
\[u(\boldsymbol{x}) = \sum_{i\in{\mathcal{I}_s}} c_i(t){\psi}_i(\zeta_0,\zeta_1){\thinspace .}\]</div>
<p>Furthermore,</p>
<div class="math">
\[c_i(t) =
\frac{(\zeta_0e^{-\zeta_1 t},{\psi}_i)}{||{\psi}_i||^2}
= ||{\psi}_i||^{-2}\int\limits_{\zeta_{0,\min}}^{\zeta_{0,\max}}
\int\limits_{\zeta_{1,\min}}^{\zeta_{1,\max}}
\zeta_0e^{-\zeta_1 t}{\psi}_i(\zeta_0,\zeta_1) p_0(\zeta_0)p_1(\zeta_1)
d\zeta_0 d\zeta_1{\thinspace .}\]</div>
<p>This is a quite heavy integral to perform by hand; it really depends on
the complexity of the probability density function <span class="math">\(p_0\)</span> for <span class="math">\(I\)</span> and
<span class="math">\(p_1\)</span> for <span class="math">\(a\)</span>. A tool like SymPy or Mathematica is indispensable,
but even these will soon give up when <span class="math">\(i\)</span> grows.</p>
<p>Uniform distributions!</p>
</div>
<div class="section" id="modeling-the-response">
<h3>Modeling the response<a class="headerlink" href="#modeling-the-response" title="Permalink to this headline">¶</a></h3>
<p>Our aim is to approximate the mapping from input to output in a
simulation program. The output will often require solving a
differential equation. Let <span class="math">\(f\)</span> be the output response as a result of
solving the differential equation. We then want to find the mapping</p>
<div class="math">
\[u(\boldsymbol{x};\boldsymbol{\zeta}) = \sum_{i\in{\mathcal{I}_s}} c_i(\boldsymbol{x}){\psi}_i(\boldsymbol{\zeta}),\]</div>
<p>or if the response is some operation (functional) on the solution <span class="math">\(u\)</span>,
say <span class="math">\(f(u)\)</span>, we seek the mapping</p>
<div class="math">
\[f(\boldsymbol{\zeta}) = \sum_{i\in{\mathcal{I}_s}} c_i(\boldsymbol{x}){\psi}_i(\boldsymbol{\zeta}),\]</div>
<p>Normally, <span class="math">\(c_i\)</span> will depend on the spatial coordinate <span class="math">\(\boldsymbol{x}\)</span> as here,
but in some cases it</p>
<p>Give examples with flux etc!</p>
</div>
<div class="section" id="numerical-integration-3">
<h3>Numerical integration<a class="headerlink" href="#numerical-integration-3" title="Permalink to this headline">¶</a></h3>
<p>Clenshaw-Curtis quadrature,
Gauss-Legendre quadrature,
Gauss-Patterson quadrature,
Genz-Keister quadrature,
Leja quadrature,
Monte Carlo integration,
Optimal Gaussian quadrature,</p>
</div>
<div class="section" id="stochastic-collocation">
<h3>Stochastic collocation<a class="headerlink" href="#stochastic-collocation" title="Permalink to this headline">¶</a></h3>
<p>The stochastic collocation method is nothing but what we called
regression in the chapter <a class="reference internal" href="._book002.html#ch-approx-global"><span class="std std-ref">Function approximation by global functions</span></a>.  We simply choose a large
number <span class="math">\(P\)</span> of evaluation points in the parameter space <span class="math">\(W\)</span> and compute
the response at these points.  Then we fit an orthogonal polynomial
expansion to these points using the principle of least squares. Here,
in this educational text, the principle of least squares suffices,
but one should that for real-life computations a lot of difficulties
may happen, especially in large-scale problems. We then need to
stabilize the least squares computations in various ways, and for this
purpose, one needs tailored software like Chaospy to be briefly
introduced in the section <a class="reference internal" href="#pc-chaospy"><span class="std std-ref">The Chaospy software</span></a>. Chaospy offers, for example, a
wide range of regression schemes.</p>
<p>Also, the choice of collocation points should make use of point families
that suit this kind of problems. Again, Chaospy offers many collections
of point families, and not surprisingly, numerical integration points
constitute popular families.</p>
</div>
</div>
<div class="section" id="the-chaospy-software">
<span id="pc-chaospy"></span><h2>The Chaospy software<a class="headerlink" href="#the-chaospy-software" title="Permalink to this headline">¶</a></h2>
<p id="index-1">Refer to our ref for comparison with Dakota and Turns.</p>
</div>
<div class="section" id="intrusive-polynomial-chaos-methods">
<span id="pc-intrusive"></span><h2>Intrusive polynomial chaos methods<a class="headerlink" href="#intrusive-polynomial-chaos-methods" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-2"></span><p id="index-3">So far we have described <em>non-intrusive</em> polynomial chaos theory, which means
that the stochastic solution method can use the underlying differential
equation solver &#8220;as is&#8221; without any modifications. This is a great
advantage, and it also makes the theory easier to understand.
However, one may construct <em>intrusive</em> methods that applies the mapping
()
in the <em>solution process</em> of the differential equation model.</p>
<p>Let us address the decay ODE, <span class="math">\(u'=-au\)</span>, where we have the mapping
<span class="math">\(u=\sum_i c_i{\psi}_i\)</span> for <span class="math">\(u\)</span> which can be inserted in the ODE,
giving rise to a residual <span class="math">\(R\)</span>:</p>
<div class="math">
\[R = \sum_i c_i'(t){\psi}_i(\boldsymbol{\zeta}) -
\sum_i c_i{\psi}_i(\boldsymbol{\zeta}){\thinspace .}\]</div>
<p>Galerkin&#8217;s method is a common choice for incorporating the polynomial
chaos expansion when solving differential equations, so we require
as usual <span class="math">\((R,v)=0\)</span> for all <span class="math">\(v\in V\)</span>, or expressed via basis functions:</p>
<div class="math">
\[\sum_j ({\psi}_i,{\psi}_j) c_i'(t) = -a ({\psi}_i,{\psi}_i)\,\quad
i=0,\ldots,N tp\]</div>
<p>This is now a differential equation system in <span class="math">\(c_i\)</span>, which can be solved
by any ODE solver. However, the size of this system is <span class="math">\((N+1)\times (N+1)\)</span>
rather than just a scalar ODE in the original model and the non-intrusive
method. This is characteristic for non-intrusive methods: the size of
the underlying system grows exponentially with the number of uncertain
parameters, and one always ends up in high-dimensional spaces for the ODEs
or the coordinates for PDEs.</p>
<p>For the Poisson equation we insert the mapping</p>
<div class="math">
\[u(\boldsymbol{x}; \boldsymbol{\zeta}) = \sum_{i\in{\mathcal{I}_s}} c_i(\boldsymbol{x}){\psi}_i(\boldsymbol{\zeta}),\]</div>
<p>and get a residual</p>
<div class="math" id="eq-auto192">
\[\tag{468}
R = -\sum_{j\in{\mathcal{I}_s}}
    \nabla\cdot({\alpha}(\boldsymbol{x})\nabla c_j(\boldsymbol{x})){\psi}_j(\boldsymbol{\zeta}) +
    f(\boldsymbol{x}){\thinspace .}\]</div>
<p>Now we can apply Galerkin&#8217;s method to get equations for <span class="math">\(c_i(\boldsymbol{x})\)</span>:</p>
<div class="math">
\[\sum_{i\in{\mathcal{I}_s}} ({\psi}_j(\boldsymbol{\zeta}), {\psi}_i(\boldsymbol{\zeta}))
\nabla\cdot({\alpha}(\boldsymbol{x})\nabla c_j(\boldsymbol{x})) = (f(\boldsymbol{x}),{\psi}_i(\boldsymbol{\zeta})),\quad
i=0,\ldots,N{\thinspace .}\]</div>
<p>Here, we think that we solve the Poisson equation by some finite difference
or element method on some mesh, so for each node <span class="math">\(\boldsymbol{x}\)</span> in the mesh, we get
the above system for <span class="math">\(c_j\)</span>.
[<strong>hpl 47</strong>: Integration by parts?]</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <center>
            <p class="logo"><a href="http://cbc.simula.no/" title="Go to Center for Biomedical Computing">
              <img class="logo" src="_static/cbc_logo.png" alt="Logo"/>
            </a></p>
            </center>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Uncertainty quantification and polynomial chaos expansions</a><ul>
<li><a class="reference internal" href="#sample-problems">Sample problems</a><ul>
<li><a class="reference internal" href="#ode-for-decay-processes">ODE for decay processes</a></li>
<li><a class="reference internal" href="#the-stochastic-poisson-equation">The stochastic Poisson equation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#basic-principles">Basic principles</a><ul>
<li><a class="reference internal" href="#basic-statistical-results">Basic statistical results</a></li>
<li><a class="reference internal" href="#least-squares-methods">Least-squares methods</a></li>
<li><a class="reference internal" href="#example-least-squares-applied-to-the-decay-ode">Example: Least squares applied to the decay ODE</a></li>
<li><a class="reference internal" href="#modeling-the-response">Modeling the response</a></li>
<li><a class="reference internal" href="#numerical-integration-3">Numerical integration</a></li>
<li><a class="reference internal" href="#stochastic-collocation">Stochastic collocation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-chaospy-software">The Chaospy software</a></li>
<li><a class="reference internal" href="#intrusive-polynomial-chaos-methods">Intrusive polynomial chaos methods</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="._book032.html"
                        title="previous chapter">Exercises</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="._book034.html"
                        title="next chapter">Variational methods for linear systems</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/._book033.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="._book034.html" title="Variational methods for linear systems"
             >next</a> |</li>
        <li class="right" >
          <a href="._book032.html" title="Exercises"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Introduction to Numerical Methods for Variational Problems</a> &raquo;</li> 
      </ul>
    </div>
<div class="wrapper">
  <div class="footer">
    <a href="http://cbc.simula.no"><img src="_static/cbc_banner.png" width="100%"><a>
    <br />
    <br />
      &copy;2016, Hans Petter Langtangen, Kent-Andre Mardal. Released under CC Attribution 4.0 license.
  </div>
</div>

  </body>
</html>